{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OLohT6qFiQT",
        "outputId": "fa062e77-78eb-4aa1-f1dd-4401bde2178b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4kauX9l5CU6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIExBSpr5TdL",
        "outputId": "702ec8e0-46a1-45c1-cdec-4b72049f985e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(948, 197) (271, 196) (207, 196)\n"
          ]
        }
      ],
      "source": [
        "df_train = pd.read_csv(\"/content/drive/MyDrive/AmEx/processed_train_f.csv\")\n",
        "test_data = pd.read_csv(\"/content/drive/MyDrive/AmEx/processed_test_f.csv\")\n",
        "round2_data = pd.read_csv(\"/content/drive/MyDrive/AmEx/round2_processed_f.csv\")\n",
        "print(df_train.shape, test_data.shape, round2_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WX2-Ep8uJRDP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Assuming df_train is already defined\n",
        "\n",
        "# Columns to exclude from normalization\n",
        "exclude_columns = ['team1_id', 'match_id', 'team2_id', 'ground_id', 'winner']\n",
        "\n",
        "# Identify numerical columns\n",
        "numerical_columns = df_train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "# Select columns to normalize (excluding specified columns)\n",
        "columns_to_normalize = [col for col in numerical_columns if col not in exclude_columns]\n",
        "\n",
        "# Initialize MinMaxScaler\n",
        "scaler = MinMaxScalar()\n",
        "\n",
        "# Fit and transform the data for normalization\n",
        "df_train[columns_to_normalize] = scaler.fit_transform(df_train[columns_to_normalize])\n",
        "\n",
        "# Apply log transform to the normalized columns\n",
        "df_train[columns_to_normalize] = np.log1p(df_train[columns_to_normalize])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-L2B8yyJf75"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Columns to exclude from normalization\n",
        "exclude_columns = ['team1_id', 'match_id', 'team2_id', 'ground_id', 'winner']\n",
        "\n",
        "# Identify numerical columns\n",
        "numerical_columns = test_data.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "# Select columns to normalize (excluding specified columns)\n",
        "columns_to_normalize = [col for col in numerical_columns if col not in exclude_columns]\n",
        "\n",
        "# Initialize MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Fit and transform the data for normalization\n",
        "test_data[columns_to_normalize] = scaler.fit_transform(test_data[columns_to_normalize])\n",
        "\n",
        "# Apply log transform to the normalized columns\n",
        "test_data[columns_to_normalize] = np.log1p(test_data[columns_to_normalize])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0G28RglJNKDh",
        "outputId": "0f051ee6-062d-4165-e3b4-4817165305cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature match id has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature toss winner has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature toss decision has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature lighting has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature team_count_50runs_last15 has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature team_winp_last5 has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature team1only_avg_runs_last15 has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature ground_avg_runs_last15 has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature avg_inning1_runs_venue has different distributions in train and test sets (p-value: 0.00001)\n",
            "Feature avg_inning1_runs_venue_last5 has different distributions in train and test sets (p-value: 0.00003)\n",
            "Feature avg_inning2_runs_venue has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature avg_inning2_runs_venue_last5 has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature victory_by_runs_team1 has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature victory_by_runs_team2 has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature victory_by_wickets_team2 has different distributions in train and test sets (p-value: 0.02121)\n",
            "Feature victory_by_runs_team1_last5 has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature victory_by_runs_team2_last5 has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature victory_by_wickets_team2_last5 has different distributions in train and test sets (p-value: 0.02004)\n",
            "Feature inning1_avg_runs_team1 has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature inning1_avg_runs_team2 has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature inning1_avg_runs_team1_last5 has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature inning1_avg_runs_team2_last5 has different distributions in train and test sets (p-value: 0.00111)\n",
            "Feature inning2_avg_runs_team1 has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature inning2_avg_runs_team2 has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature inning2_avg_runs_team1_last5 has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature inning2_avg_runs_team2_last5 has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature inning2_avg_wickets_team2 has different distributions in train and test sets (p-value: 0.01804)\n",
            "Feature team2_won_in_past has different distributions in train and test sets (p-value: 0.04078)\n",
            "Feature nrr_team1 has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature nrr_team2 has different distributions in train and test sets (p-value: 0.00006)\n",
            "Feature nrr_team1_last5 has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature nrr_team2_last5 has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature team1_win_lighting1 has different distributions in train and test sets (p-value: 0.00223)\n",
            "Feature team2_day match_wickets_avg has different distributions in train and test sets (p-value: 0.04122)\n",
            "Feature team2_day match_runs_avg has different distributions in train and test sets (p-value: 0.00532)\n",
            "Feature team1_runs_avg_inning1_venue has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature team2_runs_avg_inning1_venue has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature team1_runs_avg_inning2_venue has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature team1_venue_wins has different distributions in train and test sets (p-value: 0.00157)\n",
            "Feature team2_venue_wins has different distributions in train and test sets (p-value: 0.00003)\n",
            "Feature team1_venue_wins_last5 has different distributions in train and test sets (p-value: 0.00454)\n",
            "Feature team2_venue_wins_last5 has different distributions in train and test sets (p-value: 0.00001)\n",
            "Feature team1_runs_avg_inning1_venue_last5 has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature team2_runs_avg_inning1_venue_last5 has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature team1_runs_avg_inning2_venue_last5 has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature team2_batting_chance_winning_VenueVise has different distributions in train and test sets (p-value: 0.00478)\n",
            "Feature relative_batting_chance_venueVise has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature team1_batting_chance_winning_FormVise has different distributions in train and test sets (p-value: 0.00509)\n",
            "Feature team2_batting_chance_winning_FormVise has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature relative_batting_chance_formvise has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature team1_bowling_chance_winning_VenueVise has different distributions in train and test sets (p-value: 0.00001)\n",
            "Feature relative_bowling_chance_venueVise has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature team1_bowling_chance_winning_FormVise has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature team2_bowling_chance_winning_FormVise has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature relative_bowling_chance_formvise has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature performance_relative_venue_vise has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature performance_relative_formVise has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature team1_runs_avg_inning1_venue - team2_runs_avg_inning1_venue has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature team1_runs_avg_inning2_venue - team2_runs_avg_inning2_venue has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature team1_night match_wickets_avg - team2_night match_wickets_avg has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature team1_day match_runs_avg - team2_day match_runs_avg has different distributions in train and test sets (p-value: 0.00316)\n",
            "Feature team1_night match_runs_avg - team2_night match_runs_avg has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature team1_day/night match_runs_avg - team2_day/night match_runs_avg has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature team1_win_lighting1 - team2_win_lighting1 has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature team1_win_lighting1_last5 - team2_win_lighting1_last5 has different distributions in train and test sets (p-value: 0.00037)\n",
            "Feature nrr_team1 - nrr_team2 has different distributions in train and test sets (p-value: 0.00848)\n",
            "Feature nrr_team1_last5 - nrr_team2_last5 has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature team1_won_in_past - team2_won_in_past has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature inning2_avg_wickets_team1 - inning2_avg_wickets_team2 has different distributions in train and test sets (p-value: 0.01272)\n",
            "Feature inning1_avg_runs_team1 - inning1_avg_runs_team2 has different distributions in train and test sets (p-value: 0.00077)\n",
            "Feature inning2_avg_runs_team1 - inning2_avg_runs_team2 has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature inning1_avg_runs_team1_last5 - inning1_avg_runs_team2_last5 has different distributions in train and test sets (p-value: 0.01292)\n",
            "Feature victory_by_runs_team1 - victory_by_runs_team2 has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature victory_by_wickets_team1 - victory_by_wickets_team2 has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature victory_by_runs_team1_last5 - victory_by_runs_team2_last5 has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature victory_by_wickets_team1_last5 - victory_by_wickets_team2_last5 has different distributions in train and test sets (p-value: 0.00416)\n",
            "Feature Overall_performance_relative_VenueVise has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature Overall_performance_relative_FormVise has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature top_bowler1_team1 has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature top_bowler2_team1 has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature top_bowler3_team1 has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature team2_BowlerAbilities_list has different distributions in train and test sets (p-value: 0.03571)\n",
            "Feature Sum_of_BowlerAbilities_team2 has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature top_bowler1_team2 has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature top_bowler2_team2 has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature top_bowler3_team2 has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature Sum_of_BatsmanAbilities_team1 has different distributions in train and test sets (p-value: 0.00001)\n",
            "Feature top_batsman1_team1 has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature Sum_of_BatsmanAbilities_team2 has different distributions in train and test sets (p-value: 0.00041)\n",
            "Feature top_batsman1_team2 has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature top_batsman2_team2 has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature top_batsman3_team2 has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature Sum_batting-bowling_team1 has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature Sum_batting-bowling_team2 has different distributions in train and test sets (p-value: 0.00002)\n",
            "Feature Batting-Bowling_diffrence has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature Batting_ability_diffrence has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature Bowling_ability_diffrence has different distributions in train and test sets (p-value: 0.00029)\n",
            "Feature team1_performance_under_Pressure has different distributions in train and test sets (p-value: 0.02068)\n",
            "Feature performance_under_pressure_relative has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature team1_vs_team2_avg_inning2_wickets has different distributions in train and test sets (p-value: 0.02133)\n",
            "Feature past_head_on_vs has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature performance_relative_venue_vise_batting has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature performance_relative_formVise_batting has different distributions in train and test sets (p-value: 0.00001)\n",
            "Feature performance_relative_formVise_bowling has different distributions in train and test sets (p-value: 0.00054)\n",
            "Feature past_head_on_vs_batting has different distributions in train and test sets (p-value: 0.00000)\n",
            "Feature past_head_on_vs_bowling has different distributions in train and test sets (p-value: 0.00000)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import ks_2samp\n",
        "\n",
        "def check_distribution(train_df, test_df, features):\n",
        "    similar_features = []\n",
        "    different_features = []\n",
        "\n",
        "    for feature in features:\n",
        "        if feature == 'winner':\n",
        "            continue  # Skip the target column\n",
        "        train_data = train_df[feature]\n",
        "        test_data = test_df[feature]\n",
        "        stat, p_value = ks_2samp(train_data, test_data)\n",
        "\n",
        "        if p_value < 0.05:  # Statistical significance threshold\n",
        "            print(f\"Feature {feature} has different distributions in train and test sets (p-value: {p_value:.5f})\")\n",
        "            different_features.append(feature)\n",
        "        else:\n",
        "            similar_features.append(feature)\n",
        "\n",
        "    return similar_features, different_features\n",
        "\n",
        "similar_features, different_features = check_distribution(df_train, test_data, df_train.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crMg9XHQNP5p",
        "outputId": "4a4f2166-a645-4d36-f6d2-0707181230f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['team1', 'team1_id', 'team1_roster_ids', 'team2', 'team2_id', 'team2_roster_ids', 'venue', 'city', 'match_dt', 'series_name', 'season', 'ground_id', 'team1_winp_team2_last15', 'avg_inning1_wickets_venue', 'avg_inning1_wickets_venue_last5', 'avg_inning2_wickets_venue', 'avg_inning2_wickets_venue_last5', 'victory_by_wickets_team1', 'victory_by_wickets_team1_last5', 'inning1_avg_wickets_team1', 'inning1_avg_wickets_team2', 'inning1_avg_wickets_team1_last5', 'inning1_avg_wickets_team2_last5', 'inning2_avg_wickets_team1', 'inning2_avg_wickets_team1_last5', 'inning2_avg_wickets_team2_last5', 'team1_won_in_past', 'team1_won_in_past_last5', 'team2_won_in_past_last5', 'team2_win_lighting1', 'team1_win_lighting1_last5', 'team2_win_lighting1_last5', 'team1_win_lighting2', 'team2_win_lighting2', 'team1_win_lighting2_last5', 'team2_win_lighting2_last5', 'team1_day match_wickets_avg', 'team1_night match_wickets_avg', 'team1_day/night match_wickets_avg', 'team2_night match_wickets_avg', 'team2_day/night match_wickets_avg', 'team1_day match_runs_avg', 'team1_night match_runs_avg', 'team1_day/night match_runs_avg', 'team2_night match_runs_avg', 'team2_day/night match_runs_avg', 'team1_wickets_avg_inning1_venue', 'team2_wickets_avg_inning1_venue', 'team1_wickets_avg_inning2_venue', 'team2_wickets_avg_inning2_venue', 'team2_runs_avg_inning2_venue', 'team1_wickets_avg_inning1_venue_last5', 'team2_wickets_avg_inning1_venue_last5', 'team1_wickets_avg_inning2_venue_last5', 'team2_wickets_avg_inning2_venue_last5', 'team2_runs_avg_inning2_venue_last5', 'team1_batting_chance_winning_VenueVise', 'team2_bowling_chance_winning_VenueVise', 'team1_venue_wins_last5 - team2_venue_wins_last5', 'team1_venue_wins - team2_venue_wins', 'team1_wickets_avg_inning1_venue - team2_wickets_avg_inning1_venue', 'team1_wickets_avg_inning2_venue - team2_wickets_avg_inning2_venue', 'team1_day match_wickets_avg - team2_day match_wickets_avg', 'team1_day/night match_wickets_avg - team2_day/night match_wickets_avg', 'team1_win_lighting2 - team2_win_lighting2', 'team1_win_lighting2_last5 - team2_win_lighting2_last5', 'team1_won_in_past_last5 - team2_won_in_past_last5', 'inning1_avg_wickets_team1 - inning1_avg_wickets_team2', 'inning1_avg_wickets_team1_last5 - inning1_avg_wickets_team2_last5', 'inning2_avg_wickets_team1_last5 - inning2_avg_wickets_team2_last5', 'inning2_avg_runs_team1_last5 - inning2_avg_runs_team2_last5', 'venue_based_bat_first_win_probability', 'team1_toss_based_win_chance', 'team1_BowlerAbilities_list', 'Sum_of_BowlerAbilities_team1', 'team1_BatsmanAbilities_list', 'top_batsman2_team1', 'top_batsman3_team1', 'team2_BatsmanAbilities_list', 'team2_performance_under_Pressure', 'team1_wins_vs_team2_venue', 'team2_wins_vs_team1_venue', 'team1_vs_team2_avg_inning1_runs', 'team2_vs_team1_avg_inning1_runs', 'team1_vs_team2_avg_inning2_runs', 'team2_vs_team1_avg_inning2_runs', 'team1_vs_team2_avg_inning1_wickets', 'team2_vs_team1_avg_inning1_wickets', 'team2_vs_team1_avg_inning2_wickets', 'performance_relative_venue_vise_bowling']\n",
            "90\n",
            "['match id', 'toss winner', 'toss decision', 'lighting', 'team_count_50runs_last15', 'team_winp_last5', 'team1only_avg_runs_last15', 'ground_avg_runs_last15', 'avg_inning1_runs_venue', 'avg_inning1_runs_venue_last5', 'avg_inning2_runs_venue', 'avg_inning2_runs_venue_last5', 'victory_by_runs_team1', 'victory_by_runs_team2', 'victory_by_wickets_team2', 'victory_by_runs_team1_last5', 'victory_by_runs_team2_last5', 'victory_by_wickets_team2_last5', 'inning1_avg_runs_team1', 'inning1_avg_runs_team2', 'inning1_avg_runs_team1_last5', 'inning1_avg_runs_team2_last5', 'inning2_avg_runs_team1', 'inning2_avg_runs_team2', 'inning2_avg_runs_team1_last5', 'inning2_avg_runs_team2_last5', 'inning2_avg_wickets_team2', 'team2_won_in_past', 'nrr_team1', 'nrr_team2', 'nrr_team1_last5', 'nrr_team2_last5', 'team1_win_lighting1', 'team2_day match_wickets_avg', 'team2_day match_runs_avg', 'team1_runs_avg_inning1_venue', 'team2_runs_avg_inning1_venue', 'team1_runs_avg_inning2_venue', 'team1_venue_wins', 'team2_venue_wins', 'team1_venue_wins_last5', 'team2_venue_wins_last5', 'team1_runs_avg_inning1_venue_last5', 'team2_runs_avg_inning1_venue_last5', 'team1_runs_avg_inning2_venue_last5', 'team2_batting_chance_winning_VenueVise', 'relative_batting_chance_venueVise', 'team1_batting_chance_winning_FormVise', 'team2_batting_chance_winning_FormVise', 'relative_batting_chance_formvise', 'team1_bowling_chance_winning_VenueVise', 'relative_bowling_chance_venueVise', 'team1_bowling_chance_winning_FormVise', 'team2_bowling_chance_winning_FormVise', 'relative_bowling_chance_formvise', 'performance_relative_venue_vise', 'performance_relative_formVise', 'team1_runs_avg_inning1_venue - team2_runs_avg_inning1_venue', 'team1_runs_avg_inning2_venue - team2_runs_avg_inning2_venue', 'team1_night match_wickets_avg - team2_night match_wickets_avg', 'team1_day match_runs_avg - team2_day match_runs_avg', 'team1_night match_runs_avg - team2_night match_runs_avg', 'team1_day/night match_runs_avg - team2_day/night match_runs_avg', 'team1_win_lighting1 - team2_win_lighting1', 'team1_win_lighting1_last5 - team2_win_lighting1_last5', 'nrr_team1 - nrr_team2', 'nrr_team1_last5 - nrr_team2_last5', 'team1_won_in_past - team2_won_in_past', 'inning2_avg_wickets_team1 - inning2_avg_wickets_team2', 'inning1_avg_runs_team1 - inning1_avg_runs_team2', 'inning2_avg_runs_team1 - inning2_avg_runs_team2', 'inning1_avg_runs_team1_last5 - inning1_avg_runs_team2_last5', 'victory_by_runs_team1 - victory_by_runs_team2', 'victory_by_wickets_team1 - victory_by_wickets_team2', 'victory_by_runs_team1_last5 - victory_by_runs_team2_last5', 'victory_by_wickets_team1_last5 - victory_by_wickets_team2_last5', 'Overall_performance_relative_VenueVise', 'Overall_performance_relative_FormVise', 'top_bowler1_team1', 'top_bowler2_team1', 'top_bowler3_team1', 'team2_BowlerAbilities_list', 'Sum_of_BowlerAbilities_team2', 'top_bowler1_team2', 'top_bowler2_team2', 'top_bowler3_team2', 'Sum_of_BatsmanAbilities_team1', 'top_batsman1_team1', 'Sum_of_BatsmanAbilities_team2', 'top_batsman1_team2', 'top_batsman2_team2', 'top_batsman3_team2', 'Sum_batting-bowling_team1', 'Sum_batting-bowling_team2', 'Batting-Bowling_diffrence', 'Batting_ability_diffrence', 'Bowling_ability_diffrence', 'team1_performance_under_Pressure', 'performance_under_pressure_relative', 'team1_vs_team2_avg_inning2_wickets', 'past_head_on_vs', 'performance_relative_venue_vise_batting', 'performance_relative_formVise_batting', 'performance_relative_formVise_bowling', 'past_head_on_vs_batting', 'past_head_on_vs_bowling']\n",
            "106\n"
          ]
        }
      ],
      "source": [
        "print(similar_features)\n",
        "print(len(similar_features))\n",
        "print(different_features)\n",
        "print(len(different_features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUb9qgn0J77a",
        "outputId": "b2da9626-412a-49fa-c8a2-5911464a74c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removed features with significantly different distributions:\n",
            "['match id', 'team1', 'team1_id', 'team1_roster_ids', 'team2', 'team2_id', 'team2_roster_ids', 'toss winner', 'toss decision', 'venue', 'city', 'match_dt', 'lighting', 'series_name', 'ground_id', 'team_count_50runs_last15', 'team_winp_last5', 'team1only_avg_runs_last15', 'ground_avg_runs_last15', 'avg_inning1_runs_venue', 'avg_inning1_runs_venue_last5', 'avg_inning2_runs_venue', 'avg_inning2_runs_venue_last5', 'avg_inning1_wickets_venue', 'avg_inning1_wickets_venue_last5', 'avg_inning2_wickets_venue', 'avg_inning2_wickets_venue_last5', 'victory_by_runs_team1', 'victory_by_runs_team2', 'victory_by_wickets_team1', 'victory_by_wickets_team2', 'victory_by_runs_team1_last5', 'victory_by_runs_team2_last5', 'victory_by_wickets_team1_last5', 'victory_by_wickets_team2_last5', 'inning1_avg_runs_team1', 'inning1_avg_runs_team2', 'inning1_avg_runs_team1_last5', 'inning1_avg_runs_team2_last5', 'inning2_avg_runs_team1', 'inning2_avg_runs_team2', 'inning2_avg_runs_team1_last5', 'inning2_avg_runs_team2_last5', 'inning1_avg_wickets_team1', 'inning1_avg_wickets_team2', 'inning1_avg_wickets_team1_last5', 'inning1_avg_wickets_team2_last5', 'inning2_avg_wickets_team1', 'inning2_avg_wickets_team2', 'inning2_avg_wickets_team1_last5', 'inning2_avg_wickets_team2_last5', 'team1_won_in_past', 'team2_won_in_past', 'team1_won_in_past_last5', 'nrr_team1', 'nrr_team2', 'nrr_team1_last5', 'nrr_team2_last5', 'team1_win_lighting1', 'team2_win_lighting1', 'team1_win_lighting1_last5', 'team2_win_lighting1_last5', 'team1_win_lighting2', 'team2_win_lighting2', 'team1_day match_wickets_avg', 'team1_night match_wickets_avg', 'team1_day/night match_wickets_avg', 'team2_day match_wickets_avg', 'team2_night match_wickets_avg', 'team2_day/night match_wickets_avg', 'team1_day match_runs_avg', 'team1_night match_runs_avg', 'team1_day/night match_runs_avg', 'team2_day match_runs_avg', 'team2_night match_runs_avg', 'team2_day/night match_runs_avg', 'team1_wickets_avg_inning1_venue', 'team2_wickets_avg_inning1_venue', 'team1_wickets_avg_inning2_venue', 'team2_wickets_avg_inning2_venue', 'team1_runs_avg_inning1_venue', 'team2_runs_avg_inning1_venue', 'team1_runs_avg_inning2_venue', 'team2_runs_avg_inning2_venue', 'team1_venue_wins', 'team2_venue_wins', 'team2_venue_wins_last5', 'team1_wickets_avg_inning1_venue_last5', 'team2_wickets_avg_inning1_venue_last5', 'team1_wickets_avg_inning2_venue_last5', 'team2_wickets_avg_inning2_venue_last5', 'team1_runs_avg_inning1_venue_last5', 'team2_runs_avg_inning1_venue_last5', 'team1_runs_avg_inning2_venue_last5', 'team2_runs_avg_inning2_venue_last5', 'team1_batting_chance_winning_VenueVise', 'team2_batting_chance_winning_VenueVise', 'relative_batting_chance_venueVise', 'team1_batting_chance_winning_FormVise', 'team2_batting_chance_winning_FormVise', 'relative_batting_chance_formvise', 'team1_bowling_chance_winning_VenueVise', 'team2_bowling_chance_winning_VenueVise', 'relative_bowling_chance_venueVise', 'team1_bowling_chance_winning_FormVise', 'team2_bowling_chance_winning_FormVise', 'relative_bowling_chance_formvise', 'performance_relative_venue_vise', 'performance_relative_formVise', 'team1_venue_wins_last5 - team2_venue_wins_last5', 'team1_venue_wins - team2_venue_wins', 'team1_runs_avg_inning1_venue - team2_runs_avg_inning1_venue', 'team1_runs_avg_inning2_venue - team2_runs_avg_inning2_venue', 'team1_wickets_avg_inning1_venue - team2_wickets_avg_inning1_venue', 'team1_wickets_avg_inning2_venue - team2_wickets_avg_inning2_venue', 'team1_day match_wickets_avg - team2_day match_wickets_avg', 'team1_night match_wickets_avg - team2_night match_wickets_avg', 'team1_day/night match_wickets_avg - team2_day/night match_wickets_avg', 'team1_day match_runs_avg - team2_day match_runs_avg', 'team1_night match_runs_avg - team2_night match_runs_avg', 'team1_day/night match_runs_avg - team2_day/night match_runs_avg', 'team1_win_lighting1 - team2_win_lighting1', 'team1_win_lighting2 - team2_win_lighting2', 'team1_win_lighting1_last5 - team2_win_lighting1_last5', 'team1_win_lighting2_last5 - team2_win_lighting2_last5', 'nrr_team1 - nrr_team2', 'nrr_team1_last5 - nrr_team2_last5', 'team1_won_in_past - team2_won_in_past', 'team1_won_in_past_last5 - team2_won_in_past_last5', 'inning1_avg_wickets_team1 - inning1_avg_wickets_team2', 'inning2_avg_wickets_team1 - inning2_avg_wickets_team2', 'inning1_avg_runs_team1 - inning1_avg_runs_team2', 'inning2_avg_runs_team1 - inning2_avg_runs_team2', 'inning1_avg_wickets_team1_last5 - inning1_avg_wickets_team2_last5', 'inning2_avg_wickets_team1_last5 - inning2_avg_wickets_team2_last5', 'inning1_avg_runs_team1_last5 - inning1_avg_runs_team2_last5', 'inning2_avg_runs_team1_last5 - inning2_avg_runs_team2_last5', 'victory_by_runs_team1 - victory_by_runs_team2', 'victory_by_wickets_team1 - victory_by_wickets_team2', 'victory_by_runs_team1_last5 - victory_by_runs_team2_last5', 'victory_by_wickets_team1_last5 - victory_by_wickets_team2_last5', 'Overall_performance_relative_VenueVise', 'Overall_performance_relative_FormVise', 'venue_based_bat_first_win_probability', 'team1_toss_based_win_chance', 'team1_BowlerAbilities_list', 'Sum_of_BowlerAbilities_team1', 'top_bowler1_team1', 'top_bowler2_team1', 'top_bowler3_team1', 'team2_BowlerAbilities_list', 'Sum_of_BowlerAbilities_team2', 'top_bowler1_team2', 'top_bowler2_team2', 'top_bowler3_team2', 'team1_BatsmanAbilities_list', 'Sum_of_BatsmanAbilities_team1', 'top_batsman1_team1', 'top_batsman2_team1', 'top_batsman3_team1', 'team2_BatsmanAbilities_list', 'Sum_of_BatsmanAbilities_team2', 'top_batsman1_team2', 'top_batsman2_team2', 'top_batsman3_team2', 'Sum_batting-bowling_team1', 'Sum_batting-bowling_team2', 'Batting-Bowling_diffrence', 'Batting_ability_diffrence', 'Bowling_ability_diffrence', 'team1_performance_under_Pressure', 'team2_performance_under_Pressure', 'performance_under_pressure_relative', 'team1_wins_vs_team2_venue', 'team1_vs_team2_avg_inning1_runs', 'team2_vs_team1_avg_inning1_runs', 'team1_vs_team2_avg_inning2_runs', 'team2_vs_team1_avg_inning2_runs', 'team1_vs_team2_avg_inning1_wickets', 'team2_vs_team1_avg_inning1_wickets', 'team1_vs_team2_avg_inning2_wickets', 'team2_vs_team1_avg_inning2_wickets', 'past_head_on_vs', 'performance_relative_venue_vise_batting', 'performance_relative_venue_vise_bowling', 'performance_relative_formVise_batting', 'performance_relative_formVise_bowling', 'past_head_on_vs_batting', 'past_head_on_vs_bowling']\n",
            "189\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import entropy\n",
        "\n",
        "def calculate_kl_divergence(train_feature, test_feature):\n",
        "    # Compute value counts and normalize\n",
        "    train_counts = train_feature.value_counts(normalize=True)\n",
        "    test_counts = test_feature.value_counts(normalize=True)\n",
        "\n",
        "    # Align the indices to handle missing values if any\n",
        "    all_index = train_counts.index.union(test_counts.index)\n",
        "    train_counts = train_counts.reindex(all_index, fill_value=0)\n",
        "    test_counts = test_counts.reindex(all_index, fill_value=0)\n",
        "\n",
        "    # Calculate KL divergence\n",
        "    kl_div = entropy(train_counts, test_counts)\n",
        "\n",
        "    return kl_div\n",
        "\n",
        "def remove_different_distribution_features(df_train, df_test, threshold=0.1):\n",
        "    features_to_remove = []\n",
        "\n",
        "    # Iterate through each feature\n",
        "    for feature in df_train.columns:\n",
        "        # Calculate KL divergence for the feature\n",
        "        if feature == 'winner':\n",
        "          continue\n",
        "        kl_div = calculate_kl_divergence(df_train[feature], df_test[feature])\n",
        "\n",
        "        # Compare with threshold\n",
        "        if kl_div > threshold:\n",
        "            features_to_remove.append(feature)\n",
        "\n",
        "    # Remove features from both dataframes\n",
        "    df_train_filtered = df_train.drop(columns=features_to_remove)\n",
        "    df_test_filtered = df_test.drop(columns=features_to_remove)\n",
        "\n",
        "    return df_train_filtered, df_test_filtered, features_to_remove\n",
        "\n",
        "# Example usage:\n",
        "df_train_filtered, df_test_filtered, removed_features = remove_different_distribution_features(df_train, test_data, threshold=0.1)\n",
        "\n",
        "# Printing removed features\n",
        "print(\"Removed features with significantly different distributions:\")\n",
        "print(removed_features)\n",
        "print(len(removed_features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "rAxPZtnr95N2"
      },
      "outputs": [],
      "source": [
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7JAOqWYCBwRw",
        "outputId": "e2c3c51e-363b-4a94-ffc3-a363e6da2cfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV Scores - Avg: 0.8236453201970443, Min: 0.75, Max: 0.9310344827586207\n",
            "Test Accuracy: 0.8741258741258742\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "# Assuming df_train and 'winner' column exist in your dataset\n",
        "\n",
        "# Select numerical columns\n",
        "numerical_cols = df_train.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "# Exclude the target column from numerical_cols if needed\n",
        "if 'winner' in numerical_cols:\n",
        "    numerical_cols = numerical_cols.drop('winner')\n",
        "\n",
        "# Split the data into train, test, and validation sets with stratification\n",
        "X = df_train[numerical_cols].drop(columns=['team1_id', 'match id', 'team2_id', 'ground_id'])\n",
        "y = df_train['winner']\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "# Initialize the CatBoost classifier with default parameters\n",
        "model = CatBoostClassifier(verbose=False)\n",
        "\n",
        "# Train the model on the training set\n",
        "model.fit(X_train, y_train, eval_set=(X_val, y_val), verbose=False)\n",
        "\n",
        "# Perform cross-validation on the validation set and report min, max, and average scores\n",
        "cv_scores = cross_val_score(model, X_val, y_val, cv=5, scoring='accuracy')\n",
        "print(f\"CV Scores - Avg: {cv_scores.mean()}, Min: {cv_scores.min()}, Max: {cv_scores.max()}\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred_test = model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "feature_importances = model.get_feature_importance()\n",
        "ft_imp_cat = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "et9-S6T4FA5u",
        "outputId": "ba3f8abc-6ce4-43ef-8b87-7e9b37f0443e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV Scores - Avg: 0.810344827586207, Min: 0.7586206896551724, Max: 0.8928571428571429\n",
            "Test Accuracy: 0.8811188811188811\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Assuming df_train and 'winner' column exist in your dataset\n",
        "\n",
        "# Select numerical columns\n",
        "numerical_cols = df_train.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "# Exclude the target column from numerical_cols if needed\n",
        "if 'winner' in numerical_cols:\n",
        "    numerical_cols = numerical_cols.drop('winner')\n",
        "\n",
        "# Exclude additional columns if necessary\n",
        "numerical_cols = numerical_cols.drop(['team1_id', 'team2_id', 'ground_id', 'match id'])\n",
        "\n",
        "# Split the data into train, test, and validation sets with stratification\n",
        "X = df_train[numerical_cols]\n",
        "y = df_train['winner']\n",
        "\n",
        "# Split the data with stratification\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "# Initialize the XGBoost classifier with default parameters\n",
        "model = XGBClassifier()\n",
        "\n",
        "# Train the model on the training set\n",
        "model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
        "\n",
        "# Perform cross-validation on the validation set and report min, max, and average scores\n",
        "cv_scores = cross_val_score(model, X_val, y_val, cv=5, scoring='accuracy')\n",
        "print(f\"CV Scores - Avg: {cv_scores.mean()}, Min: {cv_scores.min()}, Max: {cv_scores.max()}\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred_test = model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "# Get feature importances\n",
        "feature_importances = model.feature_importances_\n",
        "ft_imp_xg = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sZo93lQ0Fery",
        "outputId": "a3fda9f5-c462-43f0-81ba-465a2bb4267b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 329, number of negative: 334\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007276 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 22919\n",
            "[LightGBM] [Info] Number of data points in the train set: 663, number of used features: 178\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496229 -> initscore=-0.015083\n",
            "[LightGBM] [Info] Start training from score -0.015083\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 57, number of negative: 56\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000668 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 4895\n",
            "[LightGBM] [Info] Number of data points in the train set: 113, number of used features: 178\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504425 -> initscore=0.017700\n",
            "[LightGBM] [Info] Start training from score 0.017700\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 56, number of negative: 57\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4807\n",
            "[LightGBM] [Info] Number of data points in the train set: 113, number of used features: 178\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495575 -> initscore=-0.017700\n",
            "[LightGBM] [Info] Start training from score -0.017700\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 57, number of negative: 57\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002717 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 4888\n",
            "[LightGBM] [Info] Number of data points in the train set: 114, number of used features: 178\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 57, number of negative: 57\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000185 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4930\n",
            "[LightGBM] [Info] Number of data points in the train set: 114, number of used features: 178\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 57, number of negative: 57\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000753 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 4916\n",
            "[LightGBM] [Info] Number of data points in the train set: 114, number of used features: 178\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "CV Scores - Avg: 0.831527093596059, Min: 0.7586206896551724, Max: 0.9285714285714286\n",
            "Test Accuracy : 0.8881118881118881\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Assuming df_train and 'winner' column exist in your dataset\n",
        "\n",
        "# Select numerical columns\n",
        "numerical_cols = df_train.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "# Exclude the target column from numerical_cols if needed\n",
        "if 'winner' in numerical_cols:\n",
        "    numerical_cols = numerical_cols.drop('winner')\n",
        "\n",
        "# Exclude additional columns if necessary\n",
        "numerical_cols = numerical_cols.drop(['team1_id', 'team2_id', 'ground_id', 'match id'])\n",
        "\n",
        "# Split the data into train, test, and validation sets with stratification\n",
        "X = df_train[numerical_cols]\n",
        "y = df_train['winner']\n",
        "\n",
        "# Split the data with stratification\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "# Initialize the LightGBM classifier with default parameters\n",
        "model = lgb.LGBMClassifier()\n",
        "\n",
        "# Train the model on the training set\n",
        "model.fit(X_train, y_train, eval_set=[(X_val, y_val)])\n",
        "\n",
        "# Perform cross-validation on the validation set and report min, max, and average scores\n",
        "cv_scores = cross_val_score(model, X_val, y_val, cv=5, scoring='accuracy')\n",
        "print(f\"CV Scores - Avg: {cv_scores.mean()}, Min: {cv_scores.min()}, Max: {cv_scores.max()}\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred_test = model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "print(f\"Test Accuracy : {test_accuracy}\")\n",
        "\n",
        "# Get feature importances\n",
        "feature_importances_light = model.feature_importances_\n",
        "ft_imp_light = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances_light})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sPNZhXl1Fn7S",
        "outputId": "857d86cd-23af-45e9-e3a3-cee3d6e45a31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV Scores - Avg: 0.5637931034482758, Min: 0.5, Max: 0.6785714285714286\n",
            "Test Accuracy  : 0.4825174825174825\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "\n",
        "# Select numerical columns\n",
        "numerical_cols = df_train.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "# Exclude the target column from numerical_cols if needed\n",
        "if 'winner' in numerical_cols:\n",
        "    numerical_cols = numerical_cols.drop('winner')\n",
        "\n",
        "# Exclude additional columns if necessary\n",
        "numerical_cols = numerical_cols.drop(['team1_id', 'team2_id', 'ground_id', 'match id'])\n",
        "\n",
        "# Split the data into train, test, and validation sets with stratification\n",
        "X = df_train[numerical_cols]\n",
        "y = df_train['winner']\n",
        "\n",
        "# Split the data with stratification\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "# Initialize the GBM classifier with default parameters\n",
        "model = GradientBoostingClassifier()\n",
        "\n",
        "# Train the model on the training set\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Perform cross-validation on the validation set and report min, max, and average scores\n",
        "cv_scores = cross_val_score(model, X_val, y_val, cv=5, scoring='accuracy')\n",
        "print(f\"CV Scores - Avg: {cv_scores.mean()}, Min: {cv_scores.min()}, Max: {cv_scores.max()}\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred_test = model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "print(f\"Test Accuracy  : {test_accuracy}\")\n",
        "\n",
        "# Get feature importances\n",
        "feature_importances_gbm = model.feature_importances_\n",
        "ft_imp_gbm = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances_gbm})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7or5ltRGSsx",
        "outputId": "8fd857c0-4e50-47b1-a524-6b1b4dd2b4f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                               Feature  Avg_Importance\n",
            "148                          Sum_batting-bowling_team1        0.641454\n",
            "132                       Sum_of_BowlerAbilities_team1        0.610273\n",
            "107  team1_day/night match_runs_avg - team2_day/nig...        0.550650\n",
            "24                              inning1_avg_runs_team1        0.541103\n",
            "155                performance_under_pressure_relative        0.495763\n",
            "..                                                 ...             ...\n",
            "131                        team1_toss_based_win_chance        0.013864\n",
            "78               team1_wickets_avg_inning2_venue_last5        0.012145\n",
            "79               team2_wickets_avg_inning2_venue_last5        0.007213\n",
            "1                                        toss decision        0.000000\n",
            "157                          team2_wins_vs_team1_venue        0.000000\n",
            "\n",
            "[173 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "def ft_imp_avg(ft_imp_cat, ft_imp_xg, ft_imp_light, ft_imp_gbm):\n",
        "    # Create a MinMaxScaler instance\n",
        "    scaler = MinMaxScaler()\n",
        "\n",
        "    # Normalize the importance values in each dataframe\n",
        "    ft_imp_cat['Normalized_Importance_cat'] = scaler.fit_transform(ft_imp_cat[['Importance']])\n",
        "    ft_imp_xg['Normalized_Importance_xg'] = scaler.fit_transform(ft_imp_xg[['Importance']])\n",
        "    ft_imp_light['Normalized_Importance_light'] = scaler.fit_transform(ft_imp_light[['Importance']])\n",
        "    ft_imp_gbm['Normalized_Importance_gbm'] = scaler.fit_transform(ft_imp_gbm[['Importance']])\n",
        "\n",
        "    # Merge the dataframes on the 'Feature' column\n",
        "    merged_df = ft_imp_cat[['Feature', 'Normalized_Importance_cat']].merge(\n",
        "        ft_imp_xg[['Feature', 'Normalized_Importance_xg']], on='Feature'\n",
        "    ).merge(\n",
        "        ft_imp_light[['Feature', 'Normalized_Importance_light']], on='Feature'\n",
        "    ).merge(\n",
        "        ft_imp_gbm[['Feature', 'Normalized_Importance_gbm']], on='Feature'\n",
        "    )\n",
        "\n",
        "    # Calculate the average normalized importance for each feature\n",
        "    merged_df['Avg_Importance'] = merged_df[['Normalized_Importance_cat', 'Normalized_Importance_xg', 'Normalized_Importance_light', 'Normalized_Importance_gbm']].mean(axis=1)\n",
        "\n",
        "    # Return a dataframe with the average feature importance\n",
        "    avg_ft_imp = merged_df[['Feature', 'Avg_Importance']].sort_values(by='Avg_Importance', ascending=False)\n",
        "\n",
        "    return avg_ft_imp\n",
        "\n",
        "feat_imp_average = ft_imp_avg(ft_imp_cat, ft_imp_xg, ft_imp_light, ft_imp_gbm)\n",
        "print(feat_imp_average)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tgbAAp6Gjsx"
      },
      "outputs": [],
      "source": [
        "def find_redundant_features(df_train, avg_feature_importance):\n",
        "    # Create a correlation matrix for df_train\n",
        "    numerical_cols = df_train.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
        "\n",
        "    # Drop columns that are not features\n",
        "    features = df_train[numerical_cols].drop(columns=['match id', 'team1_id', 'team2_id', 'ground_id', 'winner'])\n",
        "    corr_matrix = features.corr().abs()\n",
        "\n",
        "    # Initialize a set to track features to keep\n",
        "    features_to_keep = set(features.columns)\n",
        "\n",
        "    # Iterate through the correlation matrix to find highly correlated pairs\n",
        "    correlated_pairs = []\n",
        "    cols = corr_matrix.columns\n",
        "    for i in range(len(cols)):\n",
        "        for j in range(i+1, len(cols)):\n",
        "            if corr_matrix.iloc[i, j] > 0.9:  # Adjust threshold as needed\n",
        "                correlated_pairs.append((cols[i], cols[j]))\n",
        "\n",
        "    # Remove less important features from each correlated pair\n",
        "    for pair in correlated_pairs:\n",
        "        feature1, feature2 = pair\n",
        "\n",
        "        # Find importance values from avg_feature_importance\n",
        "        importance1 = avg_feature_importance.loc[avg_feature_importance['Feature'] == feature1, 'Avg_Importance']\n",
        "        importance2 = avg_feature_importance.loc[avg_feature_importance['Feature'] == feature2, 'Avg_Importance']\n",
        "\n",
        "        # Check if both features exist in avg_feature_importance\n",
        "        if not importance1.empty and not importance2.empty:\n",
        "            importance1 = importance1.values[0]\n",
        "            importance2 = importance2.values[0]\n",
        "\n",
        "            # Remove the less important feature from features_to_keep\n",
        "            if importance1 < importance2:\n",
        "                features_to_keep.discard(feature1)\n",
        "            else:\n",
        "                features_to_keep.discard(feature2)\n",
        "\n",
        "    return list(features_to_keep)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyXEy9iZGlmJ",
        "outputId": "939cf496-38ac-4f04-af84-97f0bbc6277e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['victory_by_runs_team2_last5', 'team1_runs_avg_inning2_venue - team2_runs_avg_inning2_venue', 'team2_won_in_past_last5', 'team1_vs_team2_avg_inning1_wickets', 'team1_vs_team2_avg_inning2_wickets', 'team1_win_lighting1', 'Sum_of_BowlerAbilities_team2', 'team1_day match_wickets_avg - team2_day match_wickets_avg', 'team2_batting_chance_winning_VenueVise', 'victory_by_wickets_team2_last5', 'team1_win_lighting2_last5 - team2_win_lighting2_last5', 'team2_vs_team1_avg_inning1_wickets', 'team1_bowling_chance_winning_VenueVise', 'inning2_avg_runs_team1_last5 - inning2_avg_runs_team2_last5', 'team1_day match_runs_avg', 'top_bowler3_team2', 'relative_batting_chance_formvise', 'inning1_avg_runs_team2', 'top_batsman1_team1', 'team1_win_lighting2_last5', 'team1_won_in_past', 'team1_won_in_past_last5', 'past_head_on_vs_bowling', 'team1_performance_under_Pressure', 'top_bowler2_team2', 'victory_by_wickets_team1_last5 - victory_by_wickets_team2_last5', 'victory_by_wickets_team1', 'lighting', 'team1_day/night match_wickets_avg - team2_day/night match_wickets_avg', 'inning2_avg_wickets_team2', 'team_count_50runs_last15', 'Bowling_ability_diffrence', 'inning1_avg_wickets_team2', 'team1_bowling_chance_winning_FormVise', 'avg_inning1_wickets_venue', 'top_batsman2_team1', 'team2_win_lighting2', 'team1_win_lighting1_last5 - team2_win_lighting1_last5', 'nrr_team1 - nrr_team2', 'team1_winp_team2_last15', 'Sum_batting-bowling_team1', 'Batting-Bowling_diffrence', 'team2_vs_team1_avg_inning2_wickets', 'team2_day match_wickets_avg', 'inning1_avg_wickets_team1_last5 - inning1_avg_wickets_team2_last5', 'team_winp_last5', 'nrr_team1_last5 - nrr_team2_last5', 'inning2_avg_runs_team1', 'team1_wickets_avg_inning1_venue', 'avg_inning2_runs_venue_last5', 'team1only_avg_runs_last15', 'team2_win_lighting1', 'team2_wins_vs_team1_venue', 'performance_relative_formVise_bowling', 'team1_night match_runs_avg - team2_night match_runs_avg', 'top_batsman3_team2', 'team1_vs_team2_avg_inning2_runs', 'team1_day match_wickets_avg', 'performance_under_pressure_relative', 'victory_by_runs_team1_last5 - victory_by_runs_team2_last5', 'top_batsman3_team1', 'team1_runs_avg_inning1_venue - team2_runs_avg_inning1_venue', 'team1_night match_wickets_avg', 'team1_win_lighting1 - team2_win_lighting1', 'toss winner', 'victory_by_wickets_team1 - victory_by_wickets_team2', 'performance_relative_venue_vise_batting', 'Sum_of_BatsmanAbilities_team2', 'top_batsman1_team2', 'inning2_avg_wickets_team1 - inning2_avg_wickets_team2', 'team2_bowling_chance_winning_FormVise', 'inning1_avg_runs_team1 - inning1_avg_runs_team2', 'team1_wickets_avg_inning1_venue - team2_wickets_avg_inning1_venue', 'inning1_avg_runs_team1', 'top_bowler1_team1', 'team2_night match_runs_avg', 'inning1_avg_wickets_team1', 'team1_won_in_past - team2_won_in_past', 'team1_day/night match_wickets_avg', 'past_head_on_vs', 'team1_day/night match_runs_avg - team2_day/night match_runs_avg', 'nrr_team1', 'nrr_team2', 'relative_bowling_chance_venueVise', 'team1_day match_runs_avg - team2_day match_runs_avg', 'performance_relative_formVise_batting', 'victory_by_runs_team1_last5', 'team1_win_lighting1_last5', 'team2_win_lighting1_last5', 'team2_day/night match_runs_avg', 'team2_performance_under_Pressure', 'team2_won_in_past', 'nrr_team1_last5', 'team2_runs_avg_inning1_venue_last5', 'venue_based_bat_first_win_probability', 'victory_by_wickets_team2', 'team2_batting_chance_winning_FormVise', 'team1_won_in_past_last5 - team2_won_in_past_last5', 'top_bowler1_team2', 'nrr_team2_last5', 'avg_inning2_wickets_venue_last5', 'inning2_avg_wickets_team1', 'Sum_of_BowlerAbilities_team1', 'top_batsman2_team2', 'team2_vs_team1_avg_inning2_runs', 'top_bowler2_team1', 'inning2_avg_runs_team2', 'team1_night match_wickets_avg - team2_night match_wickets_avg', 'team1_wins_vs_team2_venue', 'team1_runs_avg_inning2_venue', 'relative_bowling_chance_formvise', 'top_bowler3_team1', 'team1_batting_chance_winning_FormVise']\n",
            "113\n"
          ]
        }
      ],
      "source": [
        "features_to_keep = find_redundant_features(df_train, feat_imp_average)\n",
        "print(features_to_keep)\n",
        "print(len(features_to_keep))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tx2FFFWOGtqq",
        "outputId": "530e42a1-4b63-4eb8-af01-0f8a90a65d6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Sum_batting-bowling_team1', 'Sum_of_BowlerAbilities_team1', 'team1_day/night match_runs_avg - team2_day/night match_runs_avg', 'inning1_avg_runs_team1', 'performance_under_pressure_relative', 'top_batsman3_team1', 'team_count_50runs_last15', 'victory_by_wickets_team2', 'top_bowler1_team1', 'nrr_team1 - nrr_team2', 'team1_day match_wickets_avg - team2_day match_wickets_avg', 'inning2_avg_wickets_team2', 'nrr_team1_last5', 'victory_by_wickets_team2_last5', 'top_batsman2_team1', 'Bowling_ability_diffrence', 'team1_night match_wickets_avg', 'victory_by_runs_team1_last5', 'team2_won_in_past_last5', 'team1_vs_team2_avg_inning2_runs', 'nrr_team2_last5', 'nrr_team2', 'nrr_team1', 'team1_win_lighting1 - team2_win_lighting1', 'team1_won_in_past_last5 - team2_won_in_past_last5', 'inning2_avg_runs_team1', 'Sum_of_BatsmanAbilities_team2', 'top_batsman1_team1', 'top_bowler2_team1', 'team1_day match_runs_avg - team2_day match_runs_avg', 'top_bowler2_team2', 'top_batsman1_team2', 'top_bowler3_team2', 'inning1_avg_wickets_team1', 'team2_vs_team1_avg_inning1_wickets', 'relative_bowling_chance_formvise', 'top_bowler1_team2', 'inning2_avg_runs_team1_last5 - inning2_avg_runs_team2_last5', 'victory_by_wickets_team1_last5 - victory_by_wickets_team2_last5', 'team1_won_in_past', 'team1_win_lighting1_last5 - team2_win_lighting1_last5', 'nrr_team1_last5 - nrr_team2_last5', 'top_bowler3_team1', 'avg_inning1_wickets_venue', 'avg_inning2_wickets_venue_last5', 'team_winp_last5', 'avg_inning2_runs_venue_last5', 'team2_win_lighting1_last5', 'team2_batting_chance_winning_VenueVise', 'team2_runs_avg_inning1_venue_last5', 'team2_batting_chance_winning_FormVise', 'team1_night match_wickets_avg - team2_night match_wickets_avg', 'team2_win_lighting1', 'inning1_avg_runs_team2', 'team1_performance_under_Pressure', 'inning1_avg_wickets_team1_last5 - inning1_avg_wickets_team2_last5', 'performance_relative_formVise_batting', 'team1_win_lighting1', 'team1_bowling_chance_winning_FormVise', 'team1_runs_avg_inning1_venue - team2_runs_avg_inning1_venue', 'team1_won_in_past - team2_won_in_past', 'victory_by_runs_team2_last5', 'inning2_avg_wickets_team1 - inning2_avg_wickets_team2', 'top_batsman3_team2', 'team1_day/night match_wickets_avg - team2_day/night match_wickets_avg', 'team2_performance_under_Pressure', 'inning1_avg_runs_team1 - inning1_avg_runs_team2', 'team2_bowling_chance_winning_FormVise', 'inning1_avg_wickets_team2', 'team2_vs_team1_avg_inning2_wickets', 'lighting', 'inning2_avg_runs_team2', 'top_batsman2_team2', 'victory_by_runs_team1_last5 - victory_by_runs_team2_last5', 'team2_vs_team1_avg_inning2_runs', 'team1_day/night match_wickets_avg', 'relative_batting_chance_formvise', 'victory_by_wickets_team1 - victory_by_wickets_team2', 'team2_day match_wickets_avg', 'performance_relative_venue_vise_batting', 'team1_vs_team2_avg_inning1_wickets', 'team1_wickets_avg_inning1_venue - team2_wickets_avg_inning1_venue', 'team1_win_lighting2_last5 - team2_win_lighting2_last5', 'team1_runs_avg_inning2_venue - team2_runs_avg_inning2_venue', 'Batting-Bowling_diffrence', 'past_head_on_vs_bowling', 'performance_relative_formVise_bowling', 'relative_bowling_chance_venueVise', 'team2_day/night match_runs_avg', 'Sum_of_BowlerAbilities_team2', 'team1only_avg_runs_last15', 'team1_night match_runs_avg - team2_night match_runs_avg', 'team1_day match_runs_avg', 'inning2_avg_wickets_team1', 'team2_won_in_past']\n",
            "95\n"
          ]
        }
      ],
      "source": [
        "def get_top_features_cumulative_importance(avg_feature_importance, cumulative_threshold=0.95):\n",
        "    # Sort the DataFrame by importance in descending order\n",
        "    avg_feature_importance_sorted = avg_feature_importance.sort_values(by='Avg_Importance', ascending=False)\n",
        "\n",
        "    # Calculate the cumulative importance\n",
        "    avg_feature_importance_sorted['Cumulative_importance'] = avg_feature_importance_sorted['Avg_Importance'].cumsum()\n",
        "\n",
        "    # Find the threshold where cumulative importance reaches the desired level (e.g., 95%)\n",
        "    threshold_value = cumulative_threshold * avg_feature_importance_sorted['Avg_Importance'].sum()\n",
        "\n",
        "    # Select the features that contribute to the cumulative importance threshold\n",
        "    top_features_df = avg_feature_importance_sorted[avg_feature_importance_sorted['Cumulative_importance'] <= threshold_value]\n",
        "\n",
        "    # Extract the list of feature names\n",
        "    top_features_list = top_features_df['Feature'].tolist()\n",
        "\n",
        "    return top_features_list\n",
        "\n",
        "# Ensure features_to_keep only contains features present in feat_imp_average\n",
        "valid_features = [feature for feature in features_to_keep if feature in feat_imp_average['Feature'].values]\n",
        "\n",
        "# Filter the avg_feature_importance DataFrame\n",
        "filtered_feat_imp_average = feat_imp_average[feat_imp_average['Feature'].isin(valid_features)]\n",
        "\n",
        "# Get top features based on cumulative importance\n",
        "top_features_cumulative = get_top_features_cumulative_importance(filtered_feat_imp_average, cumulative_threshold=0.95)\n",
        "\n",
        "print(top_features_cumulative)\n",
        "print(len(top_features_cumulative))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FIYhFdwuEqCx",
        "outputId": "112a3da9-78e3-4ddb-ad45-5269953917c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.30)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
            "Installing collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.5 alembic-1.13.1 colorlog-6.8.2 optuna-3.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "DIEj-JRWjZho",
        "outputId": "38211efb-34d9-40d7-b0eb-a3f461966bfb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-06-22 12:51:21,906] A new study created in memory with name: no-name-6334e69d-6dd7-4b3d-b9f8-d29ac8cd436e\n",
            "[I 2024-06-22 13:00:56,834] Trial 0 finished with value: 0.841660970608339 and parameters: {'depth': 10, 'iterations': 322, 'l2_leaf_reg': 5, 'learning_rate': 0.28401054903414746, 'subsample': 0.6468835912920555, 'bagging_temperature': 0.2964335175303001, 'border_count': 169, 'one_hot_max_size': 17}. Best is trial 0 with value: 0.841660970608339.\n",
            "[I 2024-06-22 13:02:50,603] Trial 2 finished with value: 0.8401458190931874 and parameters: {'depth': 8, 'iterations': 205, 'l2_leaf_reg': 1, 'learning_rate': 0.1404060069003133, 'subsample': 0.6247895881370579, 'bagging_temperature': 0.4595844708702308, 'border_count': 238, 'one_hot_max_size': 12}. Best is trial 0 with value: 0.841660970608339.\n",
            "[I 2024-06-22 13:02:51,782] Trial 1 finished with value: 0.8446684894053315 and parameters: {'depth': 10, 'iterations': 438, 'l2_leaf_reg': 2, 'learning_rate': 0.08285329884599107, 'subsample': 0.7255590856623274, 'bagging_temperature': 0.8745135517834305, 'border_count': 216, 'one_hot_max_size': 8}. Best is trial 1 with value: 0.8446684894053315.\n",
            "[I 2024-06-22 13:03:15,558] Trial 3 finished with value: 0.8401458190931874 and parameters: {'depth': 7, 'iterations': 133, 'l2_leaf_reg': 5, 'learning_rate': 0.030901337392100693, 'subsample': 0.9894188781180238, 'bagging_temperature': 0.07230129907727378, 'border_count': 112, 'one_hot_max_size': 8}. Best is trial 1 with value: 0.8446684894053315.\n",
            "[I 2024-06-22 13:03:16,658] Trial 4 finished with value: 0.8552175894281158 and parameters: {'depth': 8, 'iterations': 176, 'l2_leaf_reg': 9, 'learning_rate': 0.1131925876144096, 'subsample': 0.8782767987267486, 'bagging_temperature': 0.8224182534363789, 'border_count': 36, 'one_hot_max_size': 7}. Best is trial 4 with value: 0.8552175894281158.\n",
            "[I 2024-06-22 13:03:36,317] Trial 5 finished with value: 0.8371496924128504 and parameters: {'depth': 4, 'iterations': 176, 'l2_leaf_reg': 5, 'learning_rate': 0.07472295061788498, 'subsample': 0.9503461266715645, 'bagging_temperature': 0.3316303237543442, 'border_count': 47, 'one_hot_max_size': 18}. Best is trial 4 with value: 0.8552175894281158.\n",
            "[I 2024-06-22 13:03:44,794] Trial 6 finished with value: 0.8371041239462294 and parameters: {'depth': 5, 'iterations': 462, 'l2_leaf_reg': 3, 'learning_rate': 0.07672230508658158, 'subsample': 0.7271595090352161, 'bagging_temperature': 0.5255598132359872, 'border_count': 159, 'one_hot_max_size': 8}. Best is trial 4 with value: 0.8552175894281158.\n",
            "[I 2024-06-22 13:03:45,515] Trial 7 finished with value: 0.8341421736158579 and parameters: {'depth': 10, 'iterations': 108, 'l2_leaf_reg': 5, 'learning_rate': 0.08407303099238261, 'subsample': 0.9088283224185433, 'bagging_temperature': 0.9344950530205336, 'border_count': 4, 'one_hot_max_size': 13}. Best is trial 4 with value: 0.8552175894281158.\n",
            "[I 2024-06-22 13:05:16,235] Trial 8 finished with value: 0.8446457051720209 and parameters: {'depth': 7, 'iterations': 476, 'l2_leaf_reg': 4, 'learning_rate': 0.013004687442143347, 'subsample': 0.7860022043811284, 'bagging_temperature': 0.060614721739581046, 'border_count': 102, 'one_hot_max_size': 15}. Best is trial 4 with value: 0.8552175894281158.\n",
            "[I 2024-06-22 13:05:23,274] Trial 9 finished with value: 0.841660970608339 and parameters: {'depth': 9, 'iterations': 222, 'l2_leaf_reg': 5, 'learning_rate': 0.06932741733079589, 'subsample': 0.6296186331186288, 'bagging_temperature': 0.8420768792555785, 'border_count': 97, 'one_hot_max_size': 10}. Best is trial 4 with value: 0.8552175894281158.\n",
            "[I 2024-06-22 13:08:53,791] Trial 11 finished with value: 0.8401344269765323 and parameters: {'depth': 6, 'iterations': 282, 'l2_leaf_reg': 9, 'learning_rate': 0.02905695970144012, 'subsample': 0.865810821430459, 'bagging_temperature': 0.68891501666056, 'border_count': 40, 'one_hot_max_size': 4}. Best is trial 4 with value: 0.8552175894281158.\n",
            "[I 2024-06-22 13:10:52,165] Trial 10 finished with value: 0.850706311232627 and parameters: {'depth': 9, 'iterations': 485, 'l2_leaf_reg': 4, 'learning_rate': 0.062064914836119714, 'subsample': 0.8654879225405889, 'bagging_temperature': 0.8186608823223149, 'border_count': 237, 'one_hot_max_size': 18}. Best is trial 4 with value: 0.8552175894281158.\n",
            "[I 2024-06-22 13:13:29,725] Trial 12 finished with value: 0.840168603326498 and parameters: {'depth': 9, 'iterations': 386, 'l2_leaf_reg': 9, 'learning_rate': 0.168266942966803, 'subsample': 0.8121478970887005, 'bagging_temperature': 0.72748695629244, 'border_count': 222, 'one_hot_max_size': 3}. Best is trial 4 with value: 0.8552175894281158.\n",
            "[I 2024-06-22 13:15:48,801] Trial 13 finished with value: 0.8492139439507861 and parameters: {'depth': 8, 'iterations': 374, 'l2_leaf_reg': 8, 'learning_rate': 0.1764450453560914, 'subsample': 0.8476526544114308, 'bagging_temperature': 0.7114780842687374, 'border_count': 193, 'one_hot_max_size': 20}. Best is trial 4 with value: 0.8552175894281158.\n",
            "[I 2024-06-22 13:16:04,745] Trial 14 finished with value: 0.8447026657552973 and parameters: {'depth': 8, 'iterations': 289, 'l2_leaf_reg': 7, 'learning_rate': 0.035974042498741594, 'subsample': 0.8740227156103606, 'bagging_temperature': 0.9823626358385925, 'border_count': 176, 'one_hot_max_size': 20}. Best is trial 4 with value: 0.8552175894281158.\n",
            "[I 2024-06-22 13:16:25,803] Trial 15 finished with value: 0.8446912736386422 and parameters: {'depth': 8, 'iterations': 274, 'l2_leaf_reg': 7, 'learning_rate': 0.033038791329932884, 'subsample': 0.8897430858570388, 'bagging_temperature': 0.9797433721692883, 'border_count': 63, 'one_hot_max_size': 5}. Best is trial 4 with value: 0.8552175894281158.\n",
            "[I 2024-06-22 13:19:47,887] Trial 16 finished with value: 0.8356231487810435 and parameters: {'depth': 9, 'iterations': 241, 'l2_leaf_reg': 7, 'learning_rate': 0.04322826669387962, 'subsample': 0.9236205722095243, 'bagging_temperature': 0.5626033024342777, 'border_count': 46, 'one_hot_max_size': 5}. Best is trial 4 with value: 0.8552175894281158.\n",
            "[I 2024-06-22 13:20:32,561] Trial 18 finished with value: 0.8476987924356345 and parameters: {'depth': 6, 'iterations': 348, 'l2_leaf_reg': 3, 'learning_rate': 0.020742077921008573, 'subsample': 0.7960814436446804, 'bagging_temperature': 0.779720371081661, 'border_count': 128, 'one_hot_max_size': 15}. Best is trial 4 with value: 0.8552175894281158.\n",
            "[I 2024-06-22 13:20:53,517] Trial 17 finished with value: 0.8416381863750285 and parameters: {'depth': 9, 'iterations': 359, 'l2_leaf_reg': 7, 'learning_rate': 0.04812932354871017, 'subsample': 0.7779727063933163, 'bagging_temperature': 0.5556348290829731, 'border_count': 255, 'one_hot_max_size': 6}. Best is trial 4 with value: 0.8552175894281158.\n",
            "[I 2024-06-22 13:24:06,901] Trial 20 finished with value: 0.8462178172704489 and parameters: {'depth': 6, 'iterations': 414, 'l2_leaf_reg': 3, 'learning_rate': 0.241143329492845, 'subsample': 0.9658733494280303, 'bagging_temperature': 0.6350566987783854, 'border_count': 12, 'one_hot_max_size': 2}. Best is trial 4 with value: 0.8552175894281158.\n",
            "[I 2024-06-22 13:24:33,208] Trial 21 finished with value: 0.8477443609022556 and parameters: {'depth': 7, 'iterations': 182, 'l2_leaf_reg': 6, 'learning_rate': 0.12936487482815037, 'subsample': 0.8293339310634579, 'bagging_temperature': 0.8606354446949918, 'border_count': 74, 'one_hot_max_size': 10}. Best is trial 4 with value: 0.8552175894281158.\n",
            "[W 2024-06-22 13:24:39,781] Trial 22 failed with parameters: {'depth': 8, 'iterations': 492, 'l2_leaf_reg': 8, 'learning_rate': 0.12205268953680021, 'subsample': 0.8583898652006142, 'bagging_temperature': 0.7683957994004268, 'border_count': 194, 'one_hot_max_size': 20} because of the following error: KeyboardInterrupt('').\n",
            "joblib.externals.loky.process_executor._RemoteTraceback: \n",
            "\"\"\"\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py\", line 463, in _process_worker\n",
            "    r = call_item()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n",
            "    return self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 598, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 598, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/catboost/core.py\", line 5220, in fit\n",
            "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/catboost/core.py\", line 2400, in _fit\n",
            "    self._train(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/catboost/core.py\", line 1780, in _train\n",
            "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
            "  File \"_catboost.pyx\", line 4833, in _catboost._CatBoost._train\n",
            "  File \"_catboost.pyx\", line 4882, in _catboost._CatBoost._train\n",
            "KeyboardInterrupt\n",
            "\"\"\"\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-19-82438d404f99>\", line 32, in objective\n",
            "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 515, in cross_val_score\n",
            "    cv_results = cross_validate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 266, in cross_validate\n",
            "    results = parallel(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 2007, in __call__\n",
            "    return output if self.return_generator else list(output)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1650, in _get_outputs\n",
            "    yield from self._retrieve()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1754, in _retrieve\n",
            "    self._raise_error_fast()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1789, in _raise_error_fast\n",
            "    error_job.get_result(self.timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 745, in get_result\n",
            "    return self._return_or_raise()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 763, in _return_or_raise\n",
            "    raise self._result\n",
            "KeyboardInterrupt\n",
            "[W 2024-06-22 13:24:39,784] Trial 19 failed with parameters: {'depth': 9, 'iterations': 420, 'l2_leaf_reg': 6, 'learning_rate': 0.11889351751976196, 'subsample': 0.9680938039333219, 'bagging_temperature': 0.6251623485891548, 'border_count': 254, 'one_hot_max_size': 10} because of the following error: RuntimeError(\"The executor underlying Parallel has been shutdown. This is likely due to the garbage collection of a previous generator from a call to Parallel with return_as='generator'. Make sure the generator is not garbage collected when submitting a new job or that it is first properly exhausted.\").\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 595, in retrieve_result_callback\n",
            "    return out.result()\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n",
            "    return self.__get_result()\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
            "    raise self._exception\n",
            "joblib.externals.loky.process_executor.ShutdownExecutorError: The Executor was shutdown with `kill_workers=True` before this job could complete.\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-19-82438d404f99>\", line 32, in objective\n",
            "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 515, in cross_val_score\n",
            "    cv_results = cross_validate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 266, in cross_validate\n",
            "    results = parallel(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 2007, in __call__\n",
            "    return output if self.return_generator else list(output)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1650, in _get_outputs\n",
            "    yield from self._retrieve()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1754, in _retrieve\n",
            "    self._raise_error_fast()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1789, in _raise_error_fast\n",
            "    error_job.get_result(self.timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 745, in get_result\n",
            "    return self._return_or_raise()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 763, in _return_or_raise\n",
            "    raise self._result\n",
            "RuntimeError: The executor underlying Parallel has been shutdown. This is likely due to the garbage collection of a previous generator from a call to Parallel with return_as='generator'. Make sure the generator is not garbage collected when submitting a new job or that it is first properly exhausted.\n",
            "[W 2024-06-22 13:24:39,798] Trial 19 failed with value None.\n",
            "[W 2024-06-22 13:24:39,794] Trial 22 failed with value None.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-82438d404f99>\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTPESampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mbest_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \"\"\"\n\u001b[0;32m--> 451\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    452\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                         \u001b[0mcompleted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfutures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_when\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFIRST_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m                         \u001b[0;31m# Raise if exception occurred in executing the completed futures.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcompleted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(fs, timeout, return_when)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0mwaiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_and_install_waiters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_when\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m     \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from catboost import CatBoostClassifier\n",
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "\n",
        "# Split the data into train, test, and validation sets with stratification\n",
        "X = df_train[top_features_cumulative]\n",
        "y = df_train['winner']\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "# Optuna for all hyperparameters\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'depth': trial.suggest_int('depth', 4, 10),\n",
        "        'iterations': trial.suggest_int('iterations', 100, 500),\n",
        "        'l2_leaf_reg': trial.suggest_int('l2_leaf_reg', 1, 9),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
        "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
        "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n",
        "        'border_count': trial.suggest_int('border_count', 1, 255),\n",
        "        'one_hot_max_size': trial.suggest_int('one_hot_max_size', 2, 20),\n",
        "        'eval_metric': 'Accuracy',\n",
        "        'early_stopping_rounds': 50,\n",
        "        'verbose': False\n",
        "    }\n",
        "\n",
        "    model = CatBoostClassifier(**params)\n",
        "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "    return cv_scores.mean()\n",
        "\n",
        "study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=42))\n",
        "study.optimize(objective, n_trials=50, n_jobs=-1)\n",
        "\n",
        "best_params = study.best_params\n",
        "print(f\"Best hyperparameters: {best_params}\")\n",
        "\n",
        "# Train and evaluate the final model with combined best hyperparameters\n",
        "final_model = CatBoostClassifier(**best_params)\n",
        "final_model.fit(X_train, y_train, eval_set=(X_val, y_val), verbose=False)\n",
        "\n",
        "# Perform cross-validation on the validation set\n",
        "cv_scores = cross_val_score(final_model, X_val, y_val, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "print(f\"CV Scores - Avg: {cv_scores.mean()}, Min: {cv_scores.min()}, Max: {cv_scores.max()}\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred_test = final_model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "# Print final results\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "print(f\"CV Scores - Avg: {cv_scores.mean()}, Min: {cv_scores.min()}, Max: {cv_scores.max()}\")\n",
        "print(f\"Test Accuracy: {test_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_YNR7kamkO11"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from xgboost import XGBClassifier\n",
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "\n",
        "# Split the data into train, test, and validation sets with stratification\n",
        "X = df_train[top_features_cumulative]\n",
        "y = df_train['winner']\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "# Optuna for all hyperparameters\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
        "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
        "        'gamma': trial.suggest_float('gamma', 0, 10),\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
        "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
        "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n",
        "        'eval_metric': 'logloss',\n",
        "        'use_label_encoder': False\n",
        "    }\n",
        "\n",
        "    model = XGBClassifier(**params)\n",
        "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "    return cv_scores.mean()\n",
        "\n",
        "study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=42))\n",
        "study.optimize(objective, n_trials=50, n_jobs=-1)\n",
        "\n",
        "best_params = study.best_params\n",
        "print(f\"Best hyperparameters: {best_params}\")\n",
        "\n",
        "# Train and evaluate the final model with combined best hyperparameters\n",
        "final_model = XGBClassifier(**best_params, use_label_encoder=False)\n",
        "final_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=50, verbose=False)\n",
        "\n",
        "# Perform cross-validation on the validation set\n",
        "cv_scores = cross_val_score(final_model, X_val, y_val, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "print(f\"CV Scores - Avg: {cv_scores.mean()}, Min: {cv_scores.min()}, Max: {cv_scores.max()}\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred_test = final_model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "# Print final results\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "print(f\"CV Scores - Avg: {cv_scores.mean()}, Min: {cv_scores.min()}, Max: {cv_scores.max()}\")\n",
        "print(f\"Test Accuracy: {test_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "X8PZNxmilhQ_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "import lightgbm as lgb\n",
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "\n",
        "# Split the data into train, test, and validation sets with stratification\n",
        "X = df_train[top_features_cumulative]\n",
        "y = df_train['winner']\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "# Optuna for all hyperparameters\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 10, 200),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
        "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
        "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
        "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
        "        'metric': 'accuracy',\n",
        "        'verbosity': -1\n",
        "    }\n",
        "\n",
        "    model = lgb.LGBMClassifier(**params)\n",
        "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "    return cv_scores.mean()\n",
        "\n",
        "study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=42))\n",
        "study.optimize(objective, n_trials=50, n_jobs=-1)\n",
        "\n",
        "best_params = study.best_params\n",
        "print(f\"Best hyperparameters: {best_params}\")\n",
        "\n",
        "# Train and evaluate the final model with combined best hyperparameters\n",
        "final_model = lgb.LGBMClassifier(**best_params)\n",
        "final_model.fit(X_train, y_train, eval_set=(X_val, y_val))\n",
        "\n",
        "# Perform cross-validation on the validation set\n",
        "cv_scores = cross_val_score(final_model, X_val, y_val, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "print(f\"CV Scores - Avg: {cv_scores.mean()}, Min: {cv_scores.min()}, Max: {cv_scores.max()}\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred_test = final_model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "# Print final results\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "print(f\"CV Scores - Avg: {cv_scores.mean()}, Min: {cv_scores.min()}, Max: {cv_scores.max()}\")\n",
        "print(f\"Test Accuracy: {test_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "zlZhKmdrljAO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "\n",
        "# Assuming df_train, top_features_cumulative are defined appropriately\n",
        "\n",
        "# Split the data into train, test, and validation sets with stratification\n",
        "X = df_train[top_features_cumulative]\n",
        "y = df_train['winner']\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "# Define the objective function for Optuna optimization\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
        "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
        "        'max_features': trial.suggest_float('max_features', 0.6, 1.0),\n",
        "    }\n",
        "\n",
        "    model = GradientBoostingClassifier(**params)\n",
        "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "    return cv_scores.mean()\n",
        "\n",
        "# Create an Optuna study and optimize the objective function\n",
        "study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=42))\n",
        "study.optimize(objective, n_trials=50, n_jobs=-1)\n",
        "\n",
        "# Get the best hyperparameters from the study\n",
        "best_params = study.best_params\n",
        "print(f\"Best hyperparameters: {best_params}\")\n",
        "\n",
        "# Train the final model with the best hyperparameters\n",
        "final_model = GradientBoostingClassifier(**best_params)\n",
        "final_model.fit(X_train, y_train)\n",
        "\n",
        "# Perform cross-validation on the validation set\n",
        "cv_scores = cross_val_score(final_model, X_val, y_val, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "print(f\"CV Scores - Avg: {cv_scores.mean()}, Min: {cv_scores.min()}, Max: {cv_scores.max()}\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred_test = final_model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "# Print final results\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "print(f\"CV Scores - Avg: {cv_scores.mean()}, Min: {cv_scores.min()}, Max: {cv_scores.max()}\")\n",
        "print(f\"Test Accuracy: {test_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6WDfOK8Lgz4"
      },
      "outputs": [],
      "source": [
        "# catboost_params = {'depth': 4, 'iterations': 131, 'l2_leaf_reg': 9, 'learning_rate': 0.026746858922480903, 'subsample': 0.9806922046593372, 'bagging_temperature': 0.863851083829466, 'border_count': 79, 'one_hot_max_size': 10}\n",
        "# xgboost_params = {'max_depth': 5, 'n_estimators': 269, 'learning_rate': 0.1497059900832021, 'subsample': 0.6134373870090926, 'colsample_bytree': 0.8655799077621021, 'gamma': 3.39838763588673, 'min_child_weight': 10, 'reg_alpha': 5.895160858400561, 'reg_lambda': 2.0436192434364866}\n",
        "# lightgbm_params = {'max_depth': 3, 'num_leaves': 165, 'learning_rate': 0.15387125194824516, 'subsample': 0.7701573425754059, 'colsample_bytree': 0.8740741726764223, 'reg_alpha': 5.967689395391898, 'reg_lambda': 5.552505199267917, 'n_estimators': 294}\n",
        "# gbm_params = {'learning_rate': 0.013177244157007226, 'n_estimators': 223, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 10, 'max_features': 0.677756768922895}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SXJM2gUdZ0yQ",
        "outputId": "2c7c9f05-4ddf-40a9-d144-942d08e2f5a4",
        "collapsed": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 329, number of negative: 334\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000641 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3503\n",
            "[LightGBM] [Info] Number of data points in the train set: 663, number of used features: 42\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496229 -> initscore=-0.015083\n",
            "[LightGBM] [Info] Start training from score -0.015083\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-06-22 13:46:46,774] A new study created in memory with name: no-name-600099d9-4a6e-49c0-bf3f-6caf4e27af03\n",
            "[I 2024-06-22 13:46:49,643] Trial 0 finished with value: 0.8593596059113301 and parameters: {'learning_rate': 0.052892365923112986, 'n_estimators': 112, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 13, 'max_features': 0.655036768928282, 'subsample': 0.6157874159191865}. Best is trial 0 with value: 0.8593596059113301.\n",
            "[I 2024-06-22 13:46:49,722] Trial 1 finished with value: 0.8527093596059114 and parameters: {'learning_rate': 0.034649237717983235, 'n_estimators': 172, 'max_depth': 3, 'min_samples_split': 18, 'min_samples_leaf': 3, 'max_features': 0.7722099886799071, 'subsample': 0.8649414211533175}. Best is trial 0 with value: 0.8593596059113301.\n",
            "[I 2024-06-22 13:46:52,578] Trial 2 finished with value: 0.8527093596059114 and parameters: {'learning_rate': 0.01907461976400857, 'n_estimators': 357, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 11, 'max_features': 0.7764368740371677, 'subsample': 0.658183011756951}. Best is trial 0 with value: 0.8593596059113301.\n",
            "[I 2024-06-22 13:46:52,655] Trial 3 finished with value: 0.8527093596059114 and parameters: {'learning_rate': 0.050106836435088974, 'n_estimators': 287, 'max_depth': 8, 'min_samples_split': 15, 'min_samples_leaf': 6, 'max_features': 0.635739826126963, 'subsample': 0.9825967495722868}. Best is trial 0 with value: 0.8593596059113301.\n",
            "[I 2024-06-22 13:46:57,796] Trial 4 finished with value: 0.8527093596059114 and parameters: {'learning_rate': 0.014852727766831846, 'n_estimators': 244, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 16, 'max_features': 0.848321758289482, 'subsample': 0.9516978279786796}. Best is trial 0 with value: 0.8593596059113301.\n",
            "[I 2024-06-22 13:46:57,865] Trial 5 finished with value: 0.8596059113300493 and parameters: {'learning_rate': 0.2702920695136603, 'n_estimators': 307, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 13, 'max_features': 0.8122244385643091, 'subsample': 0.8022010961666519}. Best is trial 5 with value: 0.8596059113300493.\n",
            "[I 2024-06-22 13:46:59,696] Trial 7 finished with value: 0.8524630541871921 and parameters: {'learning_rate': 0.127786603095633, 'n_estimators': 252, 'max_depth': 4, 'min_samples_split': 11, 'min_samples_leaf': 8, 'max_features': 0.6770390094697102, 'subsample': 0.8867536178261791}. Best is trial 5 with value: 0.8596059113300493.\n",
            "[I 2024-06-22 13:46:59,865] Trial 6 finished with value: 0.8596059113300493 and parameters: {'learning_rate': 0.045136389002854896, 'n_estimators': 500, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 9, 'max_features': 0.8712639434951243, 'subsample': 0.7952501587129508}. Best is trial 5 with value: 0.8596059113300493.\n",
            "[I 2024-06-22 13:47:01,451] Trial 8 finished with value: 0.8527093596059114 and parameters: {'learning_rate': 0.02180831603377515, 'n_estimators': 355, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 13, 'max_features': 0.8420228983190919, 'subsample': 0.627035171943059}. Best is trial 5 with value: 0.8596059113300493.\n",
            "[I 2024-06-22 13:47:01,494] Trial 9 finished with value: 0.8527093596059114 and parameters: {'learning_rate': 0.010978364780275732, 'n_estimators': 278, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 0.806401659694704, 'subsample': 0.8755001055094691}. Best is trial 5 with value: 0.8596059113300493.\n",
            "[I 2024-06-22 13:47:02,922] Trial 10 finished with value: 0.8596059113300493 and parameters: {'learning_rate': 0.07071539385141772, 'n_estimators': 147, 'max_depth': 5, 'min_samples_split': 19, 'min_samples_leaf': 4, 'max_features': 0.6426373519898781, 'subsample': 0.6280214656755742}. Best is trial 5 with value: 0.8596059113300493.\n",
            "[I 2024-06-22 13:47:03,311] Trial 11 finished with value: 0.8596059113300493 and parameters: {'learning_rate': 0.2745114071042545, 'n_estimators': 447, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 20, 'max_features': 0.9843839559995268, 'subsample': 0.7518696966657724}. Best is trial 5 with value: 0.8596059113300493.\n",
            "[W 2024-06-22 13:47:04,245] Trial 12 failed with parameters: {'learning_rate': 0.22851529643124222, 'n_estimators': 500, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 20, 'max_features': 0.975632593611122, 'subsample': 0.7561580897658549} because of the following error: KeyboardInterrupt().\n",
            "joblib.externals.loky.process_executor._RemoteTraceback: \n",
            "\"\"\"\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py\", line 463, in _process_worker\n",
            "    r = call_item()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n",
            "    return self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 598, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 598, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py\", line 538, in fit\n",
            "    n_stages = self._fit_stages(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py\", line 615, in _fit_stages\n",
            "    raw_predictions = self._fit_stage(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py\", line 257, in _fit_stage\n",
            "    tree.fit(X, residual, sample_weight=sample_weight, check_input=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
            "    super().fit(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\", line 177, in fit\n",
            "    self._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 600, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 77, in validate_parameter_constraints\n",
            "    if constraint.is_satisfied_by(param_val):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 471, in is_satisfied_by\n",
            "    return val in self\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 447, in __contains__\n",
            "    if np.isnan(val):\n",
            "KeyboardInterrupt\n",
            "\"\"\"\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-49-3a260869256e>\", line 66, in objective\n",
            "    cv_scores = cross_val_score(model, X_val_meta, y_val, cv=5, scoring='accuracy', n_jobs=-1)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 515, in cross_val_score\n",
            "    cv_results = cross_validate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 266, in cross_validate\n",
            "    results = parallel(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 2007, in __call__\n",
            "    return output if self.return_generator else list(output)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1650, in _get_outputs\n",
            "    yield from self._retrieve()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1754, in _retrieve\n",
            "    self._raise_error_fast()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1789, in _raise_error_fast\n",
            "    error_job.get_result(self.timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 745, in get_result\n",
            "    return self._return_or_raise()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 763, in _return_or_raise\n",
            "    raise self._result\n",
            "KeyboardInterrupt\n",
            "[W 2024-06-22 13:47:04,249] Trial 12 failed with value None.\n",
            "[W 2024-06-22 13:47:04,246] Trial 13 failed with parameters: {'learning_rate': 0.12326846175923412, 'n_estimators': 495, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 9, 'max_features': 0.9269518257689392, 'subsample': 0.7700994115384419} because of the following error: KeyboardInterrupt().\n",
            "joblib.externals.loky.process_executor._RemoteTraceback: \n",
            "\"\"\"\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py\", line 463, in _process_worker\n",
            "    r = call_item()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n",
            "    return self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 598, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 598, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py\", line 538, in fit\n",
            "    n_stages = self._fit_stages(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py\", line 615, in _fit_stages\n",
            "    raw_predictions = self._fit_stage(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py\", line 257, in _fit_stage\n",
            "    tree.fit(X, residual, sample_weight=sample_weight, check_input=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
            "    super().fit(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\", line 351, in fit\n",
            "    self.tree_ = Tree(\n",
            "  File \"sklearn/tree/_tree.pyx\", line 624, in sklearn.tree._tree.Tree.__cinit__\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\", line 2687, in _max_dispatcher\n",
            "    def _max_dispatcher(a, axis=None, out=None, keepdims=None, initial=None,\n",
            "KeyboardInterrupt\n",
            "\"\"\"\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-49-3a260869256e>\", line 66, in objective\n",
            "    cv_scores = cross_val_score(model, X_val_meta, y_val, cv=5, scoring='accuracy', n_jobs=-1)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 515, in cross_val_score\n",
            "    cv_results = cross_validate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 266, in cross_validate\n",
            "    results = parallel(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 2007, in __call__\n",
            "    return output if self.return_generator else list(output)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1650, in _get_outputs\n",
            "    yield from self._retrieve()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1754, in _retrieve\n",
            "    self._raise_error_fast()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1789, in _raise_error_fast\n",
            "    error_job.get_result(self.timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 745, in get_result\n",
            "    return self._return_or_raise()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 763, in _return_or_raise\n",
            "    raise self._result\n",
            "KeyboardInterrupt\n",
            "[W 2024-06-22 13:47:04,259] Trial 13 failed with value None.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-3a260869256e>\u001b[0m in \u001b[0;36m<cell line: 71>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;31m# Create an Optuna study and optimize the objective function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTPESampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;31m# Get the best hyperparameters from the study\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \"\"\"\n\u001b[0;32m--> 451\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    452\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                         \u001b[0mcompleted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfutures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_when\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFIRST_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m                         \u001b[0;31m# Raise if exception occurred in executing the completed futures.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcompleted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(fs, timeout, return_when)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0mwaiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_and_install_waiters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_when\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m     \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from catboost import CatBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "\n",
        "# Assuming df_train, top_features_cumulative are defined appropriately\n",
        "\n",
        "# Split the data into train, test, and validation sets with stratification\n",
        "X = df_train[top_features_cumulative]\n",
        "y = df_train['winner']\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "# Define the individual models with their best parameters\n",
        "catboost_params = {'depth': 4, 'iterations': 131, 'l2_leaf_reg': 9, 'learning_rate': 0.026746858922480903, 'subsample': 0.9806922046593372, 'bagging_temperature': 0.863851083829466, 'border_count': 79, 'one_hot_max_size': 10}\n",
        "xgboost_params = {'max_depth': 5, 'n_estimators': 269, 'learning_rate': 0.1497059900832021, 'subsample': 0.6134373870090926, 'colsample_bytree': 0.8655799077621021, 'gamma': 3.39838763588673, 'min_child_weight': 10, 'reg_alpha': 5.895160858400561, 'reg_lambda': 2.0436192434364866}\n",
        "lightgbm_params = {'max_depth': 3, 'num_leaves': 165, 'learning_rate': 0.15387125194824516, 'subsample': 0.7701573425754059, 'colsample_bytree': 0.8740741726764223, 'reg_alpha': 5.967689395391898, 'reg_lambda': 5.552505199267917, 'n_estimators': 294}\n",
        "gbm_params = {'learning_rate': 0.013177244157007226, 'n_estimators': 223, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 10, 'max_features': 0.677756768922895}\n",
        "\n",
        "cat_model = CatBoostClassifier(**catboost_params, verbose=False)\n",
        "xgb_model = XGBClassifier(**xgboost_params)\n",
        "lgb_model = LGBMClassifier(**lightgbm_params)\n",
        "gbm_model = GradientBoostingClassifier(**gbm_params)\n",
        "\n",
        "# Train the individual models on the training set\n",
        "cat_model.fit(X_train, y_train)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "lgb_model.fit(X_train, y_train)\n",
        "gbm_model.fit(X_train, y_train)\n",
        "\n",
        "# Get the predictions on the validation set for the meta-model\n",
        "X_val_meta = pd.DataFrame({\n",
        "    'cat_pred': cat_model.predict(X_val),\n",
        "    'xgb_pred': xgb_model.predict(X_val),\n",
        "    'lgb_pred': lgb_model.predict(X_val),\n",
        "    'gbm_pred': gbm_model.predict(X_val)\n",
        "})\n",
        "\n",
        "# Get the predictions on the test set for the meta-model\n",
        "X_test_meta = pd.DataFrame({\n",
        "    'cat_pred': cat_model.predict(X_test),\n",
        "    'xgb_pred': xgb_model.predict(X_test),\n",
        "    'lgb_pred': lgb_model.predict(X_test),\n",
        "    'gbm_pred': gbm_model.predict(X_test)\n",
        "})\n",
        "\n",
        "# Define the objective function for tuning the meta-model using Optuna\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
        "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n",
        "        'max_features': trial.suggest_float('max_features', 0.6, 1.0),\n",
        "        'subsample': trial.suggest_float('subsample', 0.6, 1.0)\n",
        "    }\n",
        "\n",
        "    model = GradientBoostingClassifier(**params)\n",
        "    cv_scores = cross_val_score(model, X_val_meta, y_val, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "    return cv_scores.mean()\n",
        "\n",
        "# Create an Optuna study and optimize the objective function\n",
        "study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=42))\n",
        "study.optimize(objective, n_trials=100, n_jobs=-1)\n",
        "\n",
        "# Get the best hyperparameters from the study\n",
        "best_params = study.best_params\n",
        "print(f\"Best hyperparameters for meta-model: {best_params}\")\n",
        "\n",
        "# Train the final meta-model with the best hyperparameters\n",
        "final_meta_model = GradientBoostingClassifier(**best_params)\n",
        "final_meta_model.fit(X_val_meta, y_val)\n",
        "\n",
        "# Perform cross-validation on the validation set\n",
        "cv_scores = cross_val_score(final_meta_model, X_val_meta, y_val, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "print(f\"CV Scores - Avg: {cv_scores.mean()}, Min: {cv_scores.min()}, Max: {cv_scores.max()}\")\n",
        "\n",
        "# Evaluate the meta-model on the test set\n",
        "y_pred_test = final_meta_model.predict(X_test_meta)\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "# Print final results\n",
        "print(f\"Best Parameters for Meta-Model: {best_params}\")\n",
        "print(f\"CV Scores - Avg: {cv_scores.mean()}, Min: {cv_scores.min()}, Max: {cv_scores.max()}\")\n",
        "print(f\"Test Accuracy: {test_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lo5I6XtwNKvs"
      },
      "outputs": [],
      "source": [
        "# catboost for meta\n",
        "# Best Parameters for Meta-Model: {'depth': 10, 'iterations': 170, 'l2_leaf_reg': 8, 'learning_rate': 0.19754009744506684, 'subsample': 0.693889750789011, 'bagging_temperature': 0.5974660864197161, 'border_count': 72, 'one_hot_max_size': 16}\n",
        "# CV Scores - Avg: 0.8381773399014778, Min: 0.7586206896551724, Max: 0.896551724137931\n",
        "# Test Accuracy: 0.8671328671328671\n",
        "\n",
        "# xgboost for meta\n",
        "# Best Parameters for Meta-Model: {'max_depth': 9, 'n_estimators': 165, 'learning_rate': 0.21323373869865603, 'subsample': 0.8856962475019171, 'colsample_bytree': 0.6529010969767698, 'gamma': 8.739047749346323, 'min_child_weight': 5, 'reg_alpha': 6.982480429419232, 'reg_lambda': 2.141380812210051}\n",
        "# CV Scores - Avg: 0.845320197044335, Min: 0.7586206896551724, Max: 0.896551724137931\n",
        "# Test Accuracy: 0.8671328671328671\n",
        "\n",
        "# lightgbm for meta\n",
        "# Best Parameters for Meta-Model: {'max_depth': 9, 'num_leaves': 99, 'learning_rate': 0.02596036767057364, 'n_estimators': 364, 'subsample': 0.7214202982512115, 'colsample_bytree': 0.7404036334273929, 'reg_alpha': 4.7369115877798835, 'reg_lambda': 4.512847778182012, 'min_split_gain': 0.07197691915767544, 'min_child_weight': 9.019499870586479}\n",
        "# CV Scores - Avg: 0.8238916256157636, Min: 0.7586206896551724, Max: 0.896551724137931\n",
        "# Test Accuracy: 0.8671328671328671\n",
        "\n",
        "# gbm for meta\n",
        "# Best Parameters for Meta-Model: {'learning_rate': 0.018022156863544952, 'n_estimators': 227, 'max_depth': 10, 'min_samples_split': 13, 'min_samples_leaf': 9, 'max_features': 0.7353486667006071, 'subsample': 0.7140887887708872}\n",
        "# CV Scores - Avg: 0.8238916256157636, Min: 0.7586206896551724, Max: 0.896551724137931\n",
        "# Test Accuracy: 0.8671328671328671"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvbNmuoV2rHl",
        "outputId": "3f0bad8a-7d35-4f45-8f6d-5f4dd3d52a8f",
        "collapsed": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 282, number of negative: 286\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002886 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 19615\n",
            "[LightGBM] [Info] Number of data points in the train set: 568, number of used features: 178\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496479 -> initscore=-0.014085\n",
            "[LightGBM] [Info] Start training from score -0.014085\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "CV Scores - Avg: 0.8789473684210527, Min: 0.8157894736842105, Max: 0.9210526315789473\n",
            "Best Parameters for Meta-Model: {'max_depth': 9, 'n_estimators': 165, 'learning_rate': 0.21323373869865603, 'subsample': 0.8856962475019171, 'colsample_bytree': 0.6529010969767698, 'gamma': 8.739047749346323, 'min_child_weight': 5, 'reg_alpha': 6.982480429419232, 'reg_lambda': 2.141380812210051}\n",
            "CV Scores - Avg: 0.8789473684210527, Min: 0.8157894736842105, Max: 0.9210526315789473\n",
            "Test Accuracy: 0.9\n",
            "Test F1 Score: 0.8983957219251337\n",
            "Test Precision: 0.9032258064516129\n",
            "Test Recall: 0.8936170212765957\n",
            "Confusion Matrix:\n",
            "[[87  9]\n",
            " [10 84]]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "from catboost import CatBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Assuming df_train, top_features_cumulative are defined appropriately\n",
        "\n",
        "# Split the data into train, test, and validation sets with stratification\n",
        "# X = df_train[top_features_cumulative]\n",
        "# y = df_train['winner']\n",
        "# Select numerical columns\n",
        "numerical_cols = df_train.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "# Exclude the target column from numerical_cols if needed\n",
        "if 'winner' in numerical_cols:\n",
        "    numerical_cols = numerical_cols.drop('winner')\n",
        "\n",
        "# Exclude additional columns if necessary\n",
        "numerical_cols = numerical_cols.drop(['team1_id', 'team2_id', 'ground_id', 'match id'])\n",
        "\n",
        "# Split the data into train, test, and validation sets with stratification\n",
        "X = df_train[numerical_cols]\n",
        "y = df_train['winner']\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "# Define the individual models with their best parameters\n",
        "catboost_params = {'depth': 4, 'iterations': 131, 'l2_leaf_reg': 9, 'learning_rate': 0.026746858922480903, 'subsample': 0.9806922046593372, 'bagging_temperature': 0.863851083829466, 'border_count': 79, 'one_hot_max_size': 10}\n",
        "xgboost_params = {'max_depth': 5, 'n_estimators': 269, 'learning_rate': 0.1497059900832021, 'subsample': 0.6134373870090926, 'colsample_bytree': 0.8655799077621021, 'gamma': 3.39838763588673, 'min_child_weight': 10, 'reg_alpha': 5.895160858400561, 'reg_lambda': 2.0436192434364866}\n",
        "lightgbm_params = {'max_depth': 3, 'num_leaves': 165, 'learning_rate': 0.15387125194824516, 'subsample': 0.7701573425754059, 'colsample_bytree': 0.8740741726764223, 'reg_alpha': 5.967689395391898, 'reg_lambda': 5.552505199267917, 'n_estimators': 294}\n",
        "gbm_params = {'learning_rate': 0.013177244157007226, 'n_estimators': 223, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 10, 'max_features': 0.677756768922895}\n",
        "\n",
        "cat_model = CatBoostClassifier(**catboost_params, verbose=False)\n",
        "xgb_model = XGBClassifier(**xgboost_params)\n",
        "lgb_model = LGBMClassifier(**lightgbm_params)\n",
        "gbm_model = GradientBoostingClassifier(**gbm_params)\n",
        "\n",
        "# Train the individual models on the training set\n",
        "cat_model.fit(X_train, y_train)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "lgb_model.fit(X_train, y_train)\n",
        "gbm_model.fit(X_train, y_train)\n",
        "\n",
        "# Get the predictions on the validation set for the meta-model\n",
        "X_val_meta = pd.DataFrame({\n",
        "    'cat_pred': cat_model.predict(X_val),\n",
        "    'xgb_pred': xgb_model.predict(X_val),\n",
        "    'lgb_pred': lgb_model.predict(X_val),\n",
        "    'gbm_pred': gbm_model.predict(X_val)\n",
        "})\n",
        "\n",
        "# Get the predictions on the test set for the meta-model\n",
        "X_test_meta = pd.DataFrame({\n",
        "    'cat_pred': cat_model.predict(X_test),\n",
        "    'xgb_pred': xgb_model.predict(X_test),\n",
        "    'lgb_pred': lgb_model.predict(X_test),\n",
        "    'gbm_pred': gbm_model.predict(X_test)\n",
        "})\n",
        "\n",
        "# Best Parameters for Meta-Model\n",
        "meta_model_params = {\n",
        "    'max_depth': 9,\n",
        "    'n_estimators': 165,\n",
        "    'learning_rate': 0.21323373869865603,\n",
        "    'subsample': 0.8856962475019171,\n",
        "    'colsample_bytree': 0.6529010969767698,\n",
        "    'gamma': 8.739047749346323,\n",
        "    'min_child_weight': 5,\n",
        "    'reg_alpha': 6.982480429419232,\n",
        "    'reg_lambda': 2.141380812210051\n",
        "}\n",
        "\n",
        "# Train the final meta-model with the best hyperparameters\n",
        "final_meta_model = XGBClassifier(**meta_model_params)\n",
        "final_meta_model.fit(X_val_meta, y_val)\n",
        "\n",
        "# Perform cross-validation on the validation set\n",
        "cv_scores = cross_val_score(final_meta_model, X_val_meta, y_val, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "print(f\"CV Scores - Avg: {cv_scores.mean()}, Min: {cv_scores.min()}, Max: {cv_scores.max()}\")\n",
        "\n",
        "# Evaluate the meta-model on the test set\n",
        "y_pred_test = final_meta_model.predict(X_test_meta)\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "test_f1 = f1_score(y_test, y_pred_test)\n",
        "test_precision = precision_score(y_test, y_pred_test)\n",
        "test_recall = recall_score(y_test, y_pred_test)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_test)\n",
        "\n",
        "# Print final results\n",
        "print(f\"Best Parameters for Meta-Model: {meta_model_params}\")\n",
        "print(f\"CV Scores - Avg: {cv_scores.mean()}, Min: {cv_scores.min()}, Max: {cv_scores.max()}\")\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n",
        "print(f\"Test F1 Score: {test_f1}\")\n",
        "print(f\"Test Precision: {test_precision}\")\n",
        "print(f\"Test Recall: {test_recall}\")\n",
        "print(f\"Confusion Matrix:\\n{conf_matrix}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WREKI1xmriVA"
      },
      "outputs": [],
      "source": [
        "# CV Scores - Avg: 0.8596059113300493, Min: 0.7931034482758621, Max: 0.9285714285714286\n",
        "# Test Accuracy: 0.8671328671328671"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6mhOLViPK-2",
        "outputId": "5d47f9fa-d2f1-42d7-a6b7-707f8bb819bc",
        "collapsed": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 329, number of negative: 334\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005789 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 14682\n",
            "[LightGBM] [Info] Number of data points in the train set: 663, number of used features: 95\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496229 -> initscore=-0.015083\n",
            "[LightGBM] [Info] Start training from score -0.015083\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "Best Parameters for Meta-Model: {'max_depth': 9, 'n_estimators': 165, 'learning_rate': 0.21323373869865603, 'subsample': 0.8856962475019171, 'colsample_bytree': 0.6529010969767698, 'gamma': 8.739047749346323, 'min_child_weight': 5, 'reg_alpha': 6.982480429419232, 'reg_lambda': 2.141380812210051}\n",
            "Test Accuracy: 0.5017543859649123\n",
            "Test F1 Score: 0.0\n",
            "Test Precision: 0.0\n",
            "Test Recall: 0.0\n",
            "Confusion Matrix:\n",
            "[[143   0]\n",
            " [142   0]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "from catboost import CatBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Assuming df_train, top_features_cumulative are defined appropriately\n",
        "\n",
        "# Split the data into train and test sets with stratification\n",
        "X = df_train[top_features_cumulative]\n",
        "y = df_train['winner']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Define the individual models with their best parameters\n",
        "catboost_params = {'depth': 4, 'iterations': 131, 'l2_leaf_reg': 9, 'learning_rate': 0.026746858922480903, 'subsample': 0.9806922046593372, 'bagging_temperature': 0.863851083829466, 'border_count': 79, 'one_hot_max_size': 10}\n",
        "xgboost_params = {'max_depth': 5, 'n_estimators': 269, 'learning_rate': 0.1497059900832021, 'subsample': 0.6134373870090926, 'colsample_bytree': 0.8655799077621021, 'gamma': 3.39838763588673, 'min_child_weight': 10, 'reg_alpha': 5.895160858400561, 'reg_lambda': 2.0436192434364866}\n",
        "lightgbm_params = {'max_depth': 3, 'num_leaves': 165, 'learning_rate': 0.15387125194824516, 'subsample': 0.7701573425754059, 'colsample_bytree': 0.8740741726764223, 'reg_alpha': 5.967689395391898, 'reg_lambda': 5.552505199267917, 'n_estimators': 294}\n",
        "gbm_params = {'learning_rate': 0.013177244157007226, 'n_estimators': 223, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 10, 'max_features': 0.677756768922895}\n",
        "\n",
        "cat_model = CatBoostClassifier(**catboost_params, verbose=False)\n",
        "xgb_model = XGBClassifier(**xgboost_params)\n",
        "lgb_model = LGBMClassifier(**lightgbm_params)\n",
        "gbm_model = GradientBoostingClassifier(**gbm_params)\n",
        "\n",
        "# Train the individual models on the training set\n",
        "cat_model.fit(X_train, y_train)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "lgb_model.fit(X_train, y_train)\n",
        "gbm_model.fit(X_train, y_train)\n",
        "\n",
        "# Get the predictions on the test set for the meta-model\n",
        "X_test_meta = pd.DataFrame({\n",
        "    'cat_pred': cat_model.predict(X_test),\n",
        "    'xgb_pred': xgb_model.predict(X_test),\n",
        "    'lgb_pred': lgb_model.predict(X_test),\n",
        "    'gbm_pred': gbm_model.predict(X_test)\n",
        "})\n",
        "\n",
        "# Best Parameters for Meta-Model\n",
        "meta_model_params = {\n",
        "    'max_depth': 9,\n",
        "    'n_estimators': 165,\n",
        "    'learning_rate': 0.21323373869865603,\n",
        "    'subsample': 0.8856962475019171,\n",
        "    'colsample_bytree': 0.6529010969767698,\n",
        "    'gamma': 8.739047749346323,\n",
        "    'min_child_weight': 5,\n",
        "    'reg_alpha': 6.982480429419232,\n",
        "    'reg_lambda': 2.141380812210051\n",
        "}\n",
        "\n",
        "# Train the final meta-model with the best hyperparameters\n",
        "final_meta_model = XGBClassifier(**meta_model_params)\n",
        "final_meta_model.fit(X_test_meta, y_test)\n",
        "\n",
        "# Evaluate the meta-model on the test set\n",
        "y_pred_test = final_meta_model.predict(X_test_meta)\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "test_f1 = f1_score(y_test, y_pred_test)\n",
        "test_precision = precision_score(y_test, y_pred_test)\n",
        "test_recall = recall_score(y_test, y_pred_test)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_test)\n",
        "\n",
        "# Print final results\n",
        "print(f\"Best Parameters for Meta-Model: {meta_model_params}\")\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n",
        "print(f\"Test F1 Score: {test_f1}\")\n",
        "print(f\"Test Precision: {test_precision}\")\n",
        "print(f\"Test Recall: {test_recall}\")\n",
        "print(f\"Confusion Matrix:\\n{conf_matrix}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uxu0AVVGH_WO",
        "outputId": "baaf8089-dbec-405f-a30d-c9fb28707798"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(948, 194)\n"
          ]
        }
      ],
      "source": [
        "df_train['pred_winner'] = final_meta_model.predict(pd.DataFrame({\n",
        "    'cat_pred': cat_model.predict_proba(df_train[top_features_cumulative])[:, 1],\n",
        "    'xgb_pred': xgb_model.predict_proba(df_train[top_features_cumulative])[:, 1],\n",
        "    'lgb_pred': lgb_model.predict_proba(df_train[top_features_cumulative])[:, 1],\n",
        "    'gbm_pred': gbm_model.predict_proba(df_train[top_features_cumulative])[:, 1]\n",
        "}))\n",
        "\n",
        "df_train['pred_winner_score'] = final_meta_model.predict_proba(pd.DataFrame({\n",
        "    'cat_pred': cat_model.predict_proba(df_train[top_features_cumulative])[:, 1],\n",
        "    'xgb_pred': xgb_model.predict_proba(df_train[top_features_cumulative])[:, 1],\n",
        "    'lgb_pred': lgb_model.predict_proba(df_train[top_features_cumulative])[:, 1],\n",
        "    'gbm_pred': gbm_model.predict_proba(df_train[top_features_cumulative])[:, 1]\n",
        "}))[:, 1]\n",
        "\n",
        "df_train['pred_winner_id'] = df_train.apply(\n",
        "    lambda row: row['team1_id'] if row['pred_winner'] == 1 else row['team2_id'], axis=1\n",
        ")\n",
        "\n",
        "print(df_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckmXXKSh5D3P",
        "outputId": "d97a878d-d10f-43f5-ff35-3b36aae1976c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(271, 193)\n"
          ]
        }
      ],
      "source": [
        "test_data['pred_winner'] = final_meta_model.predict(pd.DataFrame({\n",
        "    'cat_pred': cat_model.predict_proba(test_data[top_features_cumulative])[:, 1],\n",
        "    'xgb_pred': xgb_model.predict_proba(test_data[top_features_cumulative])[:, 1],\n",
        "    'lgb_pred': lgb_model.predict_proba(test_data[top_features_cumulative])[:, 1],\n",
        "    'gbm_pred': gbm_model.predict_proba(test_data[top_features_cumulative])[:, 1]\n",
        "}))\n",
        "\n",
        "test_data['pred_winner_score'] = final_meta_model.predict_proba(pd.DataFrame({\n",
        "    'cat_pred': cat_model.predict_proba(test_data[top_features_cumulative])[:, 1],\n",
        "    'xgb_pred': xgb_model.predict_proba(test_data[top_features_cumulative])[:, 1],\n",
        "    'lgb_pred': lgb_model.predict_proba(test_data[top_features_cumulative])[:, 1],\n",
        "    'gbm_pred': gbm_model.predict_proba(test_data[top_features_cumulative])[:, 1]\n",
        "}))[:, 1]\n",
        "\n",
        "test_data['pred_winner_id'] = test_data.apply(\n",
        "    lambda row: row['team1_id'] if row['pred_winner'] == 1 else row['team2_id'], axis=1\n",
        ")\n",
        "\n",
        "print(test_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXDhCknb3yPm"
      },
      "outputs": [],
      "source": [
        "# catboost_params = {'depth': 4, 'iterations': 131, 'l2_leaf_reg': 9, 'learning_rate': 0.026746858922480903, 'subsample': 0.9806922046593372, 'bagging_temperature': 0.863851083829466, 'border_count': 79, 'one_hot_max_size': 10}\n",
        "# xgboost_params = {'max_depth': 5, 'n_estimators': 269, 'learning_rate': 0.1497059900832021, 'subsample': 0.6134373870090926, 'colsample_bytree': 0.8655799077621021, 'gamma': 3.39838763588673, 'min_child_weight': 10, 'reg_alpha': 5.895160858400561, 'reg_lambda': 2.0436192434364866}\n",
        "# lightgbm_params = {'max_depth': 3, 'num_leaves': 165, 'learning_rate': 0.15387125194824516, 'subsample': 0.7701573425754059, 'colsample_bytree': 0.8740741726764223, 'reg_alpha': 5.967689395391898, 'reg_lambda': 5.552505199267917, 'n_estimators': 294}\n",
        "# gbm_params = {'learning_rate': 0.013177244157007226, 'n_estimators': 223, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 10, 'max_features': 0.677756768922895}\n",
        "# Best Parameters for Meta-Model: {'max_depth': 9, 'n_estimators': 165, 'learning_rate': 0.21323373869865603, 'subsample': 0.8856962475019171, 'colsample_bytree': 0.6529010969767698, 'gamma': 8.739047749346323, 'min_child_weight': 5, 'reg_alpha': 6.982480429419232, 'reg_lambda': 2.141380812210051}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmllT_-_awiv"
      },
      "outputs": [],
      "source": [
        "df_train['dataset_type'] = 'train'\n",
        "test_data['dataset_type'] = 'r1'\n",
        "algo_name = 'CatBoost;XGBoost;LightGBM;GBM;CatBoost'\n",
        "is_ensemble = 'yes'\n",
        "n_trees = '131;269;294;223;165'\n",
        "depth = '4;5;3;3;9'\n",
        "lr = '0.026746858922480903;0.1497059900832021;0.15387125194824516;0.013177244157007226;0.21323373869865603'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXh3qU4bdWlw",
        "outputId": "c41af6f7-9286-4c20-c696-cf9e6dd122ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                           feat_name  model_feat_imp_train\n",
            "0  team1_day/night match_runs_avg - team2_day/nig...              6.203185\n",
            "1                           victory_by_wickets_team2              4.759981\n",
            "2                              nrr_team1 - nrr_team2              4.621072\n",
            "3                             inning1_avg_runs_team1              4.463710\n",
            "4                          inning1_avg_wickets_team1              4.417557\n",
            "5                       Sum_of_BowlerAbilities_team1              4.319368\n",
            "6                          inning2_avg_wickets_team2              4.268900\n",
            "7                           team_count_50runs_last15              3.877238\n",
            "8                       avg_inning2_runs_venue_last5              3.806339\n",
            "9                      Sum_of_BatsmanAbilities_team2              3.805220\n"
          ]
        }
      ],
      "source": [
        "# Get feature importances from each model\n",
        "ft_imp_cat = pd.DataFrame({'Feature': top_features_cumulative, 'Importance': cat_model.get_feature_importance()})\n",
        "ft_imp_xgb = pd.DataFrame({'Feature': top_features_cumulative, 'Importance': xgb_model.feature_importances_})\n",
        "ft_imp_lgbm = pd.DataFrame({'Feature': top_features_cumulative, 'Importance': lgb_model.feature_importances_})\n",
        "ft_imp_gbm = pd.DataFrame({'Feature': top_features_cumulative, 'Importance': gbm_model.feature_importances_})\n",
        "\n",
        "# Concatenate all feature importance DataFrames\n",
        "all_importances = pd.concat([ft_imp_cat, ft_imp_xgb, ft_imp_lgbm, ft_imp_gbm])\n",
        "\n",
        "# Calculate average importance across models\n",
        "df_avg_importance = all_importances.groupby('Feature')['Importance'].mean().reset_index()\n",
        "\n",
        "# Sort by average importance in descending order and select top 10 features\n",
        "df_avg_importance = df_avg_importance.sort_values(by='Importance', ascending=False).reset_index(drop=True).head(10)\n",
        "\n",
        "# Rename columns as per requirement\n",
        "df_feat_importance = df_avg_importance.rename(columns={'Feature': 'feat_name', 'Importance': 'model_feat_imp_train'}).head(10)\n",
        "\n",
        "# Display the final DataFrame with top 10 features and their average importance\n",
        "# print(ft_imp_cat)\n",
        "# print(ft_imp_lgbm)\n",
        "print(df_feat_importance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rJWNlLpgENA"
      },
      "outputs": [],
      "source": [
        "df_file1 = pd.concat([test_data[['match id','dataset_type','pred_winner_id','pred_winner_score',] + list(df_feat_importance['feat_name'].head(10))], \\\n",
        "                     df_train[['match id','dataset_type','pred_winner_id','pred_winner_score',] + list(df_feat_importance['feat_name'].head(10))]])\n",
        "\n",
        "renaming_dict = {}\n",
        "for i,col in enumerate(list(df_feat_importance['feat_name'].head(10))):\n",
        "    renaming_dict[col] = f'indep_feat_id{i+1}'\n",
        "df_file1.rename(columns=renaming_dict, inplace=True)\n",
        "\n",
        "for i in range(1,11):\n",
        "    if f'indep_feat_id{i}' not in df_file1.columns:\n",
        "        df_file1[f'indep_feat_id{i}'] = np.nan\n",
        "\n",
        "df_file1['train_algorithm'] = algo_name\n",
        "df_file1['is_ensemble'] = is_ensemble\n",
        "df_file1['train_hps_trees'] = n_trees\n",
        "df_file1['train_hps_depth'] = depth\n",
        "df_file1['train_hps_lr'] = lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "jgAsQKXggSfw",
        "outputId": "9c250c59-a778-49b5-b0ed-5f90ce8af221"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1219, 19)\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_file1\",\n  \"rows\": 1219,\n  \"fields\": [\n    {\n      \"column\": \"match id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 227427,\n        \"min\": 8797053,\n        \"max\": 9887863,\n        \"num_unique_values\": 1219,\n        \"samples\": [\n          9680306,\n          9084802,\n          9457447\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dataset_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"train\",\n          \"r1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_winner_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17605,\n        \"min\": 20,\n        \"max\": 49657,\n        \"num_unique_values\": 152,\n        \"samples\": [\n          216,\n          46773\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_winner_score\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.4990357458591461\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"indep_feat_id1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 65.04098574501279,\n        \"min\": -198.0,\n        \"max\": 202.0,\n        \"num_unique_values\": 599,\n        \"samples\": [\n          11.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"indep_feat_id2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.2406549219858065,\n        \"min\": 0.0,\n        \"max\": 9.333333333333334,\n        \"num_unique_values\": 118,\n        \"samples\": [\n          5.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"indep_feat_id3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17214203459246027,\n        \"min\": -0.4754317184875465,\n        \"max\": 0.7637746171609414,\n        \"num_unique_values\": 1151,\n        \"samples\": [\n          0.3405097065456655\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"indep_feat_id4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 33.65510118461637,\n        \"min\": 0.0,\n        \"max\": 216.0,\n        \"num_unique_values\": 756,\n        \"samples\": [\n          153.8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"indep_feat_id5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.5312609167831877,\n        \"min\": 0.0,\n        \"max\": 10.0,\n        \"num_unique_values\": 209,\n        \"samples\": [\n          5.909090909090909\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"indep_feat_id6\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 46.01447665234377,\n        \"min\": -11.80006287031886,\n        \"max\": 309.9111951080728,\n        \"num_unique_values\": 1167,\n        \"samples\": [\n          216.94687304359388\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"indep_feat_id7\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7924852978457915,\n        \"min\": 0.0,\n        \"max\": 10.0,\n        \"num_unique_values\": 259,\n        \"samples\": [\n          5.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"indep_feat_id8\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9730973556109637,\n        \"min\": 0.0,\n        \"max\": 11.0,\n        \"num_unique_values\": 303,\n        \"samples\": [\n          1.095238095\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"indep_feat_id9\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 39.16099936287908,\n        \"min\": 0.0,\n        \"max\": 221.0,\n        \"num_unique_values\": 386,\n        \"samples\": [\n          153.33333333333334\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"indep_feat_id10\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 153.23626900485257,\n        \"min\": 0.0,\n        \"max\": 940.3256494774366,\n        \"num_unique_values\": 1188,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_algorithm\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"CatBoost;XGBoost;LightGBM;GBM;CatBoost\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_ensemble\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_hps_trees\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"131;269;294;223;165\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_hps_depth\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"4;5;3;3;9\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_hps_lr\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"0.026746858922480903;0.1497059900832021;0.15387125194824516;0.013177244157007226;0.21323373869865603\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_file1"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-11dc6b00-cc81-4d46-acf4-51ab2ad52e59\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>match id</th>\n",
              "      <th>dataset_type</th>\n",
              "      <th>pred_winner_id</th>\n",
              "      <th>pred_winner_score</th>\n",
              "      <th>indep_feat_id1</th>\n",
              "      <th>indep_feat_id2</th>\n",
              "      <th>indep_feat_id3</th>\n",
              "      <th>indep_feat_id4</th>\n",
              "      <th>indep_feat_id5</th>\n",
              "      <th>indep_feat_id6</th>\n",
              "      <th>indep_feat_id7</th>\n",
              "      <th>indep_feat_id8</th>\n",
              "      <th>indep_feat_id9</th>\n",
              "      <th>indep_feat_id10</th>\n",
              "      <th>train_algorithm</th>\n",
              "      <th>is_ensemble</th>\n",
              "      <th>train_hps_trees</th>\n",
              "      <th>train_hps_depth</th>\n",
              "      <th>train_hps_lr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9250275</td>\n",
              "      <td>r1</td>\n",
              "      <td>90</td>\n",
              "      <td>0.499036</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.358514</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>554.272445</td>\n",
              "      <td>CatBoost;XGBoost;LightGBM;GBM;CatBoost</td>\n",
              "      <td>yes</td>\n",
              "      <td>131;269;294;223;165</td>\n",
              "      <td>4;5;3;3;9</td>\n",
              "      <td>0.026746858922480903;0.1497059900832021;0.1538...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9262189</td>\n",
              "      <td>r1</td>\n",
              "      <td>36098</td>\n",
              "      <td>0.499036</td>\n",
              "      <td>0.00</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.336467</td>\n",
              "      <td>154.500000</td>\n",
              "      <td>7.666667</td>\n",
              "      <td>245.860811</td>\n",
              "      <td>6.777778</td>\n",
              "      <td>0.615385</td>\n",
              "      <td>150.0</td>\n",
              "      <td>718.410559</td>\n",
              "      <td>CatBoost;XGBoost;LightGBM;GBM;CatBoost</td>\n",
              "      <td>yes</td>\n",
              "      <td>131;269;294;223;165</td>\n",
              "      <td>4;5;3;3;9</td>\n",
              "      <td>0.026746858922480903;0.1497059900832021;0.1538...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9128776</td>\n",
              "      <td>r1</td>\n",
              "      <td>48334</td>\n",
              "      <td>0.499036</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.219583</td>\n",
              "      <td>173.142857</td>\n",
              "      <td>6.111111</td>\n",
              "      <td>220.499792</td>\n",
              "      <td>8.600000</td>\n",
              "      <td>0.842105</td>\n",
              "      <td>161.2</td>\n",
              "      <td>713.790583</td>\n",
              "      <td>CatBoost;XGBoost;LightGBM;GBM;CatBoost</td>\n",
              "      <td>yes</td>\n",
              "      <td>131;269;294;223;165</td>\n",
              "      <td>4;5;3;3;9</td>\n",
              "      <td>0.026746858922480903;0.1497059900832021;0.1538...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9586919</td>\n",
              "      <td>r1</td>\n",
              "      <td>36112</td>\n",
              "      <td>0.499036</td>\n",
              "      <td>0.00</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.437987</td>\n",
              "      <td>179.454545</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>219.782624</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>142.6</td>\n",
              "      <td>701.656972</td>\n",
              "      <td>CatBoost;XGBoost;LightGBM;GBM;CatBoost</td>\n",
              "      <td>yes</td>\n",
              "      <td>131;269;294;223;165</td>\n",
              "      <td>4;5;3;3;9</td>\n",
              "      <td>0.026746858922480903;0.1497059900832021;0.1538...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9128538</td>\n",
              "      <td>r1</td>\n",
              "      <td>48341</td>\n",
              "      <td>0.499036</td>\n",
              "      <td>86.25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.123146</td>\n",
              "      <td>180.214286</td>\n",
              "      <td>6.142857</td>\n",
              "      <td>204.304778</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>2.375000</td>\n",
              "      <td>155.0</td>\n",
              "      <td>675.124302</td>\n",
              "      <td>CatBoost;XGBoost;LightGBM;GBM;CatBoost</td>\n",
              "      <td>yes</td>\n",
              "      <td>131;269;294;223;165</td>\n",
              "      <td>4;5;3;3;9</td>\n",
              "      <td>0.026746858922480903;0.1497059900832021;0.1538...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11dc6b00-cc81-4d46-acf4-51ab2ad52e59')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-11dc6b00-cc81-4d46-acf4-51ab2ad52e59 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-11dc6b00-cc81-4d46-acf4-51ab2ad52e59');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-02c60136-7995-4693-9cdc-6d8f3ae649d1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-02c60136-7995-4693-9cdc-6d8f3ae649d1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-02c60136-7995-4693-9cdc-6d8f3ae649d1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   match id dataset_type  pred_winner_id  pred_winner_score  indep_feat_id1  \\\n",
              "0   9250275           r1              90           0.499036            0.00   \n",
              "1   9262189           r1           36098           0.499036            0.00   \n",
              "2   9128776           r1           48334           0.499036           -0.75   \n",
              "3   9586919           r1           36112           0.499036            0.00   \n",
              "4   9128538           r1           48341           0.499036           86.25   \n",
              "\n",
              "   indep_feat_id2  indep_feat_id3  indep_feat_id4  indep_feat_id5  \\\n",
              "0             0.0        0.358514        0.000000        0.000000   \n",
              "1             5.0        0.336467      154.500000        7.666667   \n",
              "2             6.0        0.219583      173.142857        6.111111   \n",
              "3             4.0        0.437987      179.454545        6.000000   \n",
              "4             0.0        0.123146      180.214286        6.142857   \n",
              "\n",
              "   indep_feat_id6  indep_feat_id7  indep_feat_id8  indep_feat_id9  \\\n",
              "0        0.000000        6.000000        0.000000             0.0   \n",
              "1      245.860811        6.777778        0.615385           150.0   \n",
              "2      220.499792        8.600000        0.842105           161.2   \n",
              "3      219.782624        7.000000        0.285714           142.6   \n",
              "4      204.304778        7.000000        2.375000           155.0   \n",
              "\n",
              "   indep_feat_id10                         train_algorithm is_ensemble  \\\n",
              "0       554.272445  CatBoost;XGBoost;LightGBM;GBM;CatBoost         yes   \n",
              "1       718.410559  CatBoost;XGBoost;LightGBM;GBM;CatBoost         yes   \n",
              "2       713.790583  CatBoost;XGBoost;LightGBM;GBM;CatBoost         yes   \n",
              "3       701.656972  CatBoost;XGBoost;LightGBM;GBM;CatBoost         yes   \n",
              "4       675.124302  CatBoost;XGBoost;LightGBM;GBM;CatBoost         yes   \n",
              "\n",
              "       train_hps_trees train_hps_depth  \\\n",
              "0  131;269;294;223;165       4;5;3;3;9   \n",
              "1  131;269;294;223;165       4;5;3;3;9   \n",
              "2  131;269;294;223;165       4;5;3;3;9   \n",
              "3  131;269;294;223;165       4;5;3;3;9   \n",
              "4  131;269;294;223;165       4;5;3;3;9   \n",
              "\n",
              "                                        train_hps_lr  \n",
              "0  0.026746858922480903;0.1497059900832021;0.1538...  \n",
              "1  0.026746858922480903;0.1497059900832021;0.1538...  \n",
              "2  0.026746858922480903;0.1497059900832021;0.1538...  \n",
              "3  0.026746858922480903;0.1497059900832021;0.1538...  \n",
              "4  0.026746858922480903;0.1497059900832021;0.1538...  "
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_file1['pred_winner_id'] = df_file1['pred_winner_id'].astype('int64')\n",
        "print(df_file1.shape)\n",
        "df_file1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PY-A8fzWgUuw",
        "outputId": "9879cd3e-6684-480d-d732-26fbd0c62eed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                           feat_name  model_feat_imp_train\n",
            "0  team1_day/night match_runs_avg - team2_day/nig...              6.203185\n",
            "1                           victory_by_wickets_team2              4.759981\n",
            "2                              nrr_team1 - nrr_team2              4.621072\n",
            "3                             inning1_avg_runs_team1              4.463710\n",
            "4                          inning1_avg_wickets_team1              4.417557\n",
            "5                       Sum_of_BowlerAbilities_team1              4.319368\n",
            "6                          inning2_avg_wickets_team2              4.268900\n",
            "7                           team_count_50runs_last15              3.877238\n",
            "8                       avg_inning2_runs_venue_last5              3.806339\n",
            "9                      Sum_of_BatsmanAbilities_team2              3.805220\n"
          ]
        }
      ],
      "source": [
        "print(df_feat_importance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNJZJawkgnr_"
      },
      "outputs": [],
      "source": [
        "feature_desc = {\n",
        "    'team1_day/night match_runs_avg - team2_day/night match_runs_avg': 'Difference between the average runs scored by team1 and team2 in day/night matches',\n",
        "    'victory_by_wickets_team2': 'Number of matches won by team2 by wickets',\n",
        "    'nrr_team1 - nrr_team2': 'Difference in net run rate (NRR) between team1 and team2',\n",
        "    'inning1_avg_runs_team1': 'Average runs scored by team1 in the first innings',\n",
        "    'inning1_avg_wickets_team1': 'Average wickets lost by team1 in the first innings',\n",
        "    'Sum_of_BowlerAbilities_team1': 'Sum of bowler abilities for team1',\n",
        "    'inning2_avg_wickets_team2': 'Average wickets lost by team2 in the second innings',\n",
        "    'team_count_50runs_last15': 'Number of 50+ runs scored by the team in the last 15 matches',\n",
        "    'avg_inning2_runs_venue_last5': 'Average runs scored in the second innings at the venue in the last 5 matches',\n",
        "    'Sum_of_BatsmanAbilities_team2': 'Sum of batsman abilities for team2'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "jc_u-uZlgp_g",
        "outputId": "65f8ac9d-3533-40d1-d773-bd289a895cf8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_file2\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"feat_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          9,\n          2,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"feat_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"avg_inning2_runs_venue_last5\",\n          \"victory_by_wickets_team2\",\n          \"Sum_of_BowlerAbilities_team1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_feat_imp_train\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6998435999448738,\n        \"min\": 3.8052196359290518,\n        \"max\": 6.203184768492338,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          3.806339081067455,\n          4.759981317669615,\n          4.319367992938525\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"feat_rank_train\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          9,\n          2,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"feat_description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Average runs scored in the second innings at the venue in the last 5 matches\",\n          \"Number of matches won by team2 by wickets\",\n          \"Sum of bowler abilities for team1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_file2"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-bc4d5e1f-b51e-404e-aa45-5c6e33ece140\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feat_name</th>\n",
              "      <th>model_feat_imp_train</th>\n",
              "      <th>feat_rank_train</th>\n",
              "      <th>feat_description</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feat_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>team1_day/night match_runs_avg - team2_day/nig...</td>\n",
              "      <td>6.203185</td>\n",
              "      <td>1</td>\n",
              "      <td>Difference between the average runs scored by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>victory_by_wickets_team2</td>\n",
              "      <td>4.759981</td>\n",
              "      <td>2</td>\n",
              "      <td>Number of matches won by team2 by wickets</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>nrr_team1 - nrr_team2</td>\n",
              "      <td>4.621072</td>\n",
              "      <td>3</td>\n",
              "      <td>Difference in net run rate (NRR) between team1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>inning1_avg_runs_team1</td>\n",
              "      <td>4.463710</td>\n",
              "      <td>4</td>\n",
              "      <td>Average runs scored by team1 in the first innings</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>inning1_avg_wickets_team1</td>\n",
              "      <td>4.417557</td>\n",
              "      <td>5</td>\n",
              "      <td>Average wickets lost by team1 in the first inn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Sum_of_BowlerAbilities_team1</td>\n",
              "      <td>4.319368</td>\n",
              "      <td>6</td>\n",
              "      <td>Sum of bowler abilities for team1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>inning2_avg_wickets_team2</td>\n",
              "      <td>4.268900</td>\n",
              "      <td>7</td>\n",
              "      <td>Average wickets lost by team2 in the second in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>team_count_50runs_last15</td>\n",
              "      <td>3.877238</td>\n",
              "      <td>8</td>\n",
              "      <td>Number of 50+ runs scored by the team in the l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>avg_inning2_runs_venue_last5</td>\n",
              "      <td>3.806339</td>\n",
              "      <td>9</td>\n",
              "      <td>Average runs scored in the second innings at t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Sum_of_BatsmanAbilities_team2</td>\n",
              "      <td>3.805220</td>\n",
              "      <td>10</td>\n",
              "      <td>Sum of batsman abilities for team2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc4d5e1f-b51e-404e-aa45-5c6e33ece140')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bc4d5e1f-b51e-404e-aa45-5c6e33ece140 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bc4d5e1f-b51e-404e-aa45-5c6e33ece140');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a3118393-56c0-4bee-9db8-80dc718798eb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a3118393-56c0-4bee-9db8-80dc718798eb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a3118393-56c0-4bee-9db8-80dc718798eb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_ec6af3fa-905e-44d1-ae95-b0913caa44ef\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_file2')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ec6af3fa-905e-44d1-ae95-b0913caa44ef button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_file2');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                 feat_name  \\\n",
              "feat_id                                                      \n",
              "1        team1_day/night match_runs_avg - team2_day/nig...   \n",
              "2                                 victory_by_wickets_team2   \n",
              "3                                    nrr_team1 - nrr_team2   \n",
              "4                                   inning1_avg_runs_team1   \n",
              "5                                inning1_avg_wickets_team1   \n",
              "6                             Sum_of_BowlerAbilities_team1   \n",
              "7                                inning2_avg_wickets_team2   \n",
              "8                                 team_count_50runs_last15   \n",
              "9                             avg_inning2_runs_venue_last5   \n",
              "10                           Sum_of_BatsmanAbilities_team2   \n",
              "\n",
              "         model_feat_imp_train  feat_rank_train  \\\n",
              "feat_id                                          \n",
              "1                    6.203185                1   \n",
              "2                    4.759981                2   \n",
              "3                    4.621072                3   \n",
              "4                    4.463710                4   \n",
              "5                    4.417557                5   \n",
              "6                    4.319368                6   \n",
              "7                    4.268900                7   \n",
              "8                    3.877238                8   \n",
              "9                    3.806339                9   \n",
              "10                   3.805220               10   \n",
              "\n",
              "                                          feat_description  \n",
              "feat_id                                                     \n",
              "1        Difference between the average runs scored by ...  \n",
              "2                Number of matches won by team2 by wickets  \n",
              "3        Difference in net run rate (NRR) between team1...  \n",
              "4        Average runs scored by team1 in the first innings  \n",
              "5        Average wickets lost by team1 in the first inn...  \n",
              "6                        Sum of bowler abilities for team1  \n",
              "7        Average wickets lost by team2 in the second in...  \n",
              "8        Number of 50+ runs scored by the team in the l...  \n",
              "9        Average runs scored in the second innings at t...  \n",
              "10                      Sum of batsman abilities for team2  "
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# df_feat_importance.rename(index={0:'feat_id'}, inplace=True)\n",
        "df_file2 = df_feat_importance\n",
        "df_file2['feat_id'] = [i+1 for i in df_file2.index]\n",
        "df_file2['feat_rank_train'] = [i+1 for i in df_file2.index]\n",
        "df_file2 = df_file2.set_index('feat_id')\n",
        "df_file2['feat_description'] = df_file2['feat_name'].map(feature_desc)\n",
        "df_file2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhwj5LYmg5CP"
      },
      "outputs": [],
      "source": [
        "df_file1.rename(columns={'pred_winner_id': 'win_pred_team_id'}, inplace=True)\n",
        "df_file1.rename(columns={'pred_winner_score': 'win_pred_score'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sq-AsPPug_rP"
      },
      "outputs": [],
      "source": [
        "df_file1.to_csv('sub17 file1.csv', index=False)\n",
        "df_file2.to_csv('sub17 file2.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CuwcuT5EAjBw"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv('/content/processed_train_f (2).csv')\n",
        "test_data = pd.read_csv('/content/processed_test_f (2).csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ns9syPj-Aluq",
        "outputId": "256b79dd-2440-44e8-be42-fd0dd796a7d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(948, 197) (271, 196)\n"
          ]
        }
      ],
      "source": [
        "print(df_train.shape, test_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xQmndeLQwEGU",
        "outputId": "ab078095-e302-4206-8e3b-286ade004557"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500, Loss: 0.6967885494232178\n",
            "Epoch 2/500, Loss: 0.683638334274292\n",
            "Epoch 3/500, Loss: 0.6717560887336731\n",
            "Epoch 4/500, Loss: 0.6605300903320312\n",
            "Epoch 5/500, Loss: 0.6497259140014648\n",
            "Epoch 6/500, Loss: 0.638935923576355\n",
            "Epoch 7/500, Loss: 0.6280350685119629\n",
            "Epoch 8/500, Loss: 0.6169381737709045\n",
            "Epoch 9/500, Loss: 0.6055351495742798\n",
            "Epoch 10/500, Loss: 0.5938081741333008\n",
            "Epoch 11/500, Loss: 0.5815461874008179\n",
            "Epoch 12/500, Loss: 0.5687105059623718\n",
            "Epoch 13/500, Loss: 0.5552439093589783\n",
            "Epoch 14/500, Loss: 0.5411531329154968\n",
            "Epoch 15/500, Loss: 0.526512622833252\n",
            "Epoch 16/500, Loss: 0.5113442540168762\n",
            "Epoch 17/500, Loss: 0.495613694190979\n",
            "Epoch 18/500, Loss: 0.4793899953365326\n",
            "Epoch 19/500, Loss: 0.4627162218093872\n",
            "Epoch 20/500, Loss: 0.4455198049545288\n",
            "Epoch 21/500, Loss: 0.42787015438079834\n",
            "Epoch 22/500, Loss: 0.40994885563850403\n",
            "Epoch 23/500, Loss: 0.3918302059173584\n",
            "Epoch 24/500, Loss: 0.37365472316741943\n",
            "Epoch 25/500, Loss: 0.355507493019104\n",
            "Epoch 26/500, Loss: 0.3374546766281128\n",
            "Epoch 27/500, Loss: 0.31953930854797363\n",
            "Epoch 28/500, Loss: 0.30189049243927\n",
            "Epoch 29/500, Loss: 0.28467804193496704\n",
            "Epoch 30/500, Loss: 0.2679806649684906\n",
            "Epoch 31/500, Loss: 0.2518922984600067\n",
            "Epoch 32/500, Loss: 0.23646163940429688\n",
            "Epoch 33/500, Loss: 0.22169385850429535\n",
            "Epoch 34/500, Loss: 0.20757392048835754\n",
            "Epoch 35/500, Loss: 0.1940912902355194\n",
            "Epoch 36/500, Loss: 0.18132677674293518\n",
            "Epoch 37/500, Loss: 0.1693085879087448\n",
            "Epoch 38/500, Loss: 0.1579875946044922\n",
            "Epoch 39/500, Loss: 0.1473318636417389\n",
            "Epoch 40/500, Loss: 0.13728713989257812\n",
            "Epoch 41/500, Loss: 0.1277332454919815\n",
            "Epoch 42/500, Loss: 0.11870160698890686\n",
            "Epoch 43/500, Loss: 0.11019737273454666\n",
            "Epoch 44/500, Loss: 0.1021682396531105\n",
            "Epoch 45/500, Loss: 0.09457359462976456\n",
            "Epoch 46/500, Loss: 0.08745788782835007\n",
            "Epoch 47/500, Loss: 0.08076635748147964\n",
            "Epoch 48/500, Loss: 0.0744747668504715\n",
            "Epoch 49/500, Loss: 0.06857269257307053\n",
            "Epoch 50/500, Loss: 0.06303767114877701\n",
            "Epoch 51/500, Loss: 0.05783456191420555\n",
            "Epoch 52/500, Loss: 0.05298732966184616\n",
            "Epoch 53/500, Loss: 0.04847267270088196\n",
            "Epoch 54/500, Loss: 0.044303249567747116\n",
            "Epoch 55/500, Loss: 0.040456339716911316\n",
            "Epoch 56/500, Loss: 0.036925558000802994\n",
            "Epoch 57/500, Loss: 0.03371790796518326\n",
            "Epoch 58/500, Loss: 0.030791189521551132\n",
            "Epoch 59/500, Loss: 0.028122810646891594\n",
            "Epoch 60/500, Loss: 0.02569391578435898\n",
            "Epoch 61/500, Loss: 0.023489927873015404\n",
            "Epoch 62/500, Loss: 0.021516580134630203\n",
            "Epoch 63/500, Loss: 0.019741736352443695\n",
            "Epoch 64/500, Loss: 0.01813492551445961\n",
            "Epoch 65/500, Loss: 0.016683734953403473\n",
            "Epoch 66/500, Loss: 0.015368396416306496\n",
            "Epoch 67/500, Loss: 0.01417665183544159\n",
            "Epoch 68/500, Loss: 0.013095189817249775\n",
            "Epoch 69/500, Loss: 0.012116474099457264\n",
            "Epoch 70/500, Loss: 0.01122969202697277\n",
            "Epoch 71/500, Loss: 0.010429327376186848\n",
            "Epoch 72/500, Loss: 0.009706040844321251\n",
            "Epoch 73/500, Loss: 0.009049583226442337\n",
            "Epoch 74/500, Loss: 0.008455178700387478\n",
            "Epoch 75/500, Loss: 0.00791486818343401\n",
            "Epoch 76/500, Loss: 0.0074241869151592255\n",
            "Epoch 77/500, Loss: 0.006977563723921776\n",
            "Epoch 78/500, Loss: 0.006570881698280573\n",
            "Epoch 79/500, Loss: 0.006200222298502922\n",
            "Epoch 80/500, Loss: 0.005860610399395227\n",
            "Epoch 81/500, Loss: 0.005548403598368168\n",
            "Epoch 82/500, Loss: 0.005261452868580818\n",
            "Epoch 83/500, Loss: 0.004997409414499998\n",
            "Epoch 84/500, Loss: 0.004754390101879835\n",
            "Epoch 85/500, Loss: 0.004529902245849371\n",
            "Epoch 86/500, Loss: 0.00432250602170825\n",
            "Epoch 87/500, Loss: 0.004130425862967968\n",
            "Epoch 88/500, Loss: 0.003951848950237036\n",
            "Epoch 89/500, Loss: 0.003785745007917285\n",
            "Epoch 90/500, Loss: 0.003631006693467498\n",
            "Epoch 91/500, Loss: 0.0034866975620388985\n",
            "Epoch 92/500, Loss: 0.0033522669691592455\n",
            "Epoch 93/500, Loss: 0.0032268331851810217\n",
            "Epoch 94/500, Loss: 0.003109202953055501\n",
            "Epoch 95/500, Loss: 0.0029987471643835306\n",
            "Epoch 96/500, Loss: 0.0028953326400369406\n",
            "Epoch 97/500, Loss: 0.0027979849837720394\n",
            "Epoch 98/500, Loss: 0.0027062534354627132\n",
            "Epoch 99/500, Loss: 0.0026199284475296736\n",
            "Epoch 100/500, Loss: 0.0025384651962667704\n",
            "Epoch 101/500, Loss: 0.0024613679852336645\n",
            "Epoch 102/500, Loss: 0.0023883876856416464\n",
            "Epoch 103/500, Loss: 0.002319271909072995\n",
            "Epoch 104/500, Loss: 0.0022536504548043013\n",
            "Epoch 105/500, Loss: 0.002191291656345129\n",
            "Epoch 106/500, Loss: 0.0021320192608982325\n",
            "Epoch 107/500, Loss: 0.0020755017176270485\n",
            "Epoch 108/500, Loss: 0.0020215269178152084\n",
            "Epoch 109/500, Loss: 0.001969964010640979\n",
            "Epoch 110/500, Loss: 0.0019206743454560637\n",
            "Epoch 111/500, Loss: 0.0018735883058980107\n",
            "Epoch 112/500, Loss: 0.0018285029800608754\n",
            "Epoch 113/500, Loss: 0.001785223139449954\n",
            "Epoch 114/500, Loss: 0.0017437241040170193\n",
            "Epoch 115/500, Loss: 0.0017039310187101364\n",
            "Epoch 116/500, Loss: 0.001665715710259974\n",
            "Epoch 117/500, Loss: 0.0016289728228002787\n",
            "Epoch 118/500, Loss: 0.001593562075868249\n",
            "Epoch 119/500, Loss: 0.0015593958087265491\n",
            "Epoch 120/500, Loss: 0.001526466803625226\n",
            "Epoch 121/500, Loss: 0.001494708238169551\n",
            "Epoch 122/500, Loss: 0.0014640960143879056\n",
            "Epoch 123/500, Loss: 0.0014345860108733177\n",
            "Epoch 124/500, Loss: 0.0014060414396226406\n",
            "Epoch 125/500, Loss: 0.0013784090988337994\n",
            "Epoch 126/500, Loss: 0.0013516333419829607\n",
            "Epoch 127/500, Loss: 0.0013256813399493694\n",
            "Epoch 128/500, Loss: 0.0013005431974306703\n",
            "Epoch 129/500, Loss: 0.001276193419471383\n",
            "Epoch 130/500, Loss: 0.001252605696208775\n",
            "Epoch 131/500, Loss: 0.0012297078501433134\n",
            "Epoch 132/500, Loss: 0.0012074734549969435\n",
            "Epoch 133/500, Loss: 0.0011858729412779212\n",
            "Epoch 134/500, Loss: 0.0011648862855508924\n",
            "Epoch 135/500, Loss: 0.001144477166235447\n",
            "Epoch 136/500, Loss: 0.0011245997156947851\n",
            "Epoch 137/500, Loss: 0.0011052577756345272\n",
            "Epoch 138/500, Loss: 0.0010864478535950184\n",
            "Epoch 139/500, Loss: 0.0010681292042136192\n",
            "Epoch 140/500, Loss: 0.0010503035737201571\n",
            "Epoch 141/500, Loss: 0.0010329113574698567\n",
            "Epoch 142/500, Loss: 0.0010159427765756845\n",
            "Epoch 143/500, Loss: 0.000999423093162477\n",
            "Epoch 144/500, Loss: 0.0009833031799644232\n",
            "Epoch 145/500, Loss: 0.0009675699402578175\n",
            "Epoch 146/500, Loss: 0.0009522310574539006\n",
            "Epoch 147/500, Loss: 0.0009372789645567536\n",
            "Epoch 148/500, Loss: 0.0009226726251654327\n",
            "Epoch 149/500, Loss: 0.0009083955665118992\n",
            "Epoch 150/500, Loss: 0.0008944499422796071\n",
            "Epoch 151/500, Loss: 0.0008808342972770333\n",
            "Epoch 152/500, Loss: 0.0008675454882904887\n",
            "Epoch 153/500, Loss: 0.0008545514428988099\n",
            "Epoch 154/500, Loss: 0.0008418445941060781\n",
            "Epoch 155/500, Loss: 0.0008294190629385412\n",
            "Epoch 156/500, Loss: 0.0008172740926966071\n",
            "Epoch 157/500, Loss: 0.0008053906494751573\n",
            "Epoch 158/500, Loss: 0.0007937882328405976\n",
            "Epoch 159/500, Loss: 0.0007824288331903517\n",
            "Epoch 160/500, Loss: 0.0007713101804256439\n",
            "Epoch 161/500, Loss: 0.0007604265119880438\n",
            "Epoch 162/500, Loss: 0.0007497703190892935\n",
            "Epoch 163/500, Loss: 0.0007393380510620773\n",
            "Epoch 164/500, Loss: 0.0007291240035556257\n",
            "Epoch 165/500, Loss: 0.0007191182812675834\n",
            "Epoch 166/500, Loss: 0.0007093163440003991\n",
            "Epoch 167/500, Loss: 0.0006997236632741988\n",
            "Epoch 168/500, Loss: 0.0006903196917846799\n",
            "Epoch 169/500, Loss: 0.0006811071070842445\n",
            "Epoch 170/500, Loss: 0.0006720705423504114\n",
            "Epoch 171/500, Loss: 0.0006632282747887075\n",
            "Epoch 172/500, Loss: 0.0006545496871694922\n",
            "Epoch 173/500, Loss: 0.000646029191557318\n",
            "Epoch 174/500, Loss: 0.0006376708624884486\n",
            "Epoch 175/500, Loss: 0.0006294889026321471\n",
            "Epoch 176/500, Loss: 0.000621460028924048\n",
            "Epoch 177/500, Loss: 0.000613564217928797\n",
            "Epoch 178/500, Loss: 0.0006058263243176043\n",
            "Epoch 179/500, Loss: 0.0005982280126772821\n",
            "Epoch 180/500, Loss: 0.0005907738814130425\n",
            "Epoch 181/500, Loss: 0.0005834528128616512\n",
            "Epoch 182/500, Loss: 0.0005762673099525273\n",
            "Epoch 183/500, Loss: 0.0005692134145647287\n",
            "Epoch 184/500, Loss: 0.0005622880416922271\n",
            "Epoch 185/500, Loss: 0.0005554919480346143\n",
            "Epoch 186/500, Loss: 0.0005488090682774782\n",
            "Epoch 187/500, Loss: 0.0005422495305538177\n",
            "Epoch 188/500, Loss: 0.0005358123453333974\n",
            "Epoch 189/500, Loss: 0.0005294797010719776\n",
            "Epoch 190/500, Loss: 0.0005232618423178792\n",
            "Epoch 191/500, Loss: 0.0005171547527424991\n",
            "Epoch 192/500, Loss: 0.0005111551727168262\n",
            "Epoch 193/500, Loss: 0.0005052556516602635\n",
            "Epoch 194/500, Loss: 0.0004994611372239888\n",
            "Epoch 195/500, Loss: 0.0004937588819302619\n",
            "Epoch 196/500, Loss: 0.0004881540371570736\n",
            "Epoch 197/500, Loss: 0.00048263787175528705\n",
            "Epoch 198/500, Loss: 0.000477213499834761\n",
            "Epoch 199/500, Loss: 0.00047188246389850974\n",
            "Epoch 200/500, Loss: 0.0004666369059123099\n",
            "Epoch 201/500, Loss: 0.0004614756035152823\n",
            "Epoch 202/500, Loss: 0.00045639785821549594\n",
            "Epoch 203/500, Loss: 0.0004514038155321032\n",
            "Epoch 204/500, Loss: 0.0004464928642846644\n",
            "Epoch 205/500, Loss: 0.0004416565643623471\n",
            "Epoch 206/500, Loss: 0.00043689931044355035\n",
            "Epoch 207/500, Loss: 0.00043221202213317156\n",
            "Epoch 208/500, Loss: 0.00042760290671139956\n",
            "Epoch 209/500, Loss: 0.0004230657359585166\n",
            "Epoch 210/500, Loss: 0.0004185978905297816\n",
            "Epoch 211/500, Loss: 0.0004141996323596686\n",
            "Epoch 212/500, Loss: 0.0004098739009350538\n",
            "Epoch 213/500, Loss: 0.0004056071047671139\n",
            "Epoch 214/500, Loss: 0.0004014123696833849\n",
            "Epoch 215/500, Loss: 0.0003972739796154201\n",
            "Epoch 216/500, Loss: 0.0003931978135369718\n",
            "Epoch 217/500, Loss: 0.00038918672362342477\n",
            "Epoch 218/500, Loss: 0.0003852444642689079\n",
            "Epoch 219/500, Loss: 0.00038135520298965275\n",
            "Epoch 220/500, Loss: 0.00037752295611426234\n",
            "Epoch 221/500, Loss: 0.00037374900421127677\n",
            "Epoch 222/500, Loss: 0.00037003011675551534\n",
            "Epoch 223/500, Loss: 0.00036637045559473336\n",
            "Epoch 224/500, Loss: 0.0003627565165515989\n",
            "Epoch 225/500, Loss: 0.000359196012141183\n",
            "Epoch 226/500, Loss: 0.0003556832089088857\n",
            "Epoch 227/500, Loss: 0.00035222660517320037\n",
            "Epoch 228/500, Loss: 0.00034881962346844375\n",
            "Epoch 229/500, Loss: 0.000345456472132355\n",
            "Epoch 230/500, Loss: 0.00034214751212857664\n",
            "Epoch 231/500, Loss: 0.00033888063626363873\n",
            "Epoch 232/500, Loss: 0.00033565936610102654\n",
            "Epoch 233/500, Loss: 0.00033248643740080297\n",
            "Epoch 234/500, Loss: 0.00032935431227087975\n",
            "Epoch 235/500, Loss: 0.0003262687532696873\n",
            "Epoch 236/500, Loss: 0.0003232282178942114\n",
            "Epoch 237/500, Loss: 0.000320223334711045\n",
            "Epoch 238/500, Loss: 0.0003172636788804084\n",
            "Epoch 239/500, Loss: 0.0003143432841170579\n",
            "Epoch 240/500, Loss: 0.0003114661667495966\n",
            "Epoch 241/500, Loss: 0.00030862315907143056\n",
            "Epoch 242/500, Loss: 0.0003058201400563121\n",
            "Epoch 243/500, Loss: 0.000303052831441164\n",
            "Epoch 244/500, Loss: 0.0003003235615324229\n",
            "Epoch 245/500, Loss: 0.00029763218481093645\n",
            "Epoch 246/500, Loss: 0.00029497468494810164\n",
            "Epoch 247/500, Loss: 0.0002923513238783926\n",
            "Epoch 248/500, Loss: 0.0002897690865211189\n",
            "Epoch 249/500, Loss: 0.0002872142649721354\n",
            "Epoch 250/500, Loss: 0.00028469189419411123\n",
            "Epoch 251/500, Loss: 0.00028220831882208586\n",
            "Epoch 252/500, Loss: 0.00027975181001238525\n",
            "Epoch 253/500, Loss: 0.0002773298474494368\n",
            "Epoch 254/500, Loss: 0.0002749370760284364\n",
            "Epoch 255/500, Loss: 0.00027257378678768873\n",
            "Epoch 256/500, Loss: 0.00027024405426345766\n",
            "Epoch 257/500, Loss: 0.0002679418830666691\n",
            "Epoch 258/500, Loss: 0.00026566741871647537\n",
            "Epoch 259/500, Loss: 0.00026342307683080435\n",
            "Epoch 260/500, Loss: 0.00026120536495000124\n",
            "Epoch 261/500, Loss: 0.00025901521439664066\n",
            "Epoch 262/500, Loss: 0.0002568538475316018\n",
            "Epoch 263/500, Loss: 0.000254721351666376\n",
            "Epoch 264/500, Loss: 0.0002526105963625014\n",
            "Epoch 265/500, Loss: 0.00025052926503121853\n",
            "Epoch 266/500, Loss: 0.0002484678407199681\n",
            "Epoch 267/500, Loss: 0.0002464335411787033\n",
            "Epoch 268/500, Loss: 0.0002444270648993552\n",
            "Epoch 269/500, Loss: 0.00024244049564003944\n",
            "Epoch 270/500, Loss: 0.00024047655460890383\n",
            "Epoch 271/500, Loss: 0.0002385411789873615\n",
            "Epoch 272/500, Loss: 0.00023662770399823785\n",
            "Epoch 273/500, Loss: 0.00023473412147723138\n",
            "Epoch 274/500, Loss: 0.00023286696523427963\n",
            "Epoch 275/500, Loss: 0.00023101683473214507\n",
            "Epoch 276/500, Loss: 0.0002291909622726962\n",
            "Epoch 277/500, Loss: 0.00022738483676221222\n",
            "Epoch 278/500, Loss: 0.00022560225625056773\n",
            "Epoch 279/500, Loss: 0.00022383885516319424\n",
            "Epoch 280/500, Loss: 0.00022209607413969934\n",
            "Epoch 281/500, Loss: 0.00022037093003746122\n",
            "Epoch 282/500, Loss: 0.0002186644560424611\n",
            "Epoch 283/500, Loss: 0.00021698293858207762\n",
            "Epoch 284/500, Loss: 0.0002153175591956824\n",
            "Epoch 285/500, Loss: 0.00021366945293266326\n",
            "Epoch 286/500, Loss: 0.00021204285440035164\n",
            "Epoch 287/500, Loss: 0.000210435115150176\n",
            "Epoch 288/500, Loss: 0.00020884232071693987\n",
            "Epoch 289/500, Loss: 0.00020726759976241738\n",
            "Epoch 290/500, Loss: 0.0002057088859146461\n",
            "Epoch 291/500, Loss: 0.00020417101040948182\n",
            "Epoch 292/500, Loss: 0.00020265109196770936\n",
            "Epoch 293/500, Loss: 0.0002011448232224211\n",
            "Epoch 294/500, Loss: 0.00019965486717410386\n",
            "Epoch 295/500, Loss: 0.00019818483269773424\n",
            "Epoch 296/500, Loss: 0.00019672885537147522\n",
            "Epoch 297/500, Loss: 0.00019528255506884307\n",
            "Epoch 298/500, Loss: 0.00019385977066121995\n",
            "Epoch 299/500, Loss: 0.00019244597933720797\n",
            "Epoch 300/500, Loss: 0.00019105336104985327\n",
            "Epoch 301/500, Loss: 0.00018967242795042694\n",
            "Epoch 302/500, Loss: 0.0001883098011603579\n",
            "Epoch 303/500, Loss: 0.00018695328617468476\n",
            "Epoch 304/500, Loss: 0.00018561811884865165\n",
            "Epoch 305/500, Loss: 0.00018429556803312153\n",
            "Epoch 306/500, Loss: 0.00018298608483746648\n",
            "Epoch 307/500, Loss: 0.00018168830138165504\n",
            "Epoch 308/500, Loss: 0.00018040559371002018\n",
            "Epoch 309/500, Loss: 0.00017913816554937512\n",
            "Epoch 310/500, Loss: 0.00017788168042898178\n",
            "Epoch 311/500, Loss: 0.00017664063489064574\n",
            "Epoch 312/500, Loss: 0.00017541181296110153\n",
            "Epoch 313/500, Loss: 0.0001741933956509456\n",
            "Epoch 314/500, Loss: 0.00017298558668699116\n",
            "Epoch 315/500, Loss: 0.00017179590940941125\n",
            "Epoch 316/500, Loss: 0.00017061538528651\n",
            "Epoch 317/500, Loss: 0.000169447623193264\n",
            "Epoch 318/500, Loss: 0.00016828830121085048\n",
            "Epoch 319/500, Loss: 0.0001671428035479039\n",
            "Epoch 320/500, Loss: 0.00016601312381681055\n",
            "Epoch 321/500, Loss: 0.00016488792607560754\n",
            "Epoch 322/500, Loss: 0.00016377547581214458\n",
            "Epoch 323/500, Loss: 0.00016267561295535415\n",
            "Epoch 324/500, Loss: 0.0001615868677617982\n",
            "Epoch 325/500, Loss: 0.000160508556291461\n",
            "Epoch 326/500, Loss: 0.00015944047481752932\n",
            "Epoch 327/500, Loss: 0.00015838352555874735\n",
            "Epoch 328/500, Loss: 0.00015733447798993438\n",
            "Epoch 329/500, Loss: 0.00015629531117156148\n",
            "Epoch 330/500, Loss: 0.0001552690810058266\n",
            "Epoch 331/500, Loss: 0.00015425309538841248\n",
            "Epoch 332/500, Loss: 0.0001532441092422232\n",
            "Epoch 333/500, Loss: 0.00015224714297801256\n",
            "Epoch 334/500, Loss: 0.00015126063954085112\n",
            "Epoch 335/500, Loss: 0.0001502809172961861\n",
            "Epoch 336/500, Loss: 0.0001493105519330129\n",
            "Epoch 337/500, Loss: 0.00014835185720585287\n",
            "Epoch 338/500, Loss: 0.0001474012533435598\n",
            "Epoch 339/500, Loss: 0.00014645747432950884\n",
            "Epoch 340/500, Loss: 0.0001455267920391634\n",
            "Epoch 341/500, Loss: 0.00014460404054261744\n",
            "Epoch 342/500, Loss: 0.00014368844858836383\n",
            "Epoch 343/500, Loss: 0.0001427780807716772\n",
            "Epoch 344/500, Loss: 0.00014188046043273062\n",
            "Epoch 345/500, Loss: 0.00014098895189817995\n",
            "Epoch 346/500, Loss: 0.00014010696031618863\n",
            "Epoch 347/500, Loss: 0.00013923307415097952\n",
            "Epoch 348/500, Loss: 0.00013836777361575514\n",
            "Epoch 349/500, Loss: 0.0001375096762785688\n",
            "Epoch 350/500, Loss: 0.00013666397717315704\n",
            "Epoch 351/500, Loss: 0.00013582098472397774\n",
            "Epoch 352/500, Loss: 0.0001349840749753639\n",
            "Epoch 353/500, Loss: 0.00013415775902103633\n",
            "Epoch 354/500, Loss: 0.00013333739480003715\n",
            "Epoch 355/500, Loss: 0.00013252656208351254\n",
            "Epoch 356/500, Loss: 0.00013172179751563817\n",
            "Epoch 357/500, Loss: 0.0001309249782934785\n",
            "Epoch 358/500, Loss: 0.00013013531861361116\n",
            "Epoch 359/500, Loss: 0.00012935088307131082\n",
            "Epoch 360/500, Loss: 0.000128574509290047\n",
            "Epoch 361/500, Loss: 0.00012780679389834404\n",
            "Epoch 362/500, Loss: 0.00012704299297183752\n",
            "Epoch 363/500, Loss: 0.00012628783588297665\n",
            "Epoch 364/500, Loss: 0.00012553950364235789\n",
            "Epoch 365/500, Loss: 0.00012479386350605637\n",
            "Epoch 366/500, Loss: 0.00012406063615344465\n",
            "Epoch 367/500, Loss: 0.00012333081394899637\n",
            "Epoch 368/500, Loss: 0.0001226083404617384\n",
            "Epoch 369/500, Loss: 0.00012188984692329541\n",
            "Epoch 370/500, Loss: 0.00012118156882934272\n",
            "Epoch 371/500, Loss: 0.00012047528434777632\n",
            "Epoch 372/500, Loss: 0.00011977869144175202\n",
            "Epoch 373/500, Loss: 0.0001190849652630277\n",
            "Epoch 374/500, Loss: 0.00011839915532618761\n",
            "Epoch 375/500, Loss: 0.00011771746358135715\n",
            "Epoch 376/500, Loss: 0.00011704263306455687\n",
            "Epoch 377/500, Loss: 0.00011637352872639894\n",
            "Epoch 378/500, Loss: 0.00011571071081561968\n",
            "Epoch 379/500, Loss: 0.00011505489965202287\n",
            "Epoch 380/500, Loss: 0.00011440017988206819\n",
            "Epoch 381/500, Loss: 0.00011375317990314215\n",
            "Epoch 382/500, Loss: 0.00011311101843602955\n",
            "Epoch 383/500, Loss: 0.00011247588554397225\n",
            "Epoch 384/500, Loss: 0.00011184289178345352\n",
            "Epoch 385/500, Loss: 0.00011121762508992106\n",
            "Epoch 386/500, Loss: 0.00011059937241952866\n",
            "Epoch 387/500, Loss: 0.00010998453944921494\n",
            "Epoch 388/500, Loss: 0.00010937239130726084\n",
            "Epoch 389/500, Loss: 0.0001087672499124892\n",
            "Epoch 390/500, Loss: 0.00010816893336595967\n",
            "Epoch 391/500, Loss: 0.00010757241398096085\n",
            "Epoch 392/500, Loss: 0.00010698075493564829\n",
            "Epoch 393/500, Loss: 0.0001063971794792451\n",
            "Epoch 394/500, Loss: 0.00010581575043033808\n",
            "Epoch 395/500, Loss: 0.00010523865057621151\n",
            "Epoch 396/500, Loss: 0.00010466620733495802\n",
            "Epoch 397/500, Loss: 0.00010409988317405805\n",
            "Epoch 398/500, Loss: 0.0001035391105688177\n",
            "Epoch 399/500, Loss: 0.00010297980043105781\n",
            "Epoch 400/500, Loss: 0.00010242676216876134\n",
            "Epoch 401/500, Loss: 0.00010187713633058593\n",
            "Epoch 402/500, Loss: 0.00010133435716852546\n",
            "Epoch 403/500, Loss: 0.00010079372441396117\n",
            "Epoch 404/500, Loss: 0.00010025955270975828\n",
            "Epoch 405/500, Loss: 9.972845873562619e-05\n",
            "Epoch 406/500, Loss: 9.91996712400578e-05\n",
            "Epoch 407/500, Loss: 9.867575136013329e-05\n",
            "Epoch 408/500, Loss: 9.815541852731258e-05\n",
            "Epoch 409/500, Loss: 9.764281276147813e-05\n",
            "Epoch 410/500, Loss: 9.712966857478023e-05\n",
            "Epoch 411/500, Loss: 9.662641969043761e-05\n",
            "Epoch 412/500, Loss: 9.612279245629907e-05\n",
            "Epoch 413/500, Loss: 9.562168270349503e-05\n",
            "Epoch 414/500, Loss: 9.51268884819001e-05\n",
            "Epoch 415/500, Loss: 9.463314199820161e-05\n",
            "Epoch 416/500, Loss: 9.414732630830258e-05\n",
            "Epoch 417/500, Loss: 9.366274025524035e-05\n",
            "Epoch 418/500, Loss: 9.318158845417202e-05\n",
            "Epoch 419/500, Loss: 9.270545706385747e-05\n",
            "Epoch 420/500, Loss: 9.223185770679265e-05\n",
            "Epoch 421/500, Loss: 9.176272578770295e-05\n",
            "Epoch 422/500, Loss: 9.129595855483785e-05\n",
            "Epoch 423/500, Loss: 9.083348413696513e-05\n",
            "Epoch 424/500, Loss: 9.037370182340965e-05\n",
            "Epoch 425/500, Loss: 8.991968934424222e-05\n",
            "Epoch 426/500, Loss: 8.946746675064787e-05\n",
            "Epoch 427/500, Loss: 8.901883120415732e-05\n",
            "Epoch 428/500, Loss: 8.85741610545665e-05\n",
            "Epoch 429/500, Loss: 8.81292944541201e-05\n",
            "Epoch 430/500, Loss: 8.769072883296758e-05\n",
            "Epoch 431/500, Loss: 8.725610678084195e-05\n",
            "Epoch 432/500, Loss: 8.682400948600844e-05\n",
            "Epoch 433/500, Loss: 8.639208681415766e-05\n",
            "Epoch 434/500, Loss: 8.596591942477971e-05\n",
            "Epoch 435/500, Loss: 8.554622036172077e-05\n",
            "Epoch 436/500, Loss: 8.512526255799457e-05\n",
            "Epoch 437/500, Loss: 8.470700413454324e-05\n",
            "Epoch 438/500, Loss: 8.429304580204189e-05\n",
            "Epoch 439/500, Loss: 8.388125570490956e-05\n",
            "Epoch 440/500, Loss: 8.34735983517021e-05\n",
            "Epoch 441/500, Loss: 8.307043026434258e-05\n",
            "Epoch 442/500, Loss: 8.266653458122164e-05\n",
            "Epoch 443/500, Loss: 8.226732461480424e-05\n",
            "Epoch 444/500, Loss: 8.187188359443098e-05\n",
            "Epoch 445/500, Loss: 8.147788321366534e-05\n",
            "Epoch 446/500, Loss: 8.1087120634038e-05\n",
            "Epoch 447/500, Loss: 8.06993994046934e-05\n",
            "Epoch 448/500, Loss: 8.031152538023889e-05\n",
            "Epoch 449/500, Loss: 7.992918108357117e-05\n",
            "Epoch 450/500, Loss: 7.954776083352044e-05\n",
            "Epoch 451/500, Loss: 7.917010952951387e-05\n",
            "Epoch 452/500, Loss: 7.879516488173977e-05\n",
            "Epoch 453/500, Loss: 7.842380728106946e-05\n",
            "Epoch 454/500, Loss: 7.80533446231857e-05\n",
            "Epoch 455/500, Loss: 7.76880988269113e-05\n",
            "Epoch 456/500, Loss: 7.732123049208894e-05\n",
            "Epoch 457/500, Loss: 7.69593971199356e-05\n",
            "Epoch 458/500, Loss: 7.660312985535711e-05\n",
            "Epoch 459/500, Loss: 7.624363206559792e-05\n",
            "Epoch 460/500, Loss: 7.588880544062704e-05\n",
            "Epoch 461/500, Loss: 7.553380419267341e-05\n",
            "Epoch 462/500, Loss: 7.518723577959463e-05\n",
            "Epoch 463/500, Loss: 7.483888475690037e-05\n",
            "Epoch 464/500, Loss: 7.449430268025026e-05\n",
            "Epoch 465/500, Loss: 7.41509793442674e-05\n",
            "Epoch 466/500, Loss: 7.381125033134595e-05\n",
            "Epoch 467/500, Loss: 7.34743953216821e-05\n",
            "Epoch 468/500, Loss: 7.313663809327409e-05\n",
            "Epoch 469/500, Loss: 7.280445424839854e-05\n",
            "Epoch 470/500, Loss: 7.247424946399406e-05\n",
            "Epoch 471/500, Loss: 7.214333163574338e-05\n",
            "Epoch 472/500, Loss: 7.181725959526375e-05\n",
            "Epoch 473/500, Loss: 7.149172597564757e-05\n",
            "Epoch 474/500, Loss: 7.11694301571697e-05\n",
            "Epoch 475/500, Loss: 7.085037213983014e-05\n",
            "Epoch 476/500, Loss: 7.053346052998677e-05\n",
            "Epoch 477/500, Loss: 7.021602505119517e-05\n",
            "Epoch 478/500, Loss: 6.990163092268631e-05\n",
            "Epoch 479/500, Loss: 6.958976155146956e-05\n",
            "Epoch 480/500, Loss: 6.92789617460221e-05\n",
            "Epoch 481/500, Loss: 6.897067942190915e-05\n",
            "Epoch 482/500, Loss: 6.866473995614797e-05\n",
            "Epoch 483/500, Loss: 6.836454849690199e-05\n",
            "Epoch 484/500, Loss: 6.80614830343984e-05\n",
            "Epoch 485/500, Loss: 6.776182272005826e-05\n",
            "Epoch 486/500, Loss: 6.746396684320644e-05\n",
            "Epoch 487/500, Loss: 6.716773350490257e-05\n",
            "Epoch 488/500, Loss: 6.687419227091596e-05\n",
            "Epoch 489/500, Loss: 6.657921767327935e-05\n",
            "Epoch 490/500, Loss: 6.629088602494448e-05\n",
            "Epoch 491/500, Loss: 6.600344931939617e-05\n",
            "Epoch 492/500, Loss: 6.571655831066892e-05\n",
            "Epoch 493/500, Loss: 6.543075141962618e-05\n",
            "Epoch 494/500, Loss: 6.514762935694307e-05\n",
            "Epoch 495/500, Loss: 6.486829806817695e-05\n",
            "Epoch 496/500, Loss: 6.458822463173419e-05\n",
            "Epoch 497/500, Loss: 6.431031943066046e-05\n",
            "Epoch 498/500, Loss: 6.403619045158848e-05\n",
            "Epoch 499/500, Loss: 6.376097007887438e-05\n",
            "Epoch 500/500, Loss: 6.348882743623108e-05\n",
            "ROC AUC score on test set: 0.9015742202921437\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Load the data\n",
        "file_path = \"/content/processed_train_f (2).csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Dropping irrelevant columns\n",
        "irrelevant_columns = [\n",
        "    'match id', 'team1', 'team1_id', 'team1_roster_ids',\n",
        "    'team2', 'team2_id', 'team2_roster_ids', 'venue', 'city',\n",
        "    'match_dt', 'series_name', 'season'\n",
        "]\n",
        "data_cleaned = data.drop(columns=irrelevant_columns)\n",
        "\n",
        "# Select only numeric columns\n",
        "data_numeric = data_cleaned.select_dtypes(include=['number'])\n",
        "\n",
        "# Fill missing values with the mean of their respective columns\n",
        "data_filled = data_numeric.fillna(data_numeric.mean())\n",
        "\n",
        "# Split the data into features and target variable\n",
        "X = data_filled.drop(columns=['winner'])\n",
        "y = data_filled['winner']\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Standardize the features using the training data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
        "\n",
        "# Define the neural network\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(X.shape[1], 100)\n",
        "        self.fc2 = nn.Linear(100, 50)\n",
        "        self.fc3 = nn.Linear(50, 2)  # Output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        embeddings = x  # Extract embeddings here\n",
        "        x = self.fc3(x)\n",
        "        return x, embeddings\n",
        "\n",
        "model = Net()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs, _ = model(X_train_tensor)\n",
        "    loss = criterion(outputs, y_train_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
        "\n",
        "# Extract embeddings from the trained model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    _, train_embeddings = model(X_train_tensor)\n",
        "    test_outputs, test_embeddings = model(X_test_tensor)\n",
        "\n",
        "# Convert embeddings and outputs to numpy\n",
        "train_embeddings = train_embeddings.numpy()\n",
        "test_embeddings = test_embeddings.numpy()\n",
        "test_outputs = test_outputs.numpy()\n",
        "\n",
        "# Compute ROC AUC score on test set\n",
        "y_test_pred_proba = torch.softmax(torch.tensor(test_outputs), dim=1).numpy()[:, 1]\n",
        "roc_auc = roc_auc_score(y_test, y_test_pred_proba)\n",
        "print(f\"ROC AUC score on test set: {roc_auc}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8km1Wfr5UBhF",
        "outputId": "2bac0b69-4baa-4488-dc43-85b2aa6bd922"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.5-cp310-cp310-manylinux2014_x86_64.whl (98.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.4.1)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2.5\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NhOgze4zTuJ0",
        "outputId": "0cc00610-bce9-4450-cf4b-857489339a79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "38/38 [==============================] - 11s 58ms/step - loss: 224.1191 - val_loss: 192.2482\n",
            "Epoch 2/500\n",
            "38/38 [==============================] - 1s 17ms/step - loss: 191.7483 - val_loss: 175.6033\n",
            "Epoch 3/500\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 185.4063 - val_loss: 174.4636\n",
            "Epoch 4/500\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 184.6543 - val_loss: 173.6675\n",
            "Epoch 5/500\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 184.2879 - val_loss: 173.8673\n",
            "Epoch 6/500\n",
            "38/38 [==============================] - 1s 17ms/step - loss: 183.8732 - val_loss: 173.4242\n",
            "Epoch 7/500\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 183.2095 - val_loss: 172.6918\n",
            "Epoch 8/500\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 182.9677 - val_loss: 172.3423\n",
            "Epoch 9/500\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 182.5191 - val_loss: 171.9097\n",
            "Epoch 10/500\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 182.2449 - val_loss: 171.5308\n",
            "Epoch 11/500\n",
            "38/38 [==============================] - 1s 17ms/step - loss: 182.0760 - val_loss: 171.6501\n",
            "Epoch 12/500\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 181.8179 - val_loss: 171.0274\n",
            "Epoch 13/500\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 181.7696 - val_loss: 171.2543\n",
            "Epoch 14/500\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 181.4159 - val_loss: 170.7734\n",
            "Epoch 15/500\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 181.0191 - val_loss: 169.7737\n",
            "Epoch 16/500\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 181.0571 - val_loss: 169.4018\n",
            "Epoch 17/500\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 180.4601 - val_loss: 169.6417\n",
            "Epoch 18/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 180.1371 - val_loss: 169.9497\n",
            "Epoch 19/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 179.9742 - val_loss: 169.6400\n",
            "Epoch 20/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 179.9347 - val_loss: 169.2745\n",
            "Epoch 21/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 179.9217 - val_loss: 169.5903\n",
            "Epoch 22/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 179.7893 - val_loss: 169.6959\n",
            "Epoch 23/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 179.5987 - val_loss: 169.7671\n",
            "Epoch 24/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 179.5296 - val_loss: 170.0146\n",
            "Epoch 25/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 179.3955 - val_loss: 169.4034\n",
            "Epoch 26/500\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 179.6266 - val_loss: 169.6565\n",
            "Epoch 27/500\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 179.5408 - val_loss: 170.6187\n",
            "Epoch 28/500\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 179.1368 - val_loss: 169.6234\n",
            "Epoch 29/500\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 179.3870 - val_loss: 169.6772\n",
            "Epoch 30/500\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 179.3168 - val_loss: 169.9466\n",
            "24/24 [==============================] - 0s 5ms/step\n",
            "6/6 [==============================] - 0s 3ms/step\n",
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\tlearn: 0.6722419\ttotal: 143ms\tremaining: 44.7s\n",
            "1:\tlearn: 0.6574567\ttotal: 249ms\tremaining: 38.9s\n",
            "2:\tlearn: 0.6374073\ttotal: 378ms\tremaining: 39.2s\n",
            "3:\tlearn: 0.6195285\ttotal: 504ms\tremaining: 39s\n",
            "4:\tlearn: 0.6078932\ttotal: 605ms\tremaining: 37.4s\n",
            "5:\tlearn: 0.5914764\ttotal: 710ms\tremaining: 36.4s\n",
            "6:\tlearn: 0.5733615\ttotal: 834ms\tremaining: 36.6s\n",
            "7:\tlearn: 0.5595896\ttotal: 955ms\tremaining: 36.5s\n",
            "8:\tlearn: 0.5437916\ttotal: 1.07s\tremaining: 36.2s\n",
            "9:\tlearn: 0.5251252\ttotal: 1.19s\tremaining: 36s\n",
            "10:\tlearn: 0.5092472\ttotal: 1.3s\tremaining: 35.9s\n",
            "11:\tlearn: 0.4953226\ttotal: 1.43s\tremaining: 35.9s\n",
            "12:\tlearn: 0.4879105\ttotal: 1.55s\tremaining: 35.8s\n",
            "13:\tlearn: 0.4744490\ttotal: 1.67s\tremaining: 35.7s\n",
            "14:\tlearn: 0.4673250\ttotal: 1.79s\tremaining: 35.6s\n",
            "15:\tlearn: 0.4570514\ttotal: 1.9s\tremaining: 35.4s\n",
            "16:\tlearn: 0.4494470\ttotal: 2.03s\tremaining: 35.5s\n",
            "17:\tlearn: 0.4416987\ttotal: 2.14s\tremaining: 35.2s\n",
            "18:\tlearn: 0.4315549\ttotal: 2.27s\tremaining: 35.2s\n",
            "19:\tlearn: 0.4238394\ttotal: 2.39s\tremaining: 35.1s\n",
            "20:\tlearn: 0.4191216\ttotal: 2.51s\tremaining: 35s\n",
            "21:\tlearn: 0.4120379\ttotal: 2.63s\tremaining: 34.9s\n",
            "22:\tlearn: 0.3989432\ttotal: 2.75s\tremaining: 34.8s\n",
            "23:\tlearn: 0.3918713\ttotal: 2.87s\tremaining: 34.7s\n",
            "24:\tlearn: 0.3857995\ttotal: 3s\tremaining: 34.7s\n",
            "25:\tlearn: 0.3769781\ttotal: 3.13s\tremaining: 34.6s\n",
            "26:\tlearn: 0.3702173\ttotal: 3.22s\tremaining: 34.2s\n",
            "27:\tlearn: 0.3607056\ttotal: 3.28s\tremaining: 33.5s\n",
            "28:\tlearn: 0.3526625\ttotal: 3.35s\tremaining: 32.9s\n",
            "29:\tlearn: 0.3433325\ttotal: 3.41s\tremaining: 32.3s\n",
            "30:\tlearn: 0.3373480\ttotal: 3.48s\tremaining: 31.8s\n",
            "31:\tlearn: 0.3298047\ttotal: 3.55s\tremaining: 31.3s\n",
            "32:\tlearn: 0.3242907\ttotal: 3.61s\tremaining: 30.8s\n",
            "33:\tlearn: 0.3184874\ttotal: 3.68s\tremaining: 30.3s\n",
            "34:\tlearn: 0.3136892\ttotal: 3.75s\tremaining: 29.9s\n",
            "35:\tlearn: 0.3093099\ttotal: 3.82s\tremaining: 29.5s\n",
            "36:\tlearn: 0.3032111\ttotal: 3.88s\tremaining: 29.1s\n",
            "37:\tlearn: 0.2974076\ttotal: 3.94s\tremaining: 28.7s\n",
            "38:\tlearn: 0.2930721\ttotal: 4.01s\tremaining: 28.3s\n",
            "39:\tlearn: 0.2892620\ttotal: 4.09s\tremaining: 28s\n",
            "40:\tlearn: 0.2833014\ttotal: 4.15s\tremaining: 27.7s\n",
            "41:\tlearn: 0.2794621\ttotal: 4.22s\tremaining: 27.4s\n",
            "42:\tlearn: 0.2746957\ttotal: 4.29s\tremaining: 27s\n",
            "43:\tlearn: 0.2696431\ttotal: 4.36s\tremaining: 26.7s\n",
            "44:\tlearn: 0.2638325\ttotal: 4.42s\tremaining: 26.4s\n",
            "45:\tlearn: 0.2580203\ttotal: 4.49s\tremaining: 26.2s\n",
            "46:\tlearn: 0.2551841\ttotal: 4.56s\tremaining: 25.9s\n",
            "47:\tlearn: 0.2518537\ttotal: 4.62s\tremaining: 25.6s\n",
            "48:\tlearn: 0.2468153\ttotal: 4.69s\tremaining: 25.3s\n",
            "49:\tlearn: 0.2426955\ttotal: 4.75s\tremaining: 25.1s\n",
            "50:\tlearn: 0.2382114\ttotal: 4.82s\tremaining: 24.9s\n",
            "51:\tlearn: 0.2355487\ttotal: 4.88s\tremaining: 24.6s\n",
            "52:\tlearn: 0.2296920\ttotal: 4.95s\tremaining: 24.4s\n",
            "53:\tlearn: 0.2266126\ttotal: 5.01s\tremaining: 24.1s\n",
            "54:\tlearn: 0.2230638\ttotal: 5.08s\tremaining: 23.9s\n",
            "55:\tlearn: 0.2202079\ttotal: 5.16s\tremaining: 23.8s\n",
            "56:\tlearn: 0.2157038\ttotal: 5.23s\tremaining: 23.6s\n",
            "57:\tlearn: 0.2133583\ttotal: 5.29s\tremaining: 23.4s\n",
            "58:\tlearn: 0.2087064\ttotal: 5.36s\tremaining: 23.2s\n",
            "59:\tlearn: 0.2054262\ttotal: 5.42s\tremaining: 23s\n",
            "60:\tlearn: 0.2021851\ttotal: 5.49s\tremaining: 22.8s\n",
            "61:\tlearn: 0.1998491\ttotal: 5.56s\tremaining: 22.6s\n",
            "62:\tlearn: 0.1964407\ttotal: 5.62s\tremaining: 22.4s\n",
            "63:\tlearn: 0.1924257\ttotal: 5.69s\tremaining: 22.2s\n",
            "64:\tlearn: 0.1880007\ttotal: 5.75s\tremaining: 22s\n",
            "65:\tlearn: 0.1844573\ttotal: 5.82s\tremaining: 21.9s\n",
            "66:\tlearn: 0.1815475\ttotal: 5.88s\tremaining: 21.7s\n",
            "67:\tlearn: 0.1797333\ttotal: 5.95s\tremaining: 21.5s\n",
            "68:\tlearn: 0.1766346\ttotal: 6.02s\tremaining: 21.4s\n",
            "69:\tlearn: 0.1744536\ttotal: 6.08s\tremaining: 21.2s\n",
            "70:\tlearn: 0.1720625\ttotal: 6.16s\tremaining: 21.1s\n",
            "71:\tlearn: 0.1708113\ttotal: 6.23s\tremaining: 20.9s\n",
            "72:\tlearn: 0.1681807\ttotal: 6.29s\tremaining: 20.8s\n",
            "73:\tlearn: 0.1647983\ttotal: 6.36s\tremaining: 20.6s\n",
            "74:\tlearn: 0.1614331\ttotal: 6.42s\tremaining: 20.5s\n",
            "75:\tlearn: 0.1593544\ttotal: 6.5s\tremaining: 20.3s\n",
            "76:\tlearn: 0.1565550\ttotal: 6.56s\tremaining: 20.2s\n",
            "77:\tlearn: 0.1543769\ttotal: 6.62s\tremaining: 20s\n",
            "78:\tlearn: 0.1518752\ttotal: 6.69s\tremaining: 19.9s\n",
            "79:\tlearn: 0.1504028\ttotal: 6.76s\tremaining: 19.8s\n",
            "80:\tlearn: 0.1488826\ttotal: 6.82s\tremaining: 19.6s\n",
            "81:\tlearn: 0.1471767\ttotal: 6.89s\tremaining: 19.5s\n",
            "82:\tlearn: 0.1450152\ttotal: 6.95s\tremaining: 19.4s\n",
            "83:\tlearn: 0.1419891\ttotal: 7.02s\tremaining: 19.2s\n",
            "84:\tlearn: 0.1405808\ttotal: 7.09s\tremaining: 19.1s\n",
            "85:\tlearn: 0.1378483\ttotal: 7.16s\tremaining: 19s\n",
            "86:\tlearn: 0.1357821\ttotal: 7.23s\tremaining: 18.9s\n",
            "87:\tlearn: 0.1338018\ttotal: 7.3s\tremaining: 18.7s\n",
            "88:\tlearn: 0.1318183\ttotal: 7.36s\tremaining: 18.6s\n",
            "89:\tlearn: 0.1301667\ttotal: 7.43s\tremaining: 18.5s\n",
            "90:\tlearn: 0.1284783\ttotal: 7.5s\tremaining: 18.4s\n",
            "91:\tlearn: 0.1263753\ttotal: 7.56s\tremaining: 18.3s\n",
            "92:\tlearn: 0.1250248\ttotal: 7.63s\tremaining: 18.1s\n",
            "93:\tlearn: 0.1236913\ttotal: 7.69s\tremaining: 18s\n",
            "94:\tlearn: 0.1219299\ttotal: 7.76s\tremaining: 17.9s\n",
            "95:\tlearn: 0.1203285\ttotal: 7.83s\tremaining: 17.8s\n",
            "96:\tlearn: 0.1190962\ttotal: 7.89s\tremaining: 17.7s\n",
            "97:\tlearn: 0.1174615\ttotal: 7.96s\tremaining: 17.5s\n",
            "98:\tlearn: 0.1149979\ttotal: 8.02s\tremaining: 17.4s\n",
            "99:\tlearn: 0.1136658\ttotal: 8.09s\tremaining: 17.3s\n",
            "100:\tlearn: 0.1121684\ttotal: 8.15s\tremaining: 17.2s\n",
            "101:\tlearn: 0.1106194\ttotal: 8.23s\tremaining: 17.1s\n",
            "102:\tlearn: 0.1092548\ttotal: 8.3s\tremaining: 17s\n",
            "103:\tlearn: 0.1085698\ttotal: 8.36s\tremaining: 16.9s\n",
            "104:\tlearn: 0.1070435\ttotal: 8.43s\tremaining: 16.8s\n",
            "105:\tlearn: 0.1054890\ttotal: 8.5s\tremaining: 16.7s\n",
            "106:\tlearn: 0.1039077\ttotal: 8.57s\tremaining: 16.6s\n",
            "107:\tlearn: 0.1021657\ttotal: 8.63s\tremaining: 16.5s\n",
            "108:\tlearn: 0.1011225\ttotal: 8.7s\tremaining: 16.4s\n",
            "109:\tlearn: 0.0997604\ttotal: 8.76s\tremaining: 16.3s\n",
            "110:\tlearn: 0.0988884\ttotal: 8.83s\tremaining: 16.1s\n",
            "111:\tlearn: 0.0973389\ttotal: 8.89s\tremaining: 16s\n",
            "112:\tlearn: 0.0960257\ttotal: 8.96s\tremaining: 15.9s\n",
            "113:\tlearn: 0.0944925\ttotal: 9.03s\tremaining: 15.8s\n",
            "114:\tlearn: 0.0929852\ttotal: 9.1s\tremaining: 15.7s\n",
            "115:\tlearn: 0.0916679\ttotal: 9.16s\tremaining: 15.6s\n",
            "116:\tlearn: 0.0903167\ttotal: 9.24s\tremaining: 15.6s\n",
            "117:\tlearn: 0.0895700\ttotal: 9.3s\tremaining: 15.5s\n",
            "118:\tlearn: 0.0884379\ttotal: 9.37s\tremaining: 15.4s\n",
            "119:\tlearn: 0.0880626\ttotal: 9.44s\tremaining: 15.3s\n",
            "120:\tlearn: 0.0867946\ttotal: 9.51s\tremaining: 15.2s\n",
            "121:\tlearn: 0.0857291\ttotal: 9.57s\tremaining: 15.1s\n",
            "122:\tlearn: 0.0845228\ttotal: 9.63s\tremaining: 15s\n",
            "123:\tlearn: 0.0833255\ttotal: 9.7s\tremaining: 14.9s\n",
            "124:\tlearn: 0.0825011\ttotal: 9.77s\tremaining: 14.8s\n",
            "125:\tlearn: 0.0817341\ttotal: 9.83s\tremaining: 14.7s\n",
            "126:\tlearn: 0.0806139\ttotal: 9.9s\tremaining: 14.6s\n",
            "127:\tlearn: 0.0800055\ttotal: 9.96s\tremaining: 14.5s\n",
            "128:\tlearn: 0.0789246\ttotal: 10s\tremaining: 14.4s\n",
            "129:\tlearn: 0.0778443\ttotal: 10.1s\tremaining: 14.3s\n",
            "130:\tlearn: 0.0768841\ttotal: 10.2s\tremaining: 14.2s\n",
            "131:\tlearn: 0.0759183\ttotal: 10.2s\tremaining: 14.1s\n",
            "132:\tlearn: 0.0750663\ttotal: 10.3s\tremaining: 14s\n",
            "133:\tlearn: 0.0740053\ttotal: 10.4s\tremaining: 13.9s\n",
            "134:\tlearn: 0.0730101\ttotal: 10.4s\tremaining: 13.8s\n",
            "135:\tlearn: 0.0721596\ttotal: 10.5s\tremaining: 13.8s\n",
            "136:\tlearn: 0.0712205\ttotal: 10.6s\tremaining: 13.7s\n",
            "137:\tlearn: 0.0703028\ttotal: 10.6s\tremaining: 13.6s\n",
            "138:\tlearn: 0.0695847\ttotal: 10.7s\tremaining: 13.5s\n",
            "139:\tlearn: 0.0691534\ttotal: 10.8s\tremaining: 13.4s\n",
            "140:\tlearn: 0.0684247\ttotal: 10.8s\tremaining: 13.3s\n",
            "141:\tlearn: 0.0675972\ttotal: 10.9s\tremaining: 13.2s\n",
            "142:\tlearn: 0.0667970\ttotal: 11s\tremaining: 13.1s\n",
            "143:\tlearn: 0.0659498\ttotal: 11s\tremaining: 13s\n",
            "144:\tlearn: 0.0652020\ttotal: 11.1s\tremaining: 12.9s\n",
            "145:\tlearn: 0.0644401\ttotal: 11.2s\tremaining: 12.8s\n",
            "146:\tlearn: 0.0636087\ttotal: 11.2s\tremaining: 12.8s\n",
            "147:\tlearn: 0.0629235\ttotal: 11.3s\tremaining: 12.7s\n",
            "148:\tlearn: 0.0621559\ttotal: 11.4s\tremaining: 12.6s\n",
            "149:\tlearn: 0.0614169\ttotal: 11.4s\tremaining: 12.5s\n",
            "150:\tlearn: 0.0606807\ttotal: 11.5s\tremaining: 12.4s\n",
            "151:\tlearn: 0.0604957\ttotal: 11.6s\tremaining: 12.3s\n",
            "152:\tlearn: 0.0598392\ttotal: 11.7s\tremaining: 12.3s\n",
            "153:\tlearn: 0.0592766\ttotal: 11.7s\tremaining: 12.2s\n",
            "154:\tlearn: 0.0587145\ttotal: 11.8s\tremaining: 12.1s\n",
            "155:\tlearn: 0.0581688\ttotal: 11.9s\tremaining: 12s\n",
            "156:\tlearn: 0.0576262\ttotal: 11.9s\tremaining: 11.9s\n",
            "157:\tlearn: 0.0569276\ttotal: 12s\tremaining: 11.8s\n",
            "158:\tlearn: 0.0562006\ttotal: 12.1s\tremaining: 11.7s\n",
            "159:\tlearn: 0.0556967\ttotal: 12.1s\tremaining: 11.7s\n",
            "160:\tlearn: 0.0550601\ttotal: 12.2s\tremaining: 11.6s\n",
            "161:\tlearn: 0.0545737\ttotal: 12.3s\tremaining: 11.5s\n",
            "162:\tlearn: 0.0539834\ttotal: 12.3s\tremaining: 11.4s\n",
            "163:\tlearn: 0.0534907\ttotal: 12.4s\tremaining: 11.3s\n",
            "164:\tlearn: 0.0529828\ttotal: 12.5s\tremaining: 11.3s\n",
            "165:\tlearn: 0.0526148\ttotal: 12.5s\tremaining: 11.2s\n",
            "166:\tlearn: 0.0520950\ttotal: 12.6s\tremaining: 11.1s\n",
            "167:\tlearn: 0.0517240\ttotal: 12.7s\tremaining: 11s\n",
            "168:\tlearn: 0.0513207\ttotal: 12.7s\tremaining: 10.9s\n",
            "169:\tlearn: 0.0508414\ttotal: 12.8s\tremaining: 10.8s\n",
            "170:\tlearn: 0.0504115\ttotal: 12.9s\tremaining: 10.8s\n",
            "171:\tlearn: 0.0498761\ttotal: 12.9s\tremaining: 10.7s\n",
            "172:\tlearn: 0.0493884\ttotal: 13s\tremaining: 10.6s\n",
            "173:\tlearn: 0.0489890\ttotal: 13.1s\tremaining: 10.5s\n",
            "174:\tlearn: 0.0486674\ttotal: 13.1s\tremaining: 10.4s\n",
            "175:\tlearn: 0.0482076\ttotal: 13.2s\tremaining: 10.4s\n",
            "176:\tlearn: 0.0477435\ttotal: 13.3s\tremaining: 10.3s\n",
            "177:\tlearn: 0.0473599\ttotal: 13.5s\tremaining: 10.3s\n",
            "178:\tlearn: 0.0470134\ttotal: 13.6s\tremaining: 10.2s\n",
            "179:\tlearn: 0.0465663\ttotal: 13.7s\tremaining: 10.2s\n",
            "180:\tlearn: 0.0460679\ttotal: 13.8s\tremaining: 10.2s\n",
            "181:\tlearn: 0.0456572\ttotal: 13.9s\tremaining: 10.1s\n",
            "182:\tlearn: 0.0452626\ttotal: 14.1s\tremaining: 10.1s\n",
            "183:\tlearn: 0.0448472\ttotal: 14.2s\tremaining: 10s\n",
            "184:\tlearn: 0.0444033\ttotal: 14.3s\tremaining: 9.96s\n",
            "185:\tlearn: 0.0440190\ttotal: 14.4s\tremaining: 9.91s\n",
            "186:\tlearn: 0.0436772\ttotal: 14.5s\tremaining: 9.86s\n",
            "187:\tlearn: 0.0433834\ttotal: 14.6s\tremaining: 9.81s\n",
            "188:\tlearn: 0.0431345\ttotal: 14.8s\tremaining: 9.77s\n",
            "189:\tlearn: 0.0427531\ttotal: 14.9s\tremaining: 9.7s\n",
            "190:\tlearn: 0.0423657\ttotal: 15s\tremaining: 9.64s\n",
            "191:\tlearn: 0.0421129\ttotal: 15.1s\tremaining: 9.58s\n",
            "192:\tlearn: 0.0417842\ttotal: 15.2s\tremaining: 9.52s\n",
            "193:\tlearn: 0.0413568\ttotal: 15.3s\tremaining: 9.47s\n",
            "194:\tlearn: 0.0410378\ttotal: 15.4s\tremaining: 9.42s\n",
            "195:\tlearn: 0.0407312\ttotal: 15.6s\tremaining: 9.36s\n",
            "196:\tlearn: 0.0404145\ttotal: 15.7s\tremaining: 9.3s\n",
            "197:\tlearn: 0.0401751\ttotal: 15.8s\tremaining: 9.24s\n",
            "198:\tlearn: 0.0399549\ttotal: 15.9s\tremaining: 9.19s\n",
            "199:\tlearn: 0.0395822\ttotal: 16s\tremaining: 9.13s\n",
            "200:\tlearn: 0.0394145\ttotal: 16.1s\tremaining: 9.08s\n",
            "201:\tlearn: 0.0391412\ttotal: 16.3s\tremaining: 9.01s\n",
            "202:\tlearn: 0.0389821\ttotal: 16.3s\tremaining: 8.94s\n",
            "203:\tlearn: 0.0386459\ttotal: 16.4s\tremaining: 8.87s\n",
            "204:\tlearn: 0.0384084\ttotal: 16.6s\tremaining: 8.81s\n",
            "205:\tlearn: 0.0381521\ttotal: 16.7s\tremaining: 8.75s\n",
            "206:\tlearn: 0.0378992\ttotal: 16.8s\tremaining: 8.7s\n",
            "207:\tlearn: 0.0375232\ttotal: 17s\tremaining: 8.64s\n",
            "208:\tlearn: 0.0372040\ttotal: 17.1s\tremaining: 8.58s\n",
            "209:\tlearn: 0.0369044\ttotal: 17.2s\tremaining: 8.52s\n",
            "210:\tlearn: 0.0367586\ttotal: 17.3s\tremaining: 8.43s\n",
            "211:\tlearn: 0.0364567\ttotal: 17.3s\tremaining: 8.34s\n",
            "212:\tlearn: 0.0362179\ttotal: 17.4s\tremaining: 8.25s\n",
            "213:\tlearn: 0.0359843\ttotal: 17.5s\tremaining: 8.16s\n",
            "214:\tlearn: 0.0357567\ttotal: 17.5s\tremaining: 8.08s\n",
            "215:\tlearn: 0.0354787\ttotal: 17.6s\tremaining: 7.99s\n",
            "216:\tlearn: 0.0353026\ttotal: 17.7s\tremaining: 7.9s\n",
            "217:\tlearn: 0.0350215\ttotal: 17.7s\tremaining: 7.81s\n",
            "218:\tlearn: 0.0347031\ttotal: 17.8s\tremaining: 7.72s\n",
            "219:\tlearn: 0.0344513\ttotal: 17.9s\tremaining: 7.64s\n",
            "220:\tlearn: 0.0342841\ttotal: 17.9s\tremaining: 7.55s\n",
            "221:\tlearn: 0.0340851\ttotal: 18s\tremaining: 7.46s\n",
            "222:\tlearn: 0.0338574\ttotal: 18.1s\tremaining: 7.37s\n",
            "223:\tlearn: 0.0336677\ttotal: 18.1s\tremaining: 7.29s\n",
            "224:\tlearn: 0.0334839\ttotal: 18.2s\tremaining: 7.2s\n",
            "225:\tlearn: 0.0332157\ttotal: 18.3s\tremaining: 7.11s\n",
            "226:\tlearn: 0.0329630\ttotal: 18.3s\tremaining: 7.03s\n",
            "227:\tlearn: 0.0327042\ttotal: 18.4s\tremaining: 6.94s\n",
            "228:\tlearn: 0.0324618\ttotal: 18.5s\tremaining: 6.85s\n",
            "229:\tlearn: 0.0322936\ttotal: 18.5s\tremaining: 6.77s\n",
            "230:\tlearn: 0.0320247\ttotal: 18.6s\tremaining: 6.69s\n",
            "231:\tlearn: 0.0318268\ttotal: 18.7s\tremaining: 6.6s\n",
            "232:\tlearn: 0.0316157\ttotal: 18.7s\tremaining: 6.51s\n",
            "233:\tlearn: 0.0314163\ttotal: 18.8s\tremaining: 6.43s\n",
            "234:\tlearn: 0.0312084\ttotal: 18.9s\tremaining: 6.34s\n",
            "235:\tlearn: 0.0310622\ttotal: 18.9s\tremaining: 6.26s\n",
            "236:\tlearn: 0.0308910\ttotal: 19s\tremaining: 6.17s\n",
            "237:\tlearn: 0.0307330\ttotal: 19.1s\tremaining: 6.09s\n",
            "238:\tlearn: 0.0305130\ttotal: 19.1s\tremaining: 6s\n",
            "239:\tlearn: 0.0303346\ttotal: 19.2s\tremaining: 5.92s\n",
            "240:\tlearn: 0.0301579\ttotal: 19.3s\tremaining: 5.83s\n",
            "241:\tlearn: 0.0299737\ttotal: 19.3s\tremaining: 5.75s\n",
            "242:\tlearn: 0.0298468\ttotal: 19.4s\tremaining: 5.67s\n",
            "243:\tlearn: 0.0296509\ttotal: 19.5s\tremaining: 5.58s\n",
            "244:\tlearn: 0.0294406\ttotal: 19.5s\tremaining: 5.5s\n",
            "245:\tlearn: 0.0292521\ttotal: 19.6s\tremaining: 5.42s\n",
            "246:\tlearn: 0.0290421\ttotal: 19.7s\tremaining: 5.34s\n",
            "247:\tlearn: 0.0288584\ttotal: 19.7s\tremaining: 5.25s\n",
            "248:\tlearn: 0.0286333\ttotal: 19.8s\tremaining: 5.17s\n",
            "249:\tlearn: 0.0285544\ttotal: 19.9s\tremaining: 5.09s\n",
            "250:\tlearn: 0.0283704\ttotal: 19.9s\tremaining: 5s\n",
            "251:\tlearn: 0.0282742\ttotal: 20s\tremaining: 4.92s\n",
            "252:\tlearn: 0.0280781\ttotal: 20.1s\tremaining: 4.84s\n",
            "253:\tlearn: 0.0278870\ttotal: 20.1s\tremaining: 4.76s\n",
            "254:\tlearn: 0.0277409\ttotal: 20.2s\tremaining: 4.67s\n",
            "255:\tlearn: 0.0275812\ttotal: 20.3s\tremaining: 4.59s\n",
            "256:\tlearn: 0.0274038\ttotal: 20.3s\tremaining: 4.51s\n",
            "257:\tlearn: 0.0272662\ttotal: 20.4s\tremaining: 4.43s\n",
            "258:\tlearn: 0.0270946\ttotal: 20.5s\tremaining: 4.35s\n",
            "259:\tlearn: 0.0269495\ttotal: 20.5s\tremaining: 4.26s\n",
            "260:\tlearn: 0.0267726\ttotal: 20.6s\tremaining: 4.18s\n",
            "261:\tlearn: 0.0266598\ttotal: 20.7s\tremaining: 4.11s\n",
            "262:\tlearn: 0.0265322\ttotal: 20.7s\tremaining: 4.02s\n",
            "263:\tlearn: 0.0263687\ttotal: 20.8s\tremaining: 3.94s\n",
            "264:\tlearn: 0.0262311\ttotal: 20.9s\tremaining: 3.86s\n",
            "265:\tlearn: 0.0260837\ttotal: 20.9s\tremaining: 3.78s\n",
            "266:\tlearn: 0.0259797\ttotal: 21s\tremaining: 3.7s\n",
            "267:\tlearn: 0.0258603\ttotal: 21.1s\tremaining: 3.62s\n",
            "268:\tlearn: 0.0257263\ttotal: 21.1s\tremaining: 3.54s\n",
            "269:\tlearn: 0.0255761\ttotal: 21.2s\tremaining: 3.46s\n",
            "270:\tlearn: 0.0254283\ttotal: 21.3s\tremaining: 3.38s\n",
            "271:\tlearn: 0.0252922\ttotal: 21.3s\tremaining: 3.29s\n",
            "272:\tlearn: 0.0251339\ttotal: 21.4s\tremaining: 3.21s\n",
            "273:\tlearn: 0.0250132\ttotal: 21.5s\tremaining: 3.13s\n",
            "274:\tlearn: 0.0248825\ttotal: 21.5s\tremaining: 3.05s\n",
            "275:\tlearn: 0.0247508\ttotal: 21.6s\tremaining: 2.97s\n",
            "276:\tlearn: 0.0246239\ttotal: 21.7s\tremaining: 2.9s\n",
            "277:\tlearn: 0.0245435\ttotal: 21.7s\tremaining: 2.82s\n",
            "278:\tlearn: 0.0243793\ttotal: 21.8s\tremaining: 2.74s\n",
            "279:\tlearn: 0.0242371\ttotal: 21.9s\tremaining: 2.66s\n",
            "280:\tlearn: 0.0241532\ttotal: 21.9s\tremaining: 2.58s\n",
            "281:\tlearn: 0.0240095\ttotal: 22s\tremaining: 2.5s\n",
            "282:\tlearn: 0.0239704\ttotal: 22.1s\tremaining: 2.42s\n",
            "283:\tlearn: 0.0238790\ttotal: 22.1s\tremaining: 2.34s\n",
            "284:\tlearn: 0.0237725\ttotal: 22.2s\tremaining: 2.26s\n",
            "285:\tlearn: 0.0236570\ttotal: 22.3s\tremaining: 2.18s\n",
            "286:\tlearn: 0.0235605\ttotal: 22.3s\tremaining: 2.1s\n",
            "287:\tlearn: 0.0234513\ttotal: 22.4s\tremaining: 2.02s\n",
            "288:\tlearn: 0.0233422\ttotal: 22.5s\tremaining: 1.94s\n",
            "289:\tlearn: 0.0232199\ttotal: 22.5s\tremaining: 1.86s\n",
            "290:\tlearn: 0.0231203\ttotal: 22.6s\tremaining: 1.79s\n",
            "291:\tlearn: 0.0230094\ttotal: 22.7s\tremaining: 1.71s\n",
            "292:\tlearn: 0.0229143\ttotal: 22.8s\tremaining: 1.63s\n",
            "293:\tlearn: 0.0228010\ttotal: 22.8s\tremaining: 1.55s\n",
            "294:\tlearn: 0.0227385\ttotal: 22.9s\tremaining: 1.47s\n",
            "295:\tlearn: 0.0226095\ttotal: 22.9s\tremaining: 1.4s\n",
            "296:\tlearn: 0.0225048\ttotal: 23s\tremaining: 1.32s\n",
            "297:\tlearn: 0.0224194\ttotal: 23.1s\tremaining: 1.24s\n",
            "298:\tlearn: 0.0223013\ttotal: 23.1s\tremaining: 1.16s\n",
            "299:\tlearn: 0.0221896\ttotal: 23.2s\tremaining: 1.08s\n",
            "300:\tlearn: 0.0220718\ttotal: 23.3s\tremaining: 1s\n",
            "301:\tlearn: 0.0219683\ttotal: 23.3s\tremaining: 928ms\n",
            "302:\tlearn: 0.0218483\ttotal: 23.4s\tremaining: 850ms\n",
            "303:\tlearn: 0.0217356\ttotal: 23.5s\tremaining: 773ms\n",
            "304:\tlearn: 0.0216296\ttotal: 23.6s\tremaining: 696ms\n",
            "305:\tlearn: 0.0215251\ttotal: 23.7s\tremaining: 619ms\n",
            "306:\tlearn: 0.0213706\ttotal: 23.7s\tremaining: 541ms\n",
            "307:\tlearn: 0.0212918\ttotal: 23.8s\tremaining: 464ms\n",
            "308:\tlearn: 0.0211898\ttotal: 23.9s\tremaining: 386ms\n",
            "309:\tlearn: 0.0211030\ttotal: 23.9s\tremaining: 309ms\n",
            "310:\tlearn: 0.0209972\ttotal: 24s\tremaining: 231ms\n",
            "311:\tlearn: 0.0208856\ttotal: 24.1s\tremaining: 154ms\n",
            "312:\tlearn: 0.0208064\ttotal: 24.1s\tremaining: 77.1ms\n",
            "313:\tlearn: 0.0207133\ttotal: 24.2s\tremaining: 0us\n",
            "Best Parameters found:  {'depth': 9, 'iterations': 314, 'l2_leaf_reg': 6.208342600258237, 'learning_rate': 0.10611720243493492}\n",
            "Best CV Score:  0.47759672359707206\n",
            "Test Accuracy with latent features from VAE and CatBoost:  0.48947368421052634\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.losses import mse\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.stats import randint as sp_randint\n",
        "from scipy.stats import uniform as sp_uniform\n",
        "import pandas as pd\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "# Load your data\n",
        "# Example: X, y = ...\n",
        "\n",
        "# Split data into training and testing sets\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the VAE architecture\n",
        "input_dim = X_train.shape[1]\n",
        "latent_dim = 42  # Dimension of the latent space\n",
        "\n",
        "# Encoder\n",
        "inputs = Input(shape=(input_dim,))\n",
        "h = Dense(64, activation='relu')(inputs)\n",
        "h = Dense(32, activation='relu')(h)\n",
        "z_mean = Dense(latent_dim)(h)\n",
        "z_log_var = Dense(latent_dim)(h)\n",
        "\n",
        "def sampling(args):\n",
        "    z_mean, z_log_var = args\n",
        "    batch = tf.shape(z_mean)[0]\n",
        "    dim = tf.shape(z_mean)[1]\n",
        "    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
        "\n",
        "# Decoder\n",
        "decoder_h = Dense(32, activation='relu')\n",
        "decoder_h2 = Dense(64, activation='relu')\n",
        "decoder_mean = Dense(input_dim, activation='sigmoid')\n",
        "h_decoded = decoder_h(z)\n",
        "h_decoded = decoder_h2(h_decoded)\n",
        "x_decoded_mean = decoder_mean(h_decoded)\n",
        "\n",
        "# VAE model\n",
        "vae = Model(inputs, x_decoded_mean)\n",
        "\n",
        "# VAE loss\n",
        "reconstruction_loss = mse(inputs, x_decoded_mean)\n",
        "reconstruction_loss *= input_dim\n",
        "kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
        "kl_loss = tf.reduce_sum(kl_loss, axis=-1)\n",
        "kl_loss *= -0.5\n",
        "vae_loss = tf.reduce_mean(reconstruction_loss + kl_loss)\n",
        "vae.add_loss(vae_loss)\n",
        "vae.compile(optimizer='adam')\n",
        "\n",
        "# Early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Train the VAE\n",
        "vae.fit(X_train, X_train, epochs=500, batch_size=16, validation_split=0.2, shuffle=True, callbacks=[early_stopping])\n",
        "\n",
        "# Encoder model to get latent features\n",
        "encoder = Model(inputs, z)\n",
        "\n",
        "# Get the latent representations\n",
        "train_embeddings = encoder.predict(X_train)\n",
        "test_embeddings = encoder.predict(X_test)\n",
        "\n",
        "# Convert embeddings to DataFrames\n",
        "train_embeddings_df = pd.DataFrame(train_embeddings, columns=[f\"emb_{i}\" for i in range(train_embeddings.shape[1])])\n",
        "test_embeddings_df = pd.DataFrame(test_embeddings, columns=[f\"emb_{i}\" for i in range(test_embeddings.shape[1])])\n",
        "\n",
        "# Define parameter grid for RandomizedSearchCV for CatBoost\n",
        "param_grid = {\n",
        "    'iterations': sp_randint(100, 500),  # reduce range of number of trees\n",
        "    'learning_rate': sp_uniform(0.01, 0.1),  # reduce range of learning rate\n",
        "    'depth': sp_randint(4, 10),  # reduce range of tree depth\n",
        "    'l2_leaf_reg': sp_uniform(1, 10),  # reduce range of L2 regularization coefficient\n",
        "}\n",
        "\n",
        "# Initialize CatBoostClassifier\n",
        "model = CatBoostClassifier(random_state=42)\n",
        "\n",
        "# Setup RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=model,\n",
        "    param_distributions=param_grid,\n",
        "    n_iter=20,  # Increase number of iterations\n",
        "    scoring='accuracy',  # evaluation metric\n",
        "    cv=5,  # cross-validation folds\n",
        "    verbose=3,  # verbosity\n",
        "    random_state=42,  # random state for reproducibility\n",
        "    n_jobs=-1  # use all available CPU cores\n",
        ")\n",
        "\n",
        "# Fit RandomizedSearchCV on training embeddings\n",
        "random_search.fit(train_embeddings_df, y_train)\n",
        "\n",
        "# Print best parameters and best score\n",
        "print(\"Best Parameters found: \", random_search.best_params_)\n",
        "print(\"Best CV Score: \", random_search.best_score_)\n",
        "\n",
        "# Predict using the best estimator found by RandomizedSearchCV\n",
        "best_model = random_search.best_estimator_\n",
        "predictions = best_model.predict(test_embeddings_df)\n",
        "\n",
        "# Evaluate performance on test set\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(\"Test Accuracy with latent features from VAE and CatBoost: \", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "tZJIry1BUeVV",
        "outputId": "af29bf7c-2f42-470a-d033-0b4437dd4b5c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  pid = os.fork()\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-82058f600c94>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_embeddings_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best Parameters found: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m         \u001b[0;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1768\u001b[0;31m         evaluate_candidates(\n\u001b[0m\u001b[1;32m   1769\u001b[0m             ParameterSampler(\n\u001b[1;32m   1770\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     )\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2005\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2007\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 (self._jobs[0].get_status(\n\u001b[1;32m   1761\u001b[0m                     timeout=self.timeout) == TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint as sp_randint\n",
        "from scipy.stats import uniform as sp_uniform\n",
        "\n",
        "param_grid = {\n",
        "    'iterations': sp_randint(100, 1000),\n",
        "    'learning_rate': sp_uniform(0.01, 0.3),\n",
        "    'depth': sp_randint(4, 10),\n",
        "    'l2_leaf_reg': sp_uniform(1, 10),\n",
        "    'border_count': sp_randint(32, 255),\n",
        "}\n",
        "\n",
        "model = CatBoostClassifier()\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=model,\n",
        "    param_distributions=param_grid,\n",
        "    n_iter=20,\n",
        "    scoring='accuracy',\n",
        "    cv=5,\n",
        "    verbose=3,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "random_search.fit(train_embeddings_df, y_train)\n",
        "\n",
        "print(\"Best Parameters found: \", random_search.best_params_)\n",
        "print(\"Best CV Score: \", random_search.best_score_)\n",
        "\n",
        "best_model = random_search.best_estimator_\n",
        "predictions = best_model.predict(test_embeddings_df)\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(\"Test Accuracy with best model: \", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8A0akpWiyxD2",
        "outputId": "547c06b9-b009-4470-d3c2-274b773e95eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "34/34 [==============================] - 3s 28ms/step - loss: 2.3599 - accuracy: 0.5057 - val_loss: 2.0632 - val_accuracy: 0.5714\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2.0324 - accuracy: 0.6189 - val_loss: 1.9287 - val_accuracy: 0.6617\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 1.9069 - accuracy: 0.6509 - val_loss: 1.7760 - val_accuracy: 0.7519\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 1.6840 - accuracy: 0.7755 - val_loss: 1.6757 - val_accuracy: 0.7519\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 1.5940 - accuracy: 0.7811 - val_loss: 1.5868 - val_accuracy: 0.7744\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 1.4619 - accuracy: 0.8264 - val_loss: 1.5059 - val_accuracy: 0.7820\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 1.3213 - accuracy: 0.8453 - val_loss: 1.4293 - val_accuracy: 0.8045\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 1.2715 - accuracy: 0.8453 - val_loss: 1.3840 - val_accuracy: 0.7895\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 1.1323 - accuracy: 0.9000 - val_loss: 1.3379 - val_accuracy: 0.7820\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 1.0932 - accuracy: 0.8868 - val_loss: 1.2739 - val_accuracy: 0.7895\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 1.0353 - accuracy: 0.8811 - val_loss: 1.2325 - val_accuracy: 0.7820\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.9446 - accuracy: 0.9075 - val_loss: 1.1755 - val_accuracy: 0.7744\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.8911 - accuracy: 0.9057 - val_loss: 1.1578 - val_accuracy: 0.7594\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.8431 - accuracy: 0.9132 - val_loss: 1.1042 - val_accuracy: 0.7895\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.7793 - accuracy: 0.9132 - val_loss: 1.0894 - val_accuracy: 0.7669\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.7605 - accuracy: 0.9094 - val_loss: 1.0551 - val_accuracy: 0.7744\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 0.6995 - accuracy: 0.9358 - val_loss: 1.0291 - val_accuracy: 0.7820\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 1s 22ms/step - loss: 0.6574 - accuracy: 0.9321 - val_loss: 0.9999 - val_accuracy: 0.7669\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.6306 - accuracy: 0.9264 - val_loss: 0.9378 - val_accuracy: 0.7970\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.5690 - accuracy: 0.9528 - val_loss: 0.9543 - val_accuracy: 0.7895\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.5612 - accuracy: 0.9302 - val_loss: 0.9320 - val_accuracy: 0.7970\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.5294 - accuracy: 0.9377 - val_loss: 0.8779 - val_accuracy: 0.7820\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.5104 - accuracy: 0.9472 - val_loss: 0.8707 - val_accuracy: 0.7895\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.4807 - accuracy: 0.9528 - val_loss: 0.8467 - val_accuracy: 0.7669\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.4591 - accuracy: 0.9358 - val_loss: 0.8519 - val_accuracy: 0.7970\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.4255 - accuracy: 0.9585 - val_loss: 0.8427 - val_accuracy: 0.7895\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.4221 - accuracy: 0.9528 - val_loss: 0.8276 - val_accuracy: 0.7895\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.4142 - accuracy: 0.9528 - val_loss: 0.8099 - val_accuracy: 0.8045\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.3805 - accuracy: 0.9604 - val_loss: 0.8100 - val_accuracy: 0.7970\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.3778 - accuracy: 0.9472 - val_loss: 0.7796 - val_accuracy: 0.7895\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.3815 - accuracy: 0.9358 - val_loss: 0.7739 - val_accuracy: 0.7895\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.3349 - accuracy: 0.9736 - val_loss: 0.7711 - val_accuracy: 0.7820\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.3373 - accuracy: 0.9547 - val_loss: 0.7628 - val_accuracy: 0.7820\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 0.3143 - accuracy: 0.9604 - val_loss: 0.7663 - val_accuracy: 0.7895\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.3078 - accuracy: 0.9585 - val_loss: 0.7687 - val_accuracy: 0.7820\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 0.3020 - accuracy: 0.9717 - val_loss: 0.7713 - val_accuracy: 0.7820\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.2887 - accuracy: 0.9736 - val_loss: 0.7371 - val_accuracy: 0.8120\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.2747 - accuracy: 0.9774 - val_loss: 0.7314 - val_accuracy: 0.7895\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2717 - accuracy: 0.9736 - val_loss: 0.7936 - val_accuracy: 0.7895\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2715 - accuracy: 0.9623 - val_loss: 0.8040 - val_accuracy: 0.7895\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.2714 - accuracy: 0.9660 - val_loss: 0.8038 - val_accuracy: 0.7820\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.2554 - accuracy: 0.9679 - val_loss: 0.7346 - val_accuracy: 0.7820\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.2776 - accuracy: 0.9604 - val_loss: 0.7930 - val_accuracy: 0.7895\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2808 - accuracy: 0.9528 - val_loss: 0.7460 - val_accuracy: 0.7820\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.2664 - accuracy: 0.9660 - val_loss: 0.7585 - val_accuracy: 0.7895\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.2369 - accuracy: 0.9774 - val_loss: 0.7533 - val_accuracy: 0.7895\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.2315 - accuracy: 0.9736 - val_loss: 0.7789 - val_accuracy: 0.7970\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.2449 - accuracy: 0.9566 - val_loss: 0.7381 - val_accuracy: 0.7895\n",
            "9/9 [==============================] - 0s 3ms/step\n",
            "Test AUC score: 0.9175878405053296\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.85      0.79      0.82       136\n",
            "         1.0       0.82      0.87      0.84       149\n",
            "\n",
            "    accuracy                           0.83       285\n",
            "   macro avg       0.83      0.83      0.83       285\n",
            "weighted avg       0.83      0.83      0.83       285\n",
            "\n",
            "21/21 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "# Load the data\n",
        "file_path = \"/content/processed_train_f (2).csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Dropping irrelevant columns\n",
        "irrelevant_columns = [\n",
        "    'match id', 'team1', 'team1_id', 'team1_roster_ids',\n",
        "    'team2', 'team2_id', 'team2_roster_ids', 'venue', 'city',\n",
        "    'match_dt', 'series_name', 'season'\n",
        "]\n",
        "data_cleaned = data.drop(columns=irrelevant_columns)\n",
        "\n",
        "# Select only numeric columns\n",
        "data_numeric = data_cleaned.select_dtypes(include=['number'])\n",
        "\n",
        "# Fill missing values with the mean of their respective columns\n",
        "data_filled = data_numeric.fillna(data_numeric.mean())\n",
        "\n",
        "# Split the data into features and target variable\n",
        "X = data_filled.drop(columns=['winner'])\n",
        "y = data_filled['winner']\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Normalize the data using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define a neural network with an embedding layer\n",
        "input_dim = X_train_scaled.shape[1]\n",
        "embedding_dim = 45\n",
        "\n",
        "input_layer = Input(shape=(input_dim,))\n",
        "x = Dense(64, activation='relu', kernel_regularizer='l2')(input_layer)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(embedding_dim, activation='relu', kernel_regularizer='l2')(x)  # Embedding layer\n",
        "x = Dropout(0.5)(x)\n",
        "output_layer = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_scaled, y_train, epochs=100, batch_size=16, validation_split=0.2, callbacks=[early_stopping], verbose=1)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "print(f\"Test AUC score: {roc_auc_score(y_test, y_pred)}\")\n",
        "print(classification_report(y_test, (y_pred > 0.5).astype(int)))\n",
        "\n",
        "# Define a new model to extract embeddings\n",
        "embedding_model = Model(inputs=model.input, outputs=model.layers[-3].output)\n",
        "\n",
        "# Extract embeddings for the train and test sets\n",
        "train_embeddings = embedding_model.predict(X_train_scaled)\n",
        "test_embeddings = embedding_model.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "# Now train_embeddings and test_embeddings can be used for further tasks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "usUgFDKp1upc",
        "outputId": "484e2e61-f240-4d05-b692-77e8ef7fd3ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m122.9/129.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.6.2)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-tuner --upgrade\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ACn91xYj1peK",
        "outputId": "a1460f76-3dab-492d-f626-bcbfbdd71a63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reloading Tuner from my_dir/hyperparameter_tuning/tuner0.json\n",
            "Epoch 1/100\n",
            "34/34 [==============================] - 3s 26ms/step - loss: 1.5599 - accuracy: 0.5340 - val_loss: 1.3450 - val_accuracy: 0.5639\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 1.1685 - accuracy: 0.7094 - val_loss: 1.1801 - val_accuracy: 0.6992\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 0.9839 - accuracy: 0.8226 - val_loss: 1.0556 - val_accuracy: 0.7669\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.8865 - accuracy: 0.8415 - val_loss: 0.9997 - val_accuracy: 0.7669\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 0.7789 - accuracy: 0.8679 - val_loss: 0.9329 - val_accuracy: 0.7820\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.7170 - accuracy: 0.8925 - val_loss: 0.8897 - val_accuracy: 0.7970\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6525 - accuracy: 0.9170 - val_loss: 0.8621 - val_accuracy: 0.7895\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6031 - accuracy: 0.9302 - val_loss: 0.8348 - val_accuracy: 0.7970\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.5626 - accuracy: 0.9208 - val_loss: 0.8058 - val_accuracy: 0.8045\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.5226 - accuracy: 0.9358 - val_loss: 0.8088 - val_accuracy: 0.7820\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.4937 - accuracy: 0.9415 - val_loss: 0.7796 - val_accuracy: 0.7970\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.4565 - accuracy: 0.9396 - val_loss: 0.7535 - val_accuracy: 0.8045\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.4495 - accuracy: 0.9434 - val_loss: 0.7273 - val_accuracy: 0.8120\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 0.4166 - accuracy: 0.9491 - val_loss: 0.7245 - val_accuracy: 0.8045\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 1s 16ms/step - loss: 0.3916 - accuracy: 0.9472 - val_loss: 0.7022 - val_accuracy: 0.8045\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.3723 - accuracy: 0.9509 - val_loss: 0.6913 - val_accuracy: 0.8120\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 1s 27ms/step - loss: 0.3557 - accuracy: 0.9528 - val_loss: 0.6819 - val_accuracy: 0.7970\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 1s 16ms/step - loss: 0.3390 - accuracy: 0.9604 - val_loss: 0.6630 - val_accuracy: 0.7970\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.3085 - accuracy: 0.9623 - val_loss: 0.6572 - val_accuracy: 0.8195\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.3107 - accuracy: 0.9642 - val_loss: 0.6483 - val_accuracy: 0.7895\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.3060 - accuracy: 0.9698 - val_loss: 0.6567 - val_accuracy: 0.7895\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.3048 - accuracy: 0.9472 - val_loss: 0.6347 - val_accuracy: 0.7895\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.2761 - accuracy: 0.9755 - val_loss: 0.6377 - val_accuracy: 0.7895\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.2625 - accuracy: 0.9717 - val_loss: 0.6288 - val_accuracy: 0.7895\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.2563 - accuracy: 0.9660 - val_loss: 0.6182 - val_accuracy: 0.7970\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.2585 - accuracy: 0.9604 - val_loss: 0.6121 - val_accuracy: 0.7895\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2411 - accuracy: 0.9717 - val_loss: 0.6150 - val_accuracy: 0.7895\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.2342 - accuracy: 0.9642 - val_loss: 0.6155 - val_accuracy: 0.7744\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.2420 - accuracy: 0.9698 - val_loss: 0.6266 - val_accuracy: 0.7820\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 0.2229 - accuracy: 0.9698 - val_loss: 0.6278 - val_accuracy: 0.7895\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 0.2192 - accuracy: 0.9774 - val_loss: 0.6155 - val_accuracy: 0.7970\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.2210 - accuracy: 0.9585 - val_loss: 0.5954 - val_accuracy: 0.7820\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.2042 - accuracy: 0.9774 - val_loss: 0.6038 - val_accuracy: 0.7895\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.1992 - accuracy: 0.9755 - val_loss: 0.5968 - val_accuracy: 0.7895\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.1967 - accuracy: 0.9736 - val_loss: 0.5825 - val_accuracy: 0.7820\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 0.1972 - accuracy: 0.9755 - val_loss: 0.5913 - val_accuracy: 0.7820\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.1932 - accuracy: 0.9755 - val_loss: 0.5984 - val_accuracy: 0.7895\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 0.1903 - accuracy: 0.9792 - val_loss: 0.5963 - val_accuracy: 0.7895\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 0.1842 - accuracy: 0.9679 - val_loss: 0.6142 - val_accuracy: 0.7970\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.1738 - accuracy: 0.9792 - val_loss: 0.5789 - val_accuracy: 0.7895\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 0.1684 - accuracy: 0.9830 - val_loss: 0.6066 - val_accuracy: 0.7820\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 15ms/step - loss: 0.1696 - accuracy: 0.9868 - val_loss: 0.5864 - val_accuracy: 0.7895\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 1s 16ms/step - loss: 0.1688 - accuracy: 0.9792 - val_loss: 0.5913 - val_accuracy: 0.7820\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.1593 - accuracy: 0.9868 - val_loss: 0.5930 - val_accuracy: 0.7820\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 1s 16ms/step - loss: 0.1641 - accuracy: 0.9811 - val_loss: 0.6205 - val_accuracy: 0.7970\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 1s 16ms/step - loss: 0.1529 - accuracy: 0.9887 - val_loss: 0.6173 - val_accuracy: 0.7895\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.1555 - accuracy: 0.9830 - val_loss: 0.6037 - val_accuracy: 0.7970\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 1s 16ms/step - loss: 0.1544 - accuracy: 0.9868 - val_loss: 0.5951 - val_accuracy: 0.7820\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 0.1540 - accuracy: 0.9868 - val_loss: 0.6156 - val_accuracy: 0.7895\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.1460 - accuracy: 0.9906 - val_loss: 0.6373 - val_accuracy: 0.7895\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 0.1530 - accuracy: 0.9849 - val_loss: 0.6019 - val_accuracy: 0.7895\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.1452 - accuracy: 0.9830 - val_loss: 0.5866 - val_accuracy: 0.7970\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 0.1523 - accuracy: 0.9868 - val_loss: 0.6341 - val_accuracy: 0.7820\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.1486 - accuracy: 0.9811 - val_loss: 0.6085 - val_accuracy: 0.7820\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.1520 - accuracy: 0.9849 - val_loss: 0.5995 - val_accuracy: 0.7895\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 0.1536 - accuracy: 0.9830 - val_loss: 0.5943 - val_accuracy: 0.7744\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.1483 - accuracy: 0.9830 - val_loss: 0.6096 - val_accuracy: 0.7895\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 0.1461 - accuracy: 0.9792 - val_loss: 0.6107 - val_accuracy: 0.7895\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.1471 - accuracy: 0.9774 - val_loss: 0.6117 - val_accuracy: 0.7820\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.1539 - accuracy: 0.9755 - val_loss: 0.6050 - val_accuracy: 0.7820\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.1739 - accuracy: 0.9717 - val_loss: 0.6520 - val_accuracy: 0.7895\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.1461 - accuracy: 0.9792 - val_loss: 0.6104 - val_accuracy: 0.7820\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.1489 - accuracy: 0.9774 - val_loss: 0.6033 - val_accuracy: 0.7895\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.1373 - accuracy: 0.9868 - val_loss: 0.6224 - val_accuracy: 0.7820\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 1s 15ms/step - loss: 0.1376 - accuracy: 0.9811 - val_loss: 0.6469 - val_accuracy: 0.7744\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.1462 - accuracy: 0.9830 - val_loss: 0.6841 - val_accuracy: 0.7820\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.1398 - accuracy: 0.9792 - val_loss: 0.6541 - val_accuracy: 0.7820\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 1s 15ms/step - loss: 0.1357 - accuracy: 0.9849 - val_loss: 0.6653 - val_accuracy: 0.7895\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 15ms/step - loss: 0.1307 - accuracy: 0.9849 - val_loss: 0.6351 - val_accuracy: 0.7970\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 0.1313 - accuracy: 0.9849 - val_loss: 0.5911 - val_accuracy: 0.7970\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.1271 - accuracy: 0.9868 - val_loss: 0.6459 - val_accuracy: 0.8120\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.1402 - accuracy: 0.9811 - val_loss: 0.6792 - val_accuracy: 0.7895\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.1512 - accuracy: 0.9660 - val_loss: 0.6791 - val_accuracy: 0.7669\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.1389 - accuracy: 0.9849 - val_loss: 0.6515 - val_accuracy: 0.7820\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.1390 - accuracy: 0.9774 - val_loss: 0.6758 - val_accuracy: 0.7895\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 1s 24ms/step - loss: 0.1366 - accuracy: 0.9792 - val_loss: 0.6223 - val_accuracy: 0.7970\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.1348 - accuracy: 0.9849 - val_loss: 0.6854 - val_accuracy: 0.7895\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.1315 - accuracy: 0.9887 - val_loss: 0.6529 - val_accuracy: 0.7820\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 1s 16ms/step - loss: 0.1212 - accuracy: 0.9887 - val_loss: 0.6529 - val_accuracy: 0.7744\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.1279 - accuracy: 0.9830 - val_loss: 0.6630 - val_accuracy: 0.7895\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 1s 22ms/step - loss: 0.1283 - accuracy: 0.9830 - val_loss: 0.6220 - val_accuracy: 0.7895\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 1s 15ms/step - loss: 0.1452 - accuracy: 0.9623 - val_loss: 0.6331 - val_accuracy: 0.8045\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.1485 - accuracy: 0.9642 - val_loss: 0.6538 - val_accuracy: 0.7820\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.1281 - accuracy: 0.9811 - val_loss: 0.6135 - val_accuracy: 0.7895\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 15ms/step - loss: 0.1347 - accuracy: 0.9811 - val_loss: 0.6492 - val_accuracy: 0.7820\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 1s 16ms/step - loss: 0.1146 - accuracy: 0.9868 - val_loss: 0.6566 - val_accuracy: 0.8120\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.1281 - accuracy: 0.9774 - val_loss: 0.6742 - val_accuracy: 0.7895\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.1187 - accuracy: 0.9811 - val_loss: 0.6469 - val_accuracy: 0.7820\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.1233 - accuracy: 0.9849 - val_loss: 0.6488 - val_accuracy: 0.7820\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.1200 - accuracy: 0.9868 - val_loss: 0.6216 - val_accuracy: 0.7895\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 0.1205 - accuracy: 0.9887 - val_loss: 0.6452 - val_accuracy: 0.7895\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.1169 - accuracy: 0.9868 - val_loss: 0.7279 - val_accuracy: 0.7895\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.1229 - accuracy: 0.9830 - val_loss: 0.6574 - val_accuracy: 0.7895\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.1195 - accuracy: 0.9849 - val_loss: 0.6707 - val_accuracy: 0.7820\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.1188 - accuracy: 0.9830 - val_loss: 0.6978 - val_accuracy: 0.7895\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.1328 - accuracy: 0.9774 - val_loss: 0.6530 - val_accuracy: 0.7594\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.1224 - accuracy: 0.9887 - val_loss: 0.6957 - val_accuracy: 0.7970\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 0.1281 - accuracy: 0.9830 - val_loss: 0.6841 - val_accuracy: 0.7744\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.1173 - accuracy: 0.9887 - val_loss: 0.7245 - val_accuracy: 0.7820\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 1s 16ms/step - loss: 0.1122 - accuracy: 0.9925 - val_loss: 0.6300 - val_accuracy: 0.7895\n",
            "9/9 [==============================] - 0s 4ms/step\n",
            "Test AUC score: 0.9142321358073431\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.84      0.77      0.80       136\n",
            "         1.0       0.81      0.87      0.83       149\n",
            "\n",
            "    accuracy                           0.82       285\n",
            "   macro avg       0.82      0.82      0.82       285\n",
            "weighted avg       0.82      0.82      0.82       285\n",
            "\n",
            "21/21 [==============================] - 0s 5ms/step\n",
            "9/9 [==============================] - 0s 6ms/step\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "import keras_tuner as kt\n",
        "\n",
        "# Load the data\n",
        "file_path = \"/content/processed_train_f (2).csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Dropping irrelevant columns\n",
        "irrelevant_columns = [\n",
        "    'match id', 'team1', 'team1_id', 'team1_roster_ids',\n",
        "    'team2', 'team2_id', 'team2_roster_ids', 'venue', 'city',\n",
        "    'match_dt', 'series_name', 'season'\n",
        "]\n",
        "data_cleaned = data.drop(columns=irrelevant_columns)\n",
        "\n",
        "# Select only numeric columns\n",
        "data_numeric = data_cleaned.select_dtypes(include=['number'])\n",
        "\n",
        "# Fill missing values with the mean of their respective columns\n",
        "data_filled = data_numeric.fillna(data_numeric.mean())\n",
        "\n",
        "# Split the data into features and target variable\n",
        "X = data_filled.drop(columns=['winner'])\n",
        "y = data_filled['winner']\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Normalize the data using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Hyperparameter tuning function\n",
        "def build_model(hp):\n",
        "    input_dim = X_train_scaled.shape[1]\n",
        "    embedding_dim = 45\n",
        "\n",
        "    input_layer = Input(shape=(input_dim,))\n",
        "    x = Dense(embedding_dim, activation='relu', kernel_regularizer='l2')(input_layer)\n",
        "    x = Dropout(hp.Float('dropout', 0.2, 0.5, step=0.1, default=0.3))(x)\n",
        "    output_layer = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=hp.Choice('optimizer', ['adam', 'rmsprop']),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "tuner = kt.RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_loss',\n",
        "    max_trials=5,\n",
        "    executions_per_trial=3,\n",
        "    directory='my_dir',\n",
        "    project_name='hyperparameter_tuning'\n",
        ")\n",
        "\n",
        "# Perform hyperparameter tuning\n",
        "tuner.search(X_train_scaled, y_train, epochs=100, batch_size=16, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Get the best model architecture and hyperparameters\n",
        "best_hp = tuner.get_best_hyperparameters()[0]\n",
        "best_model = tuner.hypermodel.build(best_hp)\n",
        "\n",
        "# Train the best model without early stopping\n",
        "best_model.fit(X_train_scaled, y_train, epochs=100, batch_size=16, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred = best_model.predict(X_test_scaled).ravel()\n",
        "print(f\"Test AUC score: {roc_auc_score(y_test, y_pred)}\")\n",
        "print(classification_report(y_test, (y_pred > 0.5).astype(int)))\n",
        "\n",
        "# Define a new model to extract embeddings\n",
        "embedding_model = Model(inputs=best_model.input, outputs=best_model.layers[-2].output)\n",
        "\n",
        "# Extract embeddings for the train and test sets\n",
        "train_embeddings = embedding_model.predict(X_train_scaled)\n",
        "test_embeddings = embedding_model.predict(X_test_scaled)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "MNa56TZN-NJc",
        "outputId": "6f70f983-c5f6-4505-e4d7-d20aba59561a"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "read_csv() missing 1 required positional argument: 'filepath_or_buffer'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-106be309ee52>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: read_csv() missing 1 required positional argument: 'filepath_or_buffer'"
          ]
        }
      ],
      "source": [
        "data_test=pd.read_csv(\"/content/processed_test_f (2).csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "IhGBxbisOzkN",
        "outputId": "12fc9600-5ac6-4dc1-cb2d-cce26eb2fb72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting keras_tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m92.2/129.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (2.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (2.31.0)\n",
            "Collecting kt-legacy (from keras_tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (2024.6.2)\n",
            "Installing collected packages: kt-legacy, keras_tuner\n",
            "Successfully installed keras_tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install keras_tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9wjQUL3AXab"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DMQTDHI17FmG",
        "outputId": "ae92272c-a596-4213-d4d3-dd01d6b5dd00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.5-cp310-cp310-manylinux2014_x86_64.whl (98.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.4.1)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2.5\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "aVKCuunu9ZWm",
        "outputId": "9e7acd1c-ccde-42bf-b105-5c60a490687c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\tlearn: 0.6294660\ttotal: 2.4ms\tremaining: 551ms\n",
            "1:\tlearn: 0.5604569\ttotal: 4.38ms\tremaining: 499ms\n",
            "2:\tlearn: 0.5004323\ttotal: 6.11ms\tremaining: 463ms\n",
            "3:\tlearn: 0.4531936\ttotal: 7.78ms\tremaining: 439ms\n",
            "4:\tlearn: 0.4158572\ttotal: 9.44ms\tremaining: 425ms\n",
            "5:\tlearn: 0.3834883\ttotal: 11.2ms\tremaining: 419ms\n",
            "6:\tlearn: 0.3504011\ttotal: 12.8ms\tremaining: 408ms\n",
            "7:\tlearn: 0.3347190\ttotal: 14.4ms\tremaining: 401ms\n",
            "8:\tlearn: 0.3084265\ttotal: 16.2ms\tremaining: 397ms\n",
            "9:\tlearn: 0.2879910\ttotal: 17.8ms\tremaining: 392ms\n",
            "10:\tlearn: 0.2698159\ttotal: 19.4ms\tremaining: 385ms\n",
            "11:\tlearn: 0.2543472\ttotal: 21ms\tremaining: 381ms\n",
            "12:\tlearn: 0.2417293\ttotal: 22.7ms\tremaining: 379ms\n",
            "13:\tlearn: 0.2319396\ttotal: 24.4ms\tremaining: 377ms\n",
            "14:\tlearn: 0.2209422\ttotal: 26ms\tremaining: 372ms\n",
            "15:\tlearn: 0.2119370\ttotal: 27.7ms\tremaining: 370ms\n",
            "16:\tlearn: 0.2048887\ttotal: 29.3ms\tremaining: 367ms\n",
            "17:\tlearn: 0.1962780\ttotal: 31ms\tremaining: 365ms\n",
            "18:\tlearn: 0.1881716\ttotal: 32.6ms\tremaining: 362ms\n",
            "19:\tlearn: 0.1829362\ttotal: 34.3ms\tremaining: 360ms\n",
            "20:\tlearn: 0.1765922\ttotal: 35.8ms\tremaining: 357ms\n",
            "21:\tlearn: 0.1719816\ttotal: 37.6ms\tremaining: 356ms\n",
            "22:\tlearn: 0.1667392\ttotal: 39.8ms\tremaining: 359ms\n",
            "23:\tlearn: 0.1611557\ttotal: 42.1ms\tremaining: 361ms\n",
            "24:\tlearn: 0.1563101\ttotal: 44.5ms\tremaining: 365ms\n",
            "25:\tlearn: 0.1522405\ttotal: 46.7ms\tremaining: 367ms\n",
            "26:\tlearn: 0.1494953\ttotal: 49ms\tremaining: 368ms\n",
            "27:\tlearn: 0.1469944\ttotal: 50.5ms\tremaining: 364ms\n",
            "28:\tlearn: 0.1443878\ttotal: 53ms\tremaining: 367ms\n",
            "29:\tlearn: 0.1413519\ttotal: 54.5ms\tremaining: 363ms\n",
            "30:\tlearn: 0.1392036\ttotal: 56.5ms\tremaining: 363ms\n",
            "31:\tlearn: 0.1367982\ttotal: 58.3ms\tremaining: 361ms\n",
            "32:\tlearn: 0.1351320\ttotal: 60ms\tremaining: 358ms\n",
            "33:\tlearn: 0.1329634\ttotal: 61.8ms\tremaining: 357ms\n",
            "34:\tlearn: 0.1310753\ttotal: 63.5ms\tremaining: 354ms\n",
            "35:\tlearn: 0.1276180\ttotal: 65.3ms\tremaining: 352ms\n",
            "36:\tlearn: 0.1249542\ttotal: 67.2ms\tremaining: 350ms\n",
            "37:\tlearn: 0.1239559\ttotal: 69ms\tremaining: 349ms\n",
            "38:\tlearn: 0.1218619\ttotal: 70.6ms\tremaining: 346ms\n",
            "39:\tlearn: 0.1202919\ttotal: 72.2ms\tremaining: 343ms\n",
            "40:\tlearn: 0.1192820\ttotal: 73.8ms\tremaining: 340ms\n",
            "41:\tlearn: 0.1177527\ttotal: 75.5ms\tremaining: 338ms\n",
            "42:\tlearn: 0.1164758\ttotal: 77ms\tremaining: 335ms\n",
            "43:\tlearn: 0.1156959\ttotal: 78.6ms\tremaining: 332ms\n",
            "44:\tlearn: 0.1144393\ttotal: 80.3ms\tremaining: 330ms\n",
            "45:\tlearn: 0.1132863\ttotal: 81.8ms\tremaining: 327ms\n",
            "46:\tlearn: 0.1120254\ttotal: 83.5ms\tremaining: 325ms\n",
            "47:\tlearn: 0.1110866\ttotal: 85ms\tremaining: 322ms\n",
            "48:\tlearn: 0.1099597\ttotal: 86.4ms\tremaining: 319ms\n",
            "49:\tlearn: 0.1088420\ttotal: 88ms\tremaining: 317ms\n",
            "50:\tlearn: 0.1080399\ttotal: 89.7ms\tremaining: 315ms\n",
            "51:\tlearn: 0.1069875\ttotal: 91.3ms\tremaining: 312ms\n",
            "52:\tlearn: 0.1063352\ttotal: 93ms\tremaining: 311ms\n",
            "53:\tlearn: 0.1047152\ttotal: 94.6ms\tremaining: 308ms\n",
            "54:\tlearn: 0.1041574\ttotal: 96.2ms\tremaining: 306ms\n",
            "55:\tlearn: 0.1032889\ttotal: 97.7ms\tremaining: 304ms\n",
            "56:\tlearn: 0.1026492\ttotal: 99.4ms\tremaining: 302ms\n",
            "57:\tlearn: 0.1012582\ttotal: 101ms\tremaining: 300ms\n",
            "58:\tlearn: 0.1007102\ttotal: 103ms\tremaining: 297ms\n",
            "59:\tlearn: 0.0994757\ttotal: 104ms\tremaining: 295ms\n",
            "60:\tlearn: 0.0981037\ttotal: 106ms\tremaining: 294ms\n",
            "61:\tlearn: 0.0975423\ttotal: 108ms\tremaining: 291ms\n",
            "62:\tlearn: 0.0968205\ttotal: 109ms\tremaining: 290ms\n",
            "63:\tlearn: 0.0959648\ttotal: 111ms\tremaining: 288ms\n",
            "64:\tlearn: 0.0948185\ttotal: 113ms\tremaining: 286ms\n",
            "65:\tlearn: 0.0938078\ttotal: 114ms\tremaining: 284ms\n",
            "66:\tlearn: 0.0934107\ttotal: 116ms\tremaining: 282ms\n",
            "67:\tlearn: 0.0923037\ttotal: 118ms\tremaining: 280ms\n",
            "68:\tlearn: 0.0910260\ttotal: 119ms\tremaining: 279ms\n",
            "69:\tlearn: 0.0905942\ttotal: 121ms\tremaining: 276ms\n",
            "70:\tlearn: 0.0899190\ttotal: 123ms\tremaining: 275ms\n",
            "71:\tlearn: 0.0892610\ttotal: 124ms\tremaining: 272ms\n",
            "72:\tlearn: 0.0885849\ttotal: 126ms\tremaining: 271ms\n",
            "73:\tlearn: 0.0880465\ttotal: 128ms\tremaining: 269ms\n",
            "74:\tlearn: 0.0874286\ttotal: 129ms\tremaining: 267ms\n",
            "75:\tlearn: 0.0864147\ttotal: 131ms\tremaining: 265ms\n",
            "76:\tlearn: 0.0859383\ttotal: 132ms\tremaining: 263ms\n",
            "77:\tlearn: 0.0852234\ttotal: 134ms\tremaining: 262ms\n",
            "78:\tlearn: 0.0845194\ttotal: 136ms\tremaining: 259ms\n",
            "79:\tlearn: 0.0834038\ttotal: 137ms\tremaining: 258ms\n",
            "80:\tlearn: 0.0830887\ttotal: 139ms\tremaining: 256ms\n",
            "81:\tlearn: 0.0816929\ttotal: 141ms\tremaining: 254ms\n",
            "82:\tlearn: 0.0811078\ttotal: 143ms\tremaining: 253ms\n",
            "83:\tlearn: 0.0806554\ttotal: 144ms\tremaining: 250ms\n",
            "84:\tlearn: 0.0801493\ttotal: 146ms\tremaining: 249ms\n",
            "85:\tlearn: 0.0795188\ttotal: 147ms\tremaining: 247ms\n",
            "86:\tlearn: 0.0787706\ttotal: 149ms\tremaining: 245ms\n",
            "87:\tlearn: 0.0784080\ttotal: 151ms\tremaining: 243ms\n",
            "88:\tlearn: 0.0775208\ttotal: 152ms\tremaining: 241ms\n",
            "89:\tlearn: 0.0765173\ttotal: 154ms\tremaining: 239ms\n",
            "90:\tlearn: 0.0761492\ttotal: 155ms\tremaining: 237ms\n",
            "91:\tlearn: 0.0758257\ttotal: 157ms\tremaining: 235ms\n",
            "92:\tlearn: 0.0751242\ttotal: 158ms\tremaining: 233ms\n",
            "93:\tlearn: 0.0746242\ttotal: 160ms\tremaining: 232ms\n",
            "94:\tlearn: 0.0736387\ttotal: 162ms\tremaining: 230ms\n",
            "95:\tlearn: 0.0726245\ttotal: 163ms\tremaining: 228ms\n",
            "96:\tlearn: 0.0716736\ttotal: 169ms\tremaining: 232ms\n",
            "97:\tlearn: 0.0713668\ttotal: 171ms\tremaining: 231ms\n",
            "98:\tlearn: 0.0710568\ttotal: 176ms\tremaining: 233ms\n",
            "99:\tlearn: 0.0708028\ttotal: 178ms\tremaining: 231ms\n",
            "100:\tlearn: 0.0698080\ttotal: 182ms\tremaining: 233ms\n",
            "101:\tlearn: 0.0693985\ttotal: 188ms\tremaining: 236ms\n",
            "102:\tlearn: 0.0682867\ttotal: 193ms\tremaining: 237ms\n",
            "103:\tlearn: 0.0679471\ttotal: 197ms\tremaining: 239ms\n",
            "104:\tlearn: 0.0676327\ttotal: 200ms\tremaining: 238ms\n",
            "105:\tlearn: 0.0671993\ttotal: 201ms\tremaining: 235ms\n",
            "106:\tlearn: 0.0668744\ttotal: 203ms\tremaining: 233ms\n",
            "107:\tlearn: 0.0665898\ttotal: 205ms\tremaining: 231ms\n",
            "108:\tlearn: 0.0657487\ttotal: 206ms\tremaining: 229ms\n",
            "109:\tlearn: 0.0647430\ttotal: 208ms\tremaining: 227ms\n",
            "110:\tlearn: 0.0640283\ttotal: 210ms\tremaining: 225ms\n",
            "111:\tlearn: 0.0637990\ttotal: 211ms\tremaining: 223ms\n",
            "112:\tlearn: 0.0635803\ttotal: 213ms\tremaining: 221ms\n",
            "113:\tlearn: 0.0635132\ttotal: 216ms\tremaining: 219ms\n",
            "114:\tlearn: 0.0632829\ttotal: 218ms\tremaining: 218ms\n",
            "115:\tlearn: 0.0630603\ttotal: 219ms\tremaining: 216ms\n",
            "116:\tlearn: 0.0622677\ttotal: 221ms\tremaining: 213ms\n",
            "117:\tlearn: 0.0615269\ttotal: 223ms\tremaining: 211ms\n",
            "118:\tlearn: 0.0605649\ttotal: 227ms\tremaining: 212ms\n",
            "119:\tlearn: 0.0598833\ttotal: 230ms\tremaining: 211ms\n",
            "120:\tlearn: 0.0594289\ttotal: 232ms\tremaining: 209ms\n",
            "121:\tlearn: 0.0587222\ttotal: 234ms\tremaining: 207ms\n",
            "122:\tlearn: 0.0583094\ttotal: 235ms\tremaining: 205ms\n",
            "123:\tlearn: 0.0581170\ttotal: 237ms\tremaining: 203ms\n",
            "124:\tlearn: 0.0574081\ttotal: 239ms\tremaining: 200ms\n",
            "125:\tlearn: 0.0569913\ttotal: 240ms\tremaining: 198ms\n",
            "126:\tlearn: 0.0567678\ttotal: 243ms\tremaining: 197ms\n",
            "127:\tlearn: 0.0560570\ttotal: 245ms\tremaining: 195ms\n",
            "128:\tlearn: 0.0557536\ttotal: 247ms\tremaining: 193ms\n",
            "129:\tlearn: 0.0552715\ttotal: 248ms\tremaining: 191ms\n",
            "130:\tlearn: 0.0547006\ttotal: 250ms\tremaining: 189ms\n",
            "131:\tlearn: 0.0544813\ttotal: 252ms\tremaining: 187ms\n",
            "132:\tlearn: 0.0542372\ttotal: 254ms\tremaining: 185ms\n",
            "133:\tlearn: 0.0538904\ttotal: 255ms\tremaining: 183ms\n",
            "134:\tlearn: 0.0534403\ttotal: 257ms\tremaining: 181ms\n",
            "135:\tlearn: 0.0531510\ttotal: 259ms\tremaining: 179ms\n",
            "136:\tlearn: 0.0528998\ttotal: 260ms\tremaining: 177ms\n",
            "137:\tlearn: 0.0521815\ttotal: 262ms\tremaining: 175ms\n",
            "138:\tlearn: 0.0515755\ttotal: 264ms\tremaining: 173ms\n",
            "139:\tlearn: 0.0511964\ttotal: 266ms\tremaining: 171ms\n",
            "140:\tlearn: 0.0509275\ttotal: 267ms\tremaining: 169ms\n",
            "141:\tlearn: 0.0507722\ttotal: 269ms\tremaining: 167ms\n",
            "142:\tlearn: 0.0506331\ttotal: 271ms\tremaining: 165ms\n",
            "143:\tlearn: 0.0501438\ttotal: 273ms\tremaining: 163ms\n",
            "144:\tlearn: 0.0498225\ttotal: 276ms\tremaining: 162ms\n",
            "145:\tlearn: 0.0495335\ttotal: 279ms\tremaining: 161ms\n",
            "146:\tlearn: 0.0487942\ttotal: 283ms\tremaining: 160ms\n",
            "147:\tlearn: 0.0484270\ttotal: 286ms\tremaining: 158ms\n",
            "148:\tlearn: 0.0482336\ttotal: 288ms\tremaining: 157ms\n",
            "149:\tlearn: 0.0477929\ttotal: 291ms\tremaining: 155ms\n",
            "150:\tlearn: 0.0473531\ttotal: 294ms\tremaining: 154ms\n",
            "151:\tlearn: 0.0470292\ttotal: 296ms\tremaining: 152ms\n",
            "152:\tlearn: 0.0468702\ttotal: 298ms\tremaining: 150ms\n",
            "153:\tlearn: 0.0464142\ttotal: 299ms\tremaining: 148ms\n",
            "154:\tlearn: 0.0461334\ttotal: 301ms\tremaining: 146ms\n",
            "155:\tlearn: 0.0460042\ttotal: 303ms\tremaining: 144ms\n",
            "156:\tlearn: 0.0456218\ttotal: 305ms\tremaining: 142ms\n",
            "157:\tlearn: 0.0451511\ttotal: 306ms\tremaining: 140ms\n",
            "158:\tlearn: 0.0446752\ttotal: 308ms\tremaining: 138ms\n",
            "159:\tlearn: 0.0444783\ttotal: 310ms\tremaining: 135ms\n",
            "160:\tlearn: 0.0438413\ttotal: 311ms\tremaining: 133ms\n",
            "161:\tlearn: 0.0436820\ttotal: 313ms\tremaining: 131ms\n",
            "162:\tlearn: 0.0435759\ttotal: 315ms\tremaining: 129ms\n",
            "163:\tlearn: 0.0431255\ttotal: 316ms\tremaining: 127ms\n",
            "164:\tlearn: 0.0423627\ttotal: 318ms\tremaining: 125ms\n",
            "165:\tlearn: 0.0422213\ttotal: 319ms\tremaining: 123ms\n",
            "166:\tlearn: 0.0419332\ttotal: 321ms\tremaining: 121ms\n",
            "167:\tlearn: 0.0417819\ttotal: 323ms\tremaining: 119ms\n",
            "168:\tlearn: 0.0415331\ttotal: 325ms\tremaining: 117ms\n",
            "169:\tlearn: 0.0408996\ttotal: 326ms\tremaining: 115ms\n",
            "170:\tlearn: 0.0406858\ttotal: 328ms\tremaining: 113ms\n",
            "171:\tlearn: 0.0402944\ttotal: 330ms\tremaining: 111ms\n",
            "172:\tlearn: 0.0400360\ttotal: 333ms\tremaining: 110ms\n",
            "173:\tlearn: 0.0397652\ttotal: 339ms\tremaining: 109ms\n",
            "174:\tlearn: 0.0395151\ttotal: 341ms\tremaining: 107ms\n",
            "175:\tlearn: 0.0394207\ttotal: 343ms\tremaining: 105ms\n",
            "176:\tlearn: 0.0390885\ttotal: 345ms\tremaining: 103ms\n",
            "177:\tlearn: 0.0387427\ttotal: 348ms\tremaining: 102ms\n",
            "178:\tlearn: 0.0384296\ttotal: 349ms\tremaining: 99.5ms\n",
            "179:\tlearn: 0.0380482\ttotal: 351ms\tremaining: 97.5ms\n",
            "180:\tlearn: 0.0377801\ttotal: 353ms\tremaining: 95.5ms\n",
            "181:\tlearn: 0.0376655\ttotal: 354ms\tremaining: 93.5ms\n",
            "182:\tlearn: 0.0374303\ttotal: 356ms\tremaining: 91.5ms\n",
            "183:\tlearn: 0.0371903\ttotal: 358ms\tremaining: 89.4ms\n",
            "184:\tlearn: 0.0369814\ttotal: 359ms\tremaining: 87.4ms\n",
            "185:\tlearn: 0.0368680\ttotal: 361ms\tremaining: 85.4ms\n",
            "186:\tlearn: 0.0368421\ttotal: 363ms\tremaining: 83.4ms\n",
            "187:\tlearn: 0.0364230\ttotal: 364ms\tremaining: 81.4ms\n",
            "188:\tlearn: 0.0363426\ttotal: 366ms\tremaining: 79.4ms\n",
            "189:\tlearn: 0.0362495\ttotal: 368ms\tremaining: 77.4ms\n",
            "190:\tlearn: 0.0360241\ttotal: 369ms\tremaining: 75.4ms\n",
            "191:\tlearn: 0.0355632\ttotal: 371ms\tremaining: 73.4ms\n",
            "192:\tlearn: 0.0353624\ttotal: 372ms\tremaining: 71.4ms\n",
            "193:\tlearn: 0.0352682\ttotal: 374ms\tremaining: 69.4ms\n",
            "194:\tlearn: 0.0351198\ttotal: 376ms\tremaining: 67.5ms\n",
            "195:\tlearn: 0.0349204\ttotal: 377ms\tremaining: 65.5ms\n",
            "196:\tlearn: 0.0344783\ttotal: 379ms\tremaining: 63.5ms\n",
            "197:\tlearn: 0.0343654\ttotal: 381ms\tremaining: 61.5ms\n",
            "198:\tlearn: 0.0340986\ttotal: 382ms\tremaining: 59.6ms\n",
            "199:\tlearn: 0.0339499\ttotal: 384ms\tremaining: 57.6ms\n",
            "200:\tlearn: 0.0335995\ttotal: 386ms\tremaining: 55.7ms\n",
            "201:\tlearn: 0.0333926\ttotal: 388ms\tremaining: 53.7ms\n",
            "202:\tlearn: 0.0332878\ttotal: 389ms\tremaining: 51.8ms\n",
            "203:\tlearn: 0.0326771\ttotal: 391ms\tremaining: 49.9ms\n",
            "204:\tlearn: 0.0321418\ttotal: 394ms\tremaining: 48ms\n",
            "205:\tlearn: 0.0317578\ttotal: 396ms\tremaining: 46.2ms\n",
            "206:\tlearn: 0.0315954\ttotal: 398ms\tremaining: 44.2ms\n",
            "207:\tlearn: 0.0314251\ttotal: 400ms\tremaining: 42.3ms\n",
            "208:\tlearn: 0.0310454\ttotal: 402ms\tremaining: 40.4ms\n",
            "209:\tlearn: 0.0307643\ttotal: 403ms\tremaining: 38.4ms\n",
            "210:\tlearn: 0.0303501\ttotal: 405ms\tremaining: 36.4ms\n",
            "211:\tlearn: 0.0300352\ttotal: 406ms\tremaining: 34.5ms\n",
            "212:\tlearn: 0.0299002\ttotal: 409ms\tremaining: 32.6ms\n",
            "213:\tlearn: 0.0294131\ttotal: 411ms\tremaining: 30.7ms\n",
            "214:\tlearn: 0.0292949\ttotal: 413ms\tremaining: 28.8ms\n",
            "215:\tlearn: 0.0290788\ttotal: 415ms\tremaining: 26.9ms\n",
            "216:\tlearn: 0.0290121\ttotal: 416ms\tremaining: 24.9ms\n",
            "217:\tlearn: 0.0288236\ttotal: 418ms\tremaining: 23ms\n",
            "218:\tlearn: 0.0287371\ttotal: 420ms\tremaining: 21.1ms\n",
            "219:\tlearn: 0.0286306\ttotal: 421ms\tremaining: 19.1ms\n",
            "220:\tlearn: 0.0285666\ttotal: 423ms\tremaining: 17.2ms\n",
            "221:\tlearn: 0.0283636\ttotal: 424ms\tremaining: 15.3ms\n",
            "222:\tlearn: 0.0282837\ttotal: 426ms\tremaining: 13.4ms\n",
            "223:\tlearn: 0.0282148\ttotal: 428ms\tremaining: 11.5ms\n",
            "224:\tlearn: 0.0280396\ttotal: 430ms\tremaining: 9.54ms\n",
            "225:\tlearn: 0.0280273\ttotal: 431ms\tremaining: 7.63ms\n",
            "226:\tlearn: 0.0279529\ttotal: 432ms\tremaining: 5.71ms\n",
            "227:\tlearn: 0.0277274\ttotal: 434ms\tremaining: 3.81ms\n",
            "228:\tlearn: 0.0275119\ttotal: 436ms\tremaining: 1.9ms\n",
            "229:\tlearn: 0.0272801\ttotal: 437ms\tremaining: 0us\n",
            "Best Parameters found:  {'border_count': 95, 'depth': 3, 'iterations': 230, 'l2_leaf_reg': 5.299702033681603, 'learning_rate': 0.07803075385877797}\n",
            "Best CV Score:  0.9560833902939165\n",
            "Test Accuracy with best model:  0.8315789473684211\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.stats import randint as sp_randint\n",
        "from scipy.stats import uniform as sp_uniform\n",
        "\n",
        "# Assuming you have your embeddings already defined as train_embeddings and test_embeddings\n",
        "# and your target labels as y_train and y_test\n",
        "\n",
        "# Example data (replace with your actual data)\n",
        "# train_embeddings = ...\n",
        "# test_embeddings = ...\n",
        "# y_train = ...\n",
        "# y_test = ...\n",
        "\n",
        "# Convert embeddings to DataFrames\n",
        "train_embeddings_df = pd.DataFrame(train_embeddings, columns=[f\"emb_{i}\" for i in range(train_embeddings.shape[1])])\n",
        "test_embeddings_df = pd.DataFrame(test_embeddings, columns=[f\"emb_{i}\" for i in range(test_embeddings.shape[1])])\n",
        "\n",
        "# Define parameter grid for RandomizedSearchCV with reduced ranges\n",
        "param_grid = {\n",
        "    'iterations': sp_randint(100, 500),  # reduce range of number of trees\n",
        "    'learning_rate': sp_uniform(0.01, 0.1),  # reduce range of learning rate\n",
        "    'depth': sp_randint(3, 7),  # reduce range of tree depth\n",
        "    'l2_leaf_reg': sp_uniform(1, 5),  # reduce range of L2 regularization coefficient\n",
        "    'border_count': sp_randint(32, 128),  # reduce range of number of splits\n",
        "}\n",
        "\n",
        "# Initialize CatBoostClassifier\n",
        "model = CatBoostClassifier()\n",
        "\n",
        "# Setup RandomizedSearchCV with adjusted parameters\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=model,\n",
        "    param_distributions=param_grid,\n",
        "    n_iter=10,  # Reduce number of iterations\n",
        "    scoring='accuracy',  # evaluation metric\n",
        "    cv=5,  # cross-validation folds\n",
        "    verbose=3,  # verbosity\n",
        "    random_state=42,  # random state for reproducibility\n",
        "    n_jobs=-1  # use all available CPU cores\n",
        ")\n",
        "\n",
        "# Fit RandomizedSearchCV on training embeddings\n",
        "random_search.fit(train_embeddings_df, y_train)\n",
        "\n",
        "# Print best parameters and best score\n",
        "print(\"Best Parameters found: \", random_search.best_params_)\n",
        "print(\"Best CV Score: \", random_search.best_score_)\n",
        "\n",
        "# Predict using the best estimator found by RandomizedSearchCV\n",
        "best_model = random_search.best_estimator_\n",
        "predictions = best_model.predict(test_embeddings_df)\n",
        "\n",
        "# Evaluate performance on test set if y_test is available\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(\"Test Accuracy with best model: \", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uZkD_vxsd3kA",
        "outputId": "72c4f8c7-5af5-4673-d839-c401215d2791"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "449:\tlearn: 0.0553363\ttotal: 4.92s\tremaining: 6.02s\n",
            "450:\tlearn: 0.0552634\ttotal: 4.93s\tremaining: 6s\n",
            "451:\tlearn: 0.0551025\ttotal: 4.94s\tremaining: 5.99s\n",
            "452:\tlearn: 0.0549430\ttotal: 4.95s\tremaining: 5.98s\n",
            "453:\tlearn: 0.0548785\ttotal: 4.97s\tremaining: 5.97s\n",
            "454:\tlearn: 0.0547346\ttotal: 4.98s\tremaining: 5.96s\n",
            "455:\tlearn: 0.0546247\ttotal: 4.99s\tremaining: 5.95s\n",
            "456:\tlearn: 0.0545049\ttotal: 5s\tremaining: 5.94s\n",
            "457:\tlearn: 0.0543898\ttotal: 5.01s\tremaining: 5.93s\n",
            "458:\tlearn: 0.0542503\ttotal: 5.02s\tremaining: 5.92s\n",
            "459:\tlearn: 0.0541391\ttotal: 5.03s\tremaining: 5.9s\n",
            "460:\tlearn: 0.0539435\ttotal: 5.04s\tremaining: 5.89s\n",
            "461:\tlearn: 0.0538040\ttotal: 5.05s\tremaining: 5.88s\n",
            "462:\tlearn: 0.0537234\ttotal: 5.06s\tremaining: 5.87s\n",
            "463:\tlearn: 0.0536478\ttotal: 5.07s\tremaining: 5.86s\n",
            "464:\tlearn: 0.0535584\ttotal: 5.08s\tremaining: 5.85s\n",
            "465:\tlearn: 0.0534268\ttotal: 5.09s\tremaining: 5.84s\n",
            "466:\tlearn: 0.0533120\ttotal: 5.11s\tremaining: 5.83s\n",
            "467:\tlearn: 0.0531319\ttotal: 5.12s\tremaining: 5.82s\n",
            "468:\tlearn: 0.0529805\ttotal: 5.13s\tremaining: 5.8s\n",
            "469:\tlearn: 0.0528497\ttotal: 5.14s\tremaining: 5.79s\n",
            "470:\tlearn: 0.0527022\ttotal: 5.15s\tremaining: 5.78s\n",
            "471:\tlearn: 0.0525859\ttotal: 5.16s\tremaining: 5.77s\n",
            "472:\tlearn: 0.0524125\ttotal: 5.17s\tremaining: 5.76s\n",
            "473:\tlearn: 0.0522701\ttotal: 5.18s\tremaining: 5.75s\n",
            "474:\tlearn: 0.0521652\ttotal: 5.19s\tremaining: 5.74s\n",
            "475:\tlearn: 0.0520572\ttotal: 5.2s\tremaining: 5.73s\n",
            "476:\tlearn: 0.0519168\ttotal: 5.21s\tremaining: 5.71s\n",
            "477:\tlearn: 0.0517400\ttotal: 5.22s\tremaining: 5.7s\n",
            "478:\tlearn: 0.0515860\ttotal: 5.23s\tremaining: 5.69s\n",
            "479:\tlearn: 0.0515067\ttotal: 5.24s\tremaining: 5.68s\n",
            "480:\tlearn: 0.0513965\ttotal: 5.25s\tremaining: 5.67s\n",
            "481:\tlearn: 0.0512909\ttotal: 5.26s\tremaining: 5.66s\n",
            "482:\tlearn: 0.0511885\ttotal: 5.27s\tremaining: 5.64s\n",
            "483:\tlearn: 0.0511011\ttotal: 5.28s\tremaining: 5.63s\n",
            "484:\tlearn: 0.0509538\ttotal: 5.29s\tremaining: 5.62s\n",
            "485:\tlearn: 0.0508696\ttotal: 5.3s\tremaining: 5.61s\n",
            "486:\tlearn: 0.0506976\ttotal: 5.31s\tremaining: 5.6s\n",
            "487:\tlearn: 0.0506355\ttotal: 5.32s\tremaining: 5.59s\n",
            "488:\tlearn: 0.0504867\ttotal: 5.33s\tremaining: 5.58s\n",
            "489:\tlearn: 0.0503681\ttotal: 5.34s\tremaining: 5.56s\n",
            "490:\tlearn: 0.0502324\ttotal: 5.36s\tremaining: 5.55s\n",
            "491:\tlearn: 0.0501235\ttotal: 5.37s\tremaining: 5.54s\n",
            "492:\tlearn: 0.0499872\ttotal: 5.39s\tremaining: 5.54s\n",
            "493:\tlearn: 0.0498857\ttotal: 5.4s\tremaining: 5.53s\n",
            "494:\tlearn: 0.0497419\ttotal: 5.42s\tremaining: 5.53s\n",
            "495:\tlearn: 0.0495978\ttotal: 5.43s\tremaining: 5.52s\n",
            "496:\tlearn: 0.0495212\ttotal: 5.44s\tremaining: 5.51s\n",
            "497:\tlearn: 0.0494451\ttotal: 5.45s\tremaining: 5.5s\n",
            "498:\tlearn: 0.0493246\ttotal: 5.46s\tremaining: 5.49s\n",
            "499:\tlearn: 0.0492194\ttotal: 5.47s\tremaining: 5.47s\n",
            "500:\tlearn: 0.0491077\ttotal: 5.49s\tremaining: 5.46s\n",
            "501:\tlearn: 0.0489722\ttotal: 5.5s\tremaining: 5.45s\n",
            "502:\tlearn: 0.0488363\ttotal: 5.51s\tremaining: 5.44s\n",
            "503:\tlearn: 0.0487056\ttotal: 5.52s\tremaining: 5.43s\n",
            "504:\tlearn: 0.0486094\ttotal: 5.53s\tremaining: 5.42s\n",
            "505:\tlearn: 0.0485082\ttotal: 5.54s\tremaining: 5.41s\n",
            "506:\tlearn: 0.0483805\ttotal: 5.55s\tremaining: 5.39s\n",
            "507:\tlearn: 0.0482328\ttotal: 5.56s\tremaining: 5.38s\n",
            "508:\tlearn: 0.0480731\ttotal: 5.57s\tremaining: 5.37s\n",
            "509:\tlearn: 0.0479323\ttotal: 5.59s\tremaining: 5.37s\n",
            "510:\tlearn: 0.0478421\ttotal: 5.6s\tremaining: 5.36s\n",
            "511:\tlearn: 0.0476546\ttotal: 5.61s\tremaining: 5.35s\n",
            "512:\tlearn: 0.0475566\ttotal: 5.62s\tremaining: 5.34s\n",
            "513:\tlearn: 0.0474251\ttotal: 5.63s\tremaining: 5.33s\n",
            "514:\tlearn: 0.0473384\ttotal: 5.64s\tremaining: 5.32s\n",
            "515:\tlearn: 0.0472606\ttotal: 5.65s\tremaining: 5.3s\n",
            "516:\tlearn: 0.0471614\ttotal: 5.67s\tremaining: 5.29s\n",
            "517:\tlearn: 0.0470424\ttotal: 5.68s\tremaining: 5.29s\n",
            "518:\tlearn: 0.0469653\ttotal: 5.7s\tremaining: 5.28s\n",
            "519:\tlearn: 0.0468788\ttotal: 5.71s\tremaining: 5.27s\n",
            "520:\tlearn: 0.0467742\ttotal: 5.72s\tremaining: 5.26s\n",
            "521:\tlearn: 0.0467116\ttotal: 5.73s\tremaining: 5.25s\n",
            "522:\tlearn: 0.0465802\ttotal: 5.74s\tremaining: 5.23s\n",
            "523:\tlearn: 0.0464688\ttotal: 5.75s\tremaining: 5.22s\n",
            "524:\tlearn: 0.0463726\ttotal: 5.76s\tremaining: 5.21s\n",
            "525:\tlearn: 0.0462673\ttotal: 5.77s\tremaining: 5.2s\n",
            "526:\tlearn: 0.0461956\ttotal: 5.78s\tremaining: 5.19s\n",
            "527:\tlearn: 0.0460903\ttotal: 5.79s\tremaining: 5.18s\n",
            "528:\tlearn: 0.0460061\ttotal: 5.8s\tremaining: 5.17s\n",
            "529:\tlearn: 0.0459067\ttotal: 5.81s\tremaining: 5.16s\n",
            "530:\tlearn: 0.0457946\ttotal: 5.82s\tremaining: 5.14s\n",
            "531:\tlearn: 0.0457220\ttotal: 5.84s\tremaining: 5.14s\n",
            "532:\tlearn: 0.0456694\ttotal: 5.85s\tremaining: 5.13s\n",
            "533:\tlearn: 0.0455769\ttotal: 5.86s\tremaining: 5.11s\n",
            "534:\tlearn: 0.0454789\ttotal: 5.87s\tremaining: 5.1s\n",
            "535:\tlearn: 0.0453954\ttotal: 5.88s\tremaining: 5.09s\n",
            "536:\tlearn: 0.0453023\ttotal: 5.89s\tremaining: 5.08s\n",
            "537:\tlearn: 0.0452058\ttotal: 5.9s\tremaining: 5.07s\n",
            "538:\tlearn: 0.0451091\ttotal: 5.91s\tremaining: 5.06s\n",
            "539:\tlearn: 0.0450411\ttotal: 5.92s\tremaining: 5.04s\n",
            "540:\tlearn: 0.0449531\ttotal: 5.93s\tremaining: 5.03s\n",
            "541:\tlearn: 0.0448516\ttotal: 5.94s\tremaining: 5.02s\n",
            "542:\tlearn: 0.0447591\ttotal: 5.95s\tremaining: 5.01s\n",
            "543:\tlearn: 0.0446456\ttotal: 5.96s\tremaining: 5s\n",
            "544:\tlearn: 0.0445794\ttotal: 5.98s\tremaining: 4.99s\n",
            "545:\tlearn: 0.0444591\ttotal: 5.99s\tremaining: 4.98s\n",
            "546:\tlearn: 0.0443406\ttotal: 6s\tremaining: 4.97s\n",
            "547:\tlearn: 0.0442522\ttotal: 6.01s\tremaining: 4.96s\n",
            "548:\tlearn: 0.0441831\ttotal: 6.02s\tremaining: 4.95s\n",
            "549:\tlearn: 0.0440771\ttotal: 6.04s\tremaining: 4.94s\n",
            "550:\tlearn: 0.0439567\ttotal: 6.05s\tremaining: 4.93s\n",
            "551:\tlearn: 0.0438348\ttotal: 6.06s\tremaining: 4.92s\n",
            "552:\tlearn: 0.0437399\ttotal: 6.07s\tremaining: 4.91s\n",
            "553:\tlearn: 0.0436427\ttotal: 6.08s\tremaining: 4.89s\n",
            "554:\tlearn: 0.0435590\ttotal: 6.09s\tremaining: 4.88s\n",
            "555:\tlearn: 0.0434389\ttotal: 6.1s\tremaining: 4.87s\n",
            "556:\tlearn: 0.0433393\ttotal: 6.11s\tremaining: 4.86s\n",
            "557:\tlearn: 0.0432711\ttotal: 6.12s\tremaining: 4.85s\n",
            "558:\tlearn: 0.0431436\ttotal: 6.13s\tremaining: 4.84s\n",
            "559:\tlearn: 0.0430500\ttotal: 6.14s\tremaining: 4.83s\n",
            "560:\tlearn: 0.0429287\ttotal: 6.15s\tremaining: 4.82s\n",
            "561:\tlearn: 0.0428639\ttotal: 6.16s\tremaining: 4.8s\n",
            "562:\tlearn: 0.0427782\ttotal: 6.17s\tremaining: 4.79s\n",
            "563:\tlearn: 0.0427423\ttotal: 6.19s\tremaining: 4.79s\n",
            "564:\tlearn: 0.0426000\ttotal: 6.2s\tremaining: 4.77s\n",
            "565:\tlearn: 0.0425049\ttotal: 6.21s\tremaining: 4.76s\n",
            "566:\tlearn: 0.0423882\ttotal: 6.22s\tremaining: 4.75s\n",
            "567:\tlearn: 0.0423237\ttotal: 6.23s\tremaining: 4.74s\n",
            "568:\tlearn: 0.0422535\ttotal: 6.24s\tremaining: 4.73s\n",
            "569:\tlearn: 0.0421741\ttotal: 6.25s\tremaining: 4.72s\n",
            "570:\tlearn: 0.0421015\ttotal: 6.26s\tremaining: 4.71s\n",
            "571:\tlearn: 0.0419938\ttotal: 6.27s\tremaining: 4.69s\n",
            "572:\tlearn: 0.0418807\ttotal: 6.28s\tremaining: 4.68s\n",
            "573:\tlearn: 0.0417504\ttotal: 6.29s\tremaining: 4.67s\n",
            "574:\tlearn: 0.0416202\ttotal: 6.3s\tremaining: 4.66s\n",
            "575:\tlearn: 0.0415245\ttotal: 6.32s\tremaining: 4.65s\n",
            "576:\tlearn: 0.0414178\ttotal: 6.33s\tremaining: 4.64s\n",
            "577:\tlearn: 0.0412947\ttotal: 6.33s\tremaining: 4.63s\n",
            "578:\tlearn: 0.0412315\ttotal: 6.35s\tremaining: 4.61s\n",
            "579:\tlearn: 0.0411533\ttotal: 6.36s\tremaining: 4.6s\n",
            "580:\tlearn: 0.0410083\ttotal: 6.37s\tremaining: 4.59s\n",
            "581:\tlearn: 0.0409510\ttotal: 6.38s\tremaining: 4.58s\n",
            "582:\tlearn: 0.0408668\ttotal: 6.39s\tremaining: 4.57s\n",
            "583:\tlearn: 0.0408155\ttotal: 6.41s\tremaining: 4.57s\n",
            "584:\tlearn: 0.0407328\ttotal: 6.42s\tremaining: 4.55s\n",
            "585:\tlearn: 0.0406481\ttotal: 6.44s\tremaining: 4.55s\n",
            "586:\tlearn: 0.0405477\ttotal: 6.45s\tremaining: 4.54s\n",
            "587:\tlearn: 0.0404430\ttotal: 6.46s\tremaining: 4.53s\n",
            "588:\tlearn: 0.0403651\ttotal: 6.47s\tremaining: 4.52s\n",
            "589:\tlearn: 0.0402733\ttotal: 6.48s\tremaining: 4.51s\n",
            "590:\tlearn: 0.0401470\ttotal: 6.49s\tremaining: 4.49s\n",
            "591:\tlearn: 0.0400585\ttotal: 6.5s\tremaining: 4.48s\n",
            "592:\tlearn: 0.0399850\ttotal: 6.51s\tremaining: 4.47s\n",
            "593:\tlearn: 0.0398889\ttotal: 6.53s\tremaining: 4.46s\n",
            "594:\tlearn: 0.0397859\ttotal: 6.54s\tremaining: 4.45s\n",
            "595:\tlearn: 0.0396808\ttotal: 6.55s\tremaining: 4.44s\n",
            "596:\tlearn: 0.0395837\ttotal: 6.56s\tremaining: 4.43s\n",
            "597:\tlearn: 0.0394988\ttotal: 6.57s\tremaining: 4.42s\n",
            "598:\tlearn: 0.0394499\ttotal: 6.58s\tremaining: 4.4s\n",
            "599:\tlearn: 0.0393694\ttotal: 6.59s\tremaining: 4.39s\n",
            "600:\tlearn: 0.0392627\ttotal: 6.6s\tremaining: 4.38s\n",
            "601:\tlearn: 0.0391834\ttotal: 6.61s\tremaining: 4.37s\n",
            "602:\tlearn: 0.0390728\ttotal: 6.62s\tremaining: 4.36s\n",
            "603:\tlearn: 0.0389856\ttotal: 6.63s\tremaining: 4.35s\n",
            "604:\tlearn: 0.0389281\ttotal: 6.65s\tremaining: 4.34s\n",
            "605:\tlearn: 0.0388590\ttotal: 6.66s\tremaining: 4.33s\n",
            "606:\tlearn: 0.0387831\ttotal: 6.67s\tremaining: 4.32s\n",
            "607:\tlearn: 0.0387302\ttotal: 6.68s\tremaining: 4.31s\n",
            "608:\tlearn: 0.0386388\ttotal: 6.69s\tremaining: 4.3s\n",
            "609:\tlearn: 0.0385514\ttotal: 6.7s\tremaining: 4.29s\n",
            "610:\tlearn: 0.0385166\ttotal: 6.71s\tremaining: 4.27s\n",
            "611:\tlearn: 0.0384247\ttotal: 6.72s\tremaining: 4.26s\n",
            "612:\tlearn: 0.0383536\ttotal: 6.74s\tremaining: 4.25s\n",
            "613:\tlearn: 0.0382960\ttotal: 6.75s\tremaining: 4.24s\n",
            "614:\tlearn: 0.0382246\ttotal: 6.75s\tremaining: 4.23s\n",
            "615:\tlearn: 0.0381530\ttotal: 6.76s\tremaining: 4.22s\n",
            "616:\tlearn: 0.0380835\ttotal: 6.78s\tremaining: 4.21s\n",
            "617:\tlearn: 0.0380193\ttotal: 6.79s\tremaining: 4.2s\n",
            "618:\tlearn: 0.0379529\ttotal: 6.8s\tremaining: 4.19s\n",
            "619:\tlearn: 0.0378913\ttotal: 6.82s\tremaining: 4.18s\n",
            "620:\tlearn: 0.0377994\ttotal: 6.83s\tremaining: 4.17s\n",
            "621:\tlearn: 0.0377199\ttotal: 6.84s\tremaining: 4.15s\n",
            "622:\tlearn: 0.0376167\ttotal: 6.85s\tremaining: 4.14s\n",
            "623:\tlearn: 0.0375199\ttotal: 6.86s\tremaining: 4.13s\n",
            "624:\tlearn: 0.0374360\ttotal: 6.87s\tremaining: 4.12s\n",
            "625:\tlearn: 0.0373737\ttotal: 6.88s\tremaining: 4.11s\n",
            "626:\tlearn: 0.0372387\ttotal: 6.89s\tremaining: 4.1s\n",
            "627:\tlearn: 0.0372101\ttotal: 6.9s\tremaining: 4.09s\n",
            "628:\tlearn: 0.0371232\ttotal: 6.91s\tremaining: 4.07s\n",
            "629:\tlearn: 0.0370415\ttotal: 6.92s\tremaining: 4.06s\n",
            "630:\tlearn: 0.0369848\ttotal: 6.93s\tremaining: 4.05s\n",
            "631:\tlearn: 0.0369541\ttotal: 6.94s\tremaining: 4.04s\n",
            "632:\tlearn: 0.0368980\ttotal: 6.95s\tremaining: 4.03s\n",
            "633:\tlearn: 0.0368260\ttotal: 6.96s\tremaining: 4.02s\n",
            "634:\tlearn: 0.0367592\ttotal: 6.97s\tremaining: 4.01s\n",
            "635:\tlearn: 0.0366615\ttotal: 6.98s\tremaining: 4s\n",
            "636:\tlearn: 0.0366105\ttotal: 6.99s\tremaining: 3.98s\n",
            "637:\tlearn: 0.0365333\ttotal: 7.01s\tremaining: 3.98s\n",
            "638:\tlearn: 0.0364541\ttotal: 7.02s\tremaining: 3.96s\n",
            "639:\tlearn: 0.0363936\ttotal: 7.03s\tremaining: 3.95s\n",
            "640:\tlearn: 0.0363130\ttotal: 7.04s\tremaining: 3.94s\n",
            "641:\tlearn: 0.0362540\ttotal: 7.05s\tremaining: 3.93s\n",
            "642:\tlearn: 0.0361897\ttotal: 7.06s\tremaining: 3.92s\n",
            "643:\tlearn: 0.0361321\ttotal: 7.07s\tremaining: 3.91s\n",
            "644:\tlearn: 0.0360445\ttotal: 7.08s\tremaining: 3.9s\n",
            "645:\tlearn: 0.0359729\ttotal: 7.09s\tremaining: 3.89s\n",
            "646:\tlearn: 0.0358779\ttotal: 7.1s\tremaining: 3.87s\n",
            "647:\tlearn: 0.0358468\ttotal: 7.11s\tremaining: 3.86s\n",
            "648:\tlearn: 0.0358143\ttotal: 7.12s\tremaining: 3.85s\n",
            "649:\tlearn: 0.0357507\ttotal: 7.13s\tremaining: 3.84s\n",
            "650:\tlearn: 0.0356570\ttotal: 7.14s\tremaining: 3.83s\n",
            "651:\tlearn: 0.0355843\ttotal: 7.15s\tremaining: 3.82s\n",
            "652:\tlearn: 0.0355161\ttotal: 7.16s\tremaining: 3.81s\n",
            "653:\tlearn: 0.0354835\ttotal: 7.17s\tremaining: 3.79s\n",
            "654:\tlearn: 0.0354303\ttotal: 7.18s\tremaining: 3.78s\n",
            "655:\tlearn: 0.0353581\ttotal: 7.19s\tremaining: 3.77s\n",
            "656:\tlearn: 0.0352728\ttotal: 7.2s\tremaining: 3.76s\n",
            "657:\tlearn: 0.0351864\ttotal: 7.22s\tremaining: 3.75s\n",
            "658:\tlearn: 0.0351208\ttotal: 7.23s\tremaining: 3.74s\n",
            "659:\tlearn: 0.0350795\ttotal: 7.24s\tremaining: 3.73s\n",
            "660:\tlearn: 0.0349872\ttotal: 7.25s\tremaining: 3.72s\n",
            "661:\tlearn: 0.0349435\ttotal: 7.26s\tremaining: 3.71s\n",
            "662:\tlearn: 0.0349102\ttotal: 7.27s\tremaining: 3.69s\n",
            "663:\tlearn: 0.0348305\ttotal: 7.28s\tremaining: 3.68s\n",
            "664:\tlearn: 0.0347553\ttotal: 7.29s\tremaining: 3.67s\n",
            "665:\tlearn: 0.0346825\ttotal: 7.3s\tremaining: 3.66s\n",
            "666:\tlearn: 0.0346134\ttotal: 7.31s\tremaining: 3.65s\n",
            "667:\tlearn: 0.0345214\ttotal: 7.32s\tremaining: 3.64s\n",
            "668:\tlearn: 0.0344769\ttotal: 7.33s\tremaining: 3.63s\n",
            "669:\tlearn: 0.0344112\ttotal: 7.34s\tremaining: 3.62s\n",
            "670:\tlearn: 0.0343445\ttotal: 7.35s\tremaining: 3.6s\n",
            "671:\tlearn: 0.0343251\ttotal: 7.36s\tremaining: 3.59s\n",
            "672:\tlearn: 0.0342260\ttotal: 7.37s\tremaining: 3.58s\n",
            "673:\tlearn: 0.0341857\ttotal: 7.38s\tremaining: 3.57s\n",
            "674:\tlearn: 0.0341191\ttotal: 7.39s\tremaining: 3.56s\n",
            "675:\tlearn: 0.0340581\ttotal: 7.41s\tremaining: 3.55s\n",
            "676:\tlearn: 0.0339820\ttotal: 7.43s\tremaining: 3.55s\n",
            "677:\tlearn: 0.0339254\ttotal: 7.45s\tremaining: 3.54s\n",
            "678:\tlearn: 0.0338854\ttotal: 7.46s\tremaining: 3.52s\n",
            "679:\tlearn: 0.0338223\ttotal: 7.47s\tremaining: 3.51s\n",
            "680:\tlearn: 0.0337805\ttotal: 7.48s\tremaining: 3.5s\n",
            "681:\tlearn: 0.0337203\ttotal: 7.49s\tremaining: 3.49s\n",
            "682:\tlearn: 0.0336531\ttotal: 7.5s\tremaining: 3.48s\n",
            "683:\tlearn: 0.0335586\ttotal: 7.51s\tremaining: 3.47s\n",
            "684:\tlearn: 0.0334854\ttotal: 7.52s\tremaining: 3.46s\n",
            "685:\tlearn: 0.0334219\ttotal: 7.53s\tremaining: 3.45s\n",
            "686:\tlearn: 0.0333564\ttotal: 7.54s\tremaining: 3.43s\n",
            "687:\tlearn: 0.0332824\ttotal: 7.55s\tremaining: 3.42s\n",
            "688:\tlearn: 0.0332200\ttotal: 7.56s\tremaining: 3.41s\n",
            "689:\tlearn: 0.0331769\ttotal: 7.57s\tremaining: 3.4s\n",
            "690:\tlearn: 0.0331149\ttotal: 7.58s\tremaining: 3.39s\n",
            "691:\tlearn: 0.0330199\ttotal: 7.59s\tremaining: 3.38s\n",
            "692:\tlearn: 0.0329653\ttotal: 7.6s\tremaining: 3.37s\n",
            "693:\tlearn: 0.0329017\ttotal: 7.61s\tremaining: 3.36s\n",
            "694:\tlearn: 0.0328232\ttotal: 7.63s\tremaining: 3.35s\n",
            "695:\tlearn: 0.0327517\ttotal: 7.64s\tremaining: 3.34s\n",
            "696:\tlearn: 0.0326826\ttotal: 7.65s\tremaining: 3.33s\n",
            "697:\tlearn: 0.0325882\ttotal: 7.66s\tremaining: 3.31s\n",
            "698:\tlearn: 0.0325577\ttotal: 7.67s\tremaining: 3.3s\n",
            "699:\tlearn: 0.0325071\ttotal: 7.68s\tremaining: 3.29s\n",
            "700:\tlearn: 0.0324472\ttotal: 7.69s\tremaining: 3.28s\n",
            "701:\tlearn: 0.0323785\ttotal: 7.7s\tremaining: 3.27s\n",
            "702:\tlearn: 0.0323192\ttotal: 7.71s\tremaining: 3.26s\n",
            "703:\tlearn: 0.0322568\ttotal: 7.72s\tremaining: 3.25s\n",
            "704:\tlearn: 0.0321853\ttotal: 7.73s\tremaining: 3.24s\n",
            "705:\tlearn: 0.0321069\ttotal: 7.74s\tremaining: 3.22s\n",
            "706:\tlearn: 0.0320710\ttotal: 7.75s\tremaining: 3.21s\n",
            "707:\tlearn: 0.0320369\ttotal: 7.76s\tremaining: 3.2s\n",
            "708:\tlearn: 0.0319733\ttotal: 7.78s\tremaining: 3.19s\n",
            "709:\tlearn: 0.0319486\ttotal: 7.79s\tremaining: 3.18s\n",
            "710:\tlearn: 0.0318810\ttotal: 7.79s\tremaining: 3.17s\n",
            "711:\tlearn: 0.0318309\ttotal: 7.81s\tremaining: 3.16s\n",
            "712:\tlearn: 0.0317746\ttotal: 7.82s\tremaining: 3.15s\n",
            "713:\tlearn: 0.0317138\ttotal: 7.83s\tremaining: 3.14s\n",
            "714:\tlearn: 0.0316540\ttotal: 7.84s\tremaining: 3.13s\n",
            "715:\tlearn: 0.0315591\ttotal: 7.85s\tremaining: 3.12s\n",
            "716:\tlearn: 0.0314886\ttotal: 7.86s\tremaining: 3.1s\n",
            "717:\tlearn: 0.0314550\ttotal: 7.87s\tremaining: 3.09s\n",
            "718:\tlearn: 0.0313743\ttotal: 7.88s\tremaining: 3.08s\n",
            "719:\tlearn: 0.0313183\ttotal: 7.89s\tremaining: 3.07s\n",
            "720:\tlearn: 0.0312834\ttotal: 7.91s\tremaining: 3.06s\n",
            "721:\tlearn: 0.0312239\ttotal: 7.92s\tremaining: 3.05s\n",
            "722:\tlearn: 0.0311572\ttotal: 7.93s\tremaining: 3.04s\n",
            "723:\tlearn: 0.0310527\ttotal: 7.94s\tremaining: 3.03s\n",
            "724:\tlearn: 0.0310030\ttotal: 7.95s\tremaining: 3.01s\n",
            "725:\tlearn: 0.0309481\ttotal: 7.96s\tremaining: 3s\n",
            "726:\tlearn: 0.0308967\ttotal: 7.99s\tremaining: 3s\n",
            "727:\tlearn: 0.0308261\ttotal: 8s\tremaining: 2.99s\n",
            "728:\tlearn: 0.0307792\ttotal: 8.02s\tremaining: 2.98s\n",
            "729:\tlearn: 0.0307059\ttotal: 8.04s\tremaining: 2.98s\n",
            "730:\tlearn: 0.0306481\ttotal: 8.06s\tremaining: 2.97s\n",
            "731:\tlearn: 0.0305873\ttotal: 8.08s\tremaining: 2.96s\n",
            "732:\tlearn: 0.0304949\ttotal: 8.1s\tremaining: 2.95s\n",
            "733:\tlearn: 0.0304424\ttotal: 8.13s\tremaining: 2.94s\n",
            "734:\tlearn: 0.0303987\ttotal: 8.15s\tremaining: 2.94s\n",
            "735:\tlearn: 0.0303458\ttotal: 8.17s\tremaining: 2.93s\n",
            "736:\tlearn: 0.0302787\ttotal: 8.18s\tremaining: 2.92s\n",
            "737:\tlearn: 0.0302162\ttotal: 8.21s\tremaining: 2.91s\n",
            "738:\tlearn: 0.0301699\ttotal: 8.23s\tremaining: 2.91s\n",
            "739:\tlearn: 0.0301106\ttotal: 8.26s\tremaining: 2.9s\n",
            "740:\tlearn: 0.0300820\ttotal: 8.28s\tremaining: 2.9s\n",
            "741:\tlearn: 0.0299995\ttotal: 8.3s\tremaining: 2.89s\n",
            "742:\tlearn: 0.0299790\ttotal: 8.32s\tremaining: 2.88s\n",
            "743:\tlearn: 0.0299430\ttotal: 8.35s\tremaining: 2.87s\n",
            "744:\tlearn: 0.0298763\ttotal: 8.37s\tremaining: 2.86s\n",
            "745:\tlearn: 0.0298027\ttotal: 8.38s\tremaining: 2.85s\n",
            "746:\tlearn: 0.0297622\ttotal: 8.39s\tremaining: 2.84s\n",
            "747:\tlearn: 0.0296926\ttotal: 8.41s\tremaining: 2.83s\n",
            "748:\tlearn: 0.0296570\ttotal: 8.43s\tremaining: 2.83s\n",
            "749:\tlearn: 0.0296075\ttotal: 8.46s\tremaining: 2.82s\n",
            "750:\tlearn: 0.0295271\ttotal: 8.48s\tremaining: 2.81s\n",
            "751:\tlearn: 0.0295032\ttotal: 8.49s\tremaining: 2.8s\n",
            "752:\tlearn: 0.0294408\ttotal: 8.51s\tremaining: 2.79s\n",
            "753:\tlearn: 0.0293821\ttotal: 8.52s\tremaining: 2.78s\n",
            "754:\tlearn: 0.0293207\ttotal: 8.54s\tremaining: 2.77s\n",
            "755:\tlearn: 0.0292458\ttotal: 8.55s\tremaining: 2.76s\n",
            "756:\tlearn: 0.0291950\ttotal: 8.56s\tremaining: 2.75s\n",
            "757:\tlearn: 0.0291184\ttotal: 8.57s\tremaining: 2.74s\n",
            "758:\tlearn: 0.0290753\ttotal: 8.59s\tremaining: 2.73s\n",
            "759:\tlearn: 0.0290002\ttotal: 8.61s\tremaining: 2.72s\n",
            "760:\tlearn: 0.0289062\ttotal: 8.62s\tremaining: 2.71s\n",
            "761:\tlearn: 0.0288521\ttotal: 8.64s\tremaining: 2.7s\n",
            "762:\tlearn: 0.0287867\ttotal: 8.66s\tremaining: 2.69s\n",
            "763:\tlearn: 0.0287345\ttotal: 8.67s\tremaining: 2.68s\n",
            "764:\tlearn: 0.0286834\ttotal: 8.69s\tremaining: 2.67s\n",
            "765:\tlearn: 0.0286164\ttotal: 8.71s\tremaining: 2.66s\n",
            "766:\tlearn: 0.0285560\ttotal: 8.73s\tremaining: 2.65s\n",
            "767:\tlearn: 0.0285180\ttotal: 8.76s\tremaining: 2.65s\n",
            "768:\tlearn: 0.0284945\ttotal: 8.78s\tremaining: 2.64s\n",
            "769:\tlearn: 0.0284292\ttotal: 8.8s\tremaining: 2.63s\n",
            "770:\tlearn: 0.0283598\ttotal: 8.82s\tremaining: 2.62s\n",
            "771:\tlearn: 0.0283308\ttotal: 8.85s\tremaining: 2.61s\n",
            "772:\tlearn: 0.0282585\ttotal: 8.87s\tremaining: 2.6s\n",
            "773:\tlearn: 0.0281868\ttotal: 8.89s\tremaining: 2.6s\n",
            "774:\tlearn: 0.0281428\ttotal: 8.91s\tremaining: 2.59s\n",
            "775:\tlearn: 0.0280998\ttotal: 8.93s\tremaining: 2.58s\n",
            "776:\tlearn: 0.0280482\ttotal: 8.95s\tremaining: 2.57s\n",
            "777:\tlearn: 0.0279941\ttotal: 8.97s\tremaining: 2.56s\n",
            "778:\tlearn: 0.0279464\ttotal: 8.99s\tremaining: 2.55s\n",
            "779:\tlearn: 0.0278850\ttotal: 9.01s\tremaining: 2.54s\n",
            "780:\tlearn: 0.0278368\ttotal: 9.03s\tremaining: 2.53s\n",
            "781:\tlearn: 0.0277846\ttotal: 9.06s\tremaining: 2.52s\n",
            "782:\tlearn: 0.0277383\ttotal: 9.08s\tremaining: 2.52s\n",
            "783:\tlearn: 0.0276965\ttotal: 9.1s\tremaining: 2.51s\n",
            "784:\tlearn: 0.0276701\ttotal: 9.12s\tremaining: 2.5s\n",
            "785:\tlearn: 0.0276259\ttotal: 9.14s\tremaining: 2.49s\n",
            "786:\tlearn: 0.0275743\ttotal: 9.15s\tremaining: 2.48s\n",
            "787:\tlearn: 0.0275245\ttotal: 9.17s\tremaining: 2.47s\n",
            "788:\tlearn: 0.0274611\ttotal: 9.18s\tremaining: 2.46s\n",
            "789:\tlearn: 0.0274191\ttotal: 9.2s\tremaining: 2.44s\n",
            "790:\tlearn: 0.0273706\ttotal: 9.22s\tremaining: 2.44s\n",
            "791:\tlearn: 0.0273399\ttotal: 9.24s\tremaining: 2.42s\n",
            "792:\tlearn: 0.0272875\ttotal: 9.26s\tremaining: 2.42s\n",
            "793:\tlearn: 0.0272496\ttotal: 9.28s\tremaining: 2.41s\n",
            "794:\tlearn: 0.0271799\ttotal: 9.3s\tremaining: 2.4s\n",
            "795:\tlearn: 0.0271292\ttotal: 9.32s\tremaining: 2.39s\n",
            "796:\tlearn: 0.0270833\ttotal: 9.34s\tremaining: 2.38s\n",
            "797:\tlearn: 0.0270454\ttotal: 9.36s\tremaining: 2.37s\n",
            "798:\tlearn: 0.0270041\ttotal: 9.38s\tremaining: 2.36s\n",
            "799:\tlearn: 0.0269356\ttotal: 9.4s\tremaining: 2.35s\n",
            "800:\tlearn: 0.0268778\ttotal: 9.43s\tremaining: 2.34s\n",
            "801:\tlearn: 0.0268219\ttotal: 9.45s\tremaining: 2.33s\n",
            "802:\tlearn: 0.0267752\ttotal: 9.48s\tremaining: 2.32s\n",
            "803:\tlearn: 0.0267083\ttotal: 9.49s\tremaining: 2.31s\n",
            "804:\tlearn: 0.0266717\ttotal: 9.51s\tremaining: 2.3s\n",
            "805:\tlearn: 0.0266269\ttotal: 9.53s\tremaining: 2.29s\n",
            "806:\tlearn: 0.0265907\ttotal: 9.56s\tremaining: 2.29s\n",
            "807:\tlearn: 0.0265396\ttotal: 9.59s\tremaining: 2.28s\n",
            "808:\tlearn: 0.0264771\ttotal: 9.61s\tremaining: 2.27s\n",
            "809:\tlearn: 0.0264286\ttotal: 9.63s\tremaining: 2.26s\n",
            "810:\tlearn: 0.0263647\ttotal: 9.64s\tremaining: 2.25s\n",
            "811:\tlearn: 0.0263202\ttotal: 9.67s\tremaining: 2.24s\n",
            "812:\tlearn: 0.0262967\ttotal: 9.69s\tremaining: 2.23s\n",
            "813:\tlearn: 0.0262394\ttotal: 9.71s\tremaining: 2.22s\n",
            "814:\tlearn: 0.0261773\ttotal: 9.73s\tremaining: 2.21s\n",
            "815:\tlearn: 0.0261271\ttotal: 9.75s\tremaining: 2.2s\n",
            "816:\tlearn: 0.0260639\ttotal: 9.77s\tremaining: 2.19s\n",
            "817:\tlearn: 0.0260187\ttotal: 9.79s\tremaining: 2.18s\n",
            "818:\tlearn: 0.0259903\ttotal: 9.8s\tremaining: 2.17s\n",
            "819:\tlearn: 0.0259462\ttotal: 9.82s\tremaining: 2.16s\n",
            "820:\tlearn: 0.0259082\ttotal: 9.84s\tremaining: 2.15s\n",
            "821:\tlearn: 0.0258614\ttotal: 9.86s\tremaining: 2.13s\n",
            "822:\tlearn: 0.0258184\ttotal: 9.88s\tremaining: 2.13s\n",
            "823:\tlearn: 0.0257479\ttotal: 9.91s\tremaining: 2.12s\n",
            "824:\tlearn: 0.0257105\ttotal: 9.93s\tremaining: 2.1s\n",
            "825:\tlearn: 0.0256723\ttotal: 9.95s\tremaining: 2.1s\n",
            "826:\tlearn: 0.0256248\ttotal: 9.97s\tremaining: 2.08s\n",
            "827:\tlearn: 0.0255833\ttotal: 9.99s\tremaining: 2.07s\n",
            "828:\tlearn: 0.0255538\ttotal: 10s\tremaining: 2.07s\n",
            "829:\tlearn: 0.0255078\ttotal: 10s\tremaining: 2.06s\n",
            "830:\tlearn: 0.0254711\ttotal: 10.1s\tremaining: 2.04s\n",
            "831:\tlearn: 0.0254108\ttotal: 10.1s\tremaining: 2.04s\n",
            "832:\tlearn: 0.0253530\ttotal: 10.1s\tremaining: 2.03s\n",
            "833:\tlearn: 0.0252850\ttotal: 10.1s\tremaining: 2.02s\n",
            "834:\tlearn: 0.0252457\ttotal: 10.2s\tremaining: 2.01s\n",
            "835:\tlearn: 0.0251877\ttotal: 10.2s\tremaining: 2s\n",
            "836:\tlearn: 0.0251361\ttotal: 10.2s\tremaining: 1.99s\n",
            "837:\tlearn: 0.0250919\ttotal: 10.2s\tremaining: 1.97s\n",
            "838:\tlearn: 0.0250628\ttotal: 10.2s\tremaining: 1.96s\n",
            "839:\tlearn: 0.0250091\ttotal: 10.3s\tremaining: 1.95s\n",
            "840:\tlearn: 0.0249449\ttotal: 10.3s\tremaining: 1.94s\n",
            "841:\tlearn: 0.0248845\ttotal: 10.3s\tremaining: 1.93s\n",
            "842:\tlearn: 0.0248517\ttotal: 10.3s\tremaining: 1.92s\n",
            "843:\tlearn: 0.0248030\ttotal: 10.3s\tremaining: 1.91s\n",
            "844:\tlearn: 0.0247763\ttotal: 10.4s\tremaining: 1.9s\n",
            "845:\tlearn: 0.0247405\ttotal: 10.4s\tremaining: 1.89s\n",
            "846:\tlearn: 0.0247011\ttotal: 10.4s\tremaining: 1.88s\n",
            "847:\tlearn: 0.0246773\ttotal: 10.4s\tremaining: 1.87s\n",
            "848:\tlearn: 0.0246308\ttotal: 10.4s\tremaining: 1.86s\n",
            "849:\tlearn: 0.0245530\ttotal: 10.5s\tremaining: 1.85s\n",
            "850:\tlearn: 0.0245128\ttotal: 10.5s\tremaining: 1.84s\n",
            "851:\tlearn: 0.0244838\ttotal: 10.5s\tremaining: 1.83s\n",
            "852:\tlearn: 0.0244454\ttotal: 10.6s\tremaining: 1.82s\n",
            "853:\tlearn: 0.0243964\ttotal: 10.6s\tremaining: 1.81s\n",
            "854:\tlearn: 0.0243423\ttotal: 10.6s\tremaining: 1.8s\n",
            "855:\tlearn: 0.0242998\ttotal: 10.6s\tremaining: 1.79s\n",
            "856:\tlearn: 0.0242566\ttotal: 10.6s\tremaining: 1.78s\n",
            "857:\tlearn: 0.0242131\ttotal: 10.7s\tremaining: 1.76s\n",
            "858:\tlearn: 0.0241678\ttotal: 10.7s\tremaining: 1.75s\n",
            "859:\tlearn: 0.0241387\ttotal: 10.7s\tremaining: 1.74s\n",
            "860:\tlearn: 0.0240669\ttotal: 10.7s\tremaining: 1.73s\n",
            "861:\tlearn: 0.0240209\ttotal: 10.8s\tremaining: 1.72s\n",
            "862:\tlearn: 0.0239620\ttotal: 10.8s\tremaining: 1.71s\n",
            "863:\tlearn: 0.0239104\ttotal: 10.8s\tremaining: 1.7s\n",
            "864:\tlearn: 0.0238830\ttotal: 10.8s\tremaining: 1.69s\n",
            "865:\tlearn: 0.0238407\ttotal: 10.8s\tremaining: 1.68s\n",
            "866:\tlearn: 0.0237937\ttotal: 10.9s\tremaining: 1.67s\n",
            "867:\tlearn: 0.0237404\ttotal: 10.9s\tremaining: 1.65s\n",
            "868:\tlearn: 0.0236997\ttotal: 10.9s\tremaining: 1.64s\n",
            "869:\tlearn: 0.0236587\ttotal: 10.9s\tremaining: 1.63s\n",
            "870:\tlearn: 0.0236308\ttotal: 11s\tremaining: 1.62s\n",
            "871:\tlearn: 0.0235823\ttotal: 11s\tremaining: 1.61s\n",
            "872:\tlearn: 0.0235258\ttotal: 11s\tremaining: 1.6s\n",
            "873:\tlearn: 0.0234949\ttotal: 11s\tremaining: 1.59s\n",
            "874:\tlearn: 0.0234476\ttotal: 11s\tremaining: 1.58s\n",
            "875:\tlearn: 0.0234077\ttotal: 11.1s\tremaining: 1.56s\n",
            "876:\tlearn: 0.0233672\ttotal: 11.1s\tremaining: 1.55s\n",
            "877:\tlearn: 0.0233064\ttotal: 11.1s\tremaining: 1.54s\n",
            "878:\tlearn: 0.0232415\ttotal: 11.1s\tremaining: 1.53s\n",
            "879:\tlearn: 0.0232101\ttotal: 11.2s\tremaining: 1.52s\n",
            "880:\tlearn: 0.0231563\ttotal: 11.2s\tremaining: 1.51s\n",
            "881:\tlearn: 0.0231029\ttotal: 11.2s\tremaining: 1.5s\n",
            "882:\tlearn: 0.0230676\ttotal: 11.2s\tremaining: 1.49s\n",
            "883:\tlearn: 0.0230152\ttotal: 11.2s\tremaining: 1.48s\n",
            "884:\tlearn: 0.0229623\ttotal: 11.3s\tremaining: 1.46s\n",
            "885:\tlearn: 0.0229156\ttotal: 11.3s\tremaining: 1.45s\n",
            "886:\tlearn: 0.0228757\ttotal: 11.3s\tremaining: 1.44s\n",
            "887:\tlearn: 0.0228364\ttotal: 11.3s\tremaining: 1.43s\n",
            "888:\tlearn: 0.0227799\ttotal: 11.4s\tremaining: 1.42s\n",
            "889:\tlearn: 0.0227190\ttotal: 11.4s\tremaining: 1.41s\n",
            "890:\tlearn: 0.0226467\ttotal: 11.4s\tremaining: 1.39s\n",
            "891:\tlearn: 0.0226114\ttotal: 11.4s\tremaining: 1.38s\n",
            "892:\tlearn: 0.0225749\ttotal: 11.4s\tremaining: 1.37s\n",
            "893:\tlearn: 0.0225407\ttotal: 11.4s\tremaining: 1.35s\n",
            "894:\tlearn: 0.0224965\ttotal: 11.4s\tremaining: 1.34s\n",
            "895:\tlearn: 0.0224626\ttotal: 11.5s\tremaining: 1.33s\n",
            "896:\tlearn: 0.0224089\ttotal: 11.5s\tremaining: 1.32s\n",
            "897:\tlearn: 0.0223594\ttotal: 11.5s\tremaining: 1.31s\n",
            "898:\tlearn: 0.0223073\ttotal: 11.6s\tremaining: 1.3s\n",
            "899:\tlearn: 0.0222767\ttotal: 11.6s\tremaining: 1.28s\n",
            "900:\tlearn: 0.0222332\ttotal: 11.6s\tremaining: 1.27s\n",
            "901:\tlearn: 0.0222135\ttotal: 11.6s\tremaining: 1.26s\n",
            "902:\tlearn: 0.0221739\ttotal: 11.6s\tremaining: 1.25s\n",
            "903:\tlearn: 0.0221369\ttotal: 11.7s\tremaining: 1.24s\n",
            "904:\tlearn: 0.0220988\ttotal: 11.7s\tremaining: 1.23s\n",
            "905:\tlearn: 0.0220408\ttotal: 11.7s\tremaining: 1.21s\n",
            "906:\tlearn: 0.0220295\ttotal: 11.7s\tremaining: 1.2s\n",
            "907:\tlearn: 0.0219827\ttotal: 11.7s\tremaining: 1.19s\n",
            "908:\tlearn: 0.0219379\ttotal: 11.8s\tremaining: 1.18s\n",
            "909:\tlearn: 0.0219001\ttotal: 11.8s\tremaining: 1.17s\n",
            "910:\tlearn: 0.0218377\ttotal: 11.8s\tremaining: 1.15s\n",
            "911:\tlearn: 0.0218012\ttotal: 11.8s\tremaining: 1.14s\n",
            "912:\tlearn: 0.0217807\ttotal: 11.8s\tremaining: 1.13s\n",
            "913:\tlearn: 0.0217415\ttotal: 11.9s\tremaining: 1.12s\n",
            "914:\tlearn: 0.0217117\ttotal: 11.9s\tremaining: 1.1s\n",
            "915:\tlearn: 0.0216800\ttotal: 11.9s\tremaining: 1.09s\n",
            "916:\tlearn: 0.0216311\ttotal: 11.9s\tremaining: 1.08s\n",
            "917:\tlearn: 0.0215787\ttotal: 12s\tremaining: 1.07s\n",
            "918:\tlearn: 0.0215455\ttotal: 12s\tremaining: 1.06s\n",
            "919:\tlearn: 0.0215027\ttotal: 12s\tremaining: 1.04s\n",
            "920:\tlearn: 0.0214773\ttotal: 12s\tremaining: 1.03s\n",
            "921:\tlearn: 0.0214468\ttotal: 12.1s\tremaining: 1.02s\n",
            "922:\tlearn: 0.0214130\ttotal: 12.1s\tremaining: 1.01s\n",
            "923:\tlearn: 0.0213661\ttotal: 12.1s\tremaining: 995ms\n",
            "924:\tlearn: 0.0213464\ttotal: 12.1s\tremaining: 982ms\n",
            "925:\tlearn: 0.0213101\ttotal: 12.1s\tremaining: 971ms\n",
            "926:\tlearn: 0.0212747\ttotal: 12.2s\tremaining: 958ms\n",
            "927:\tlearn: 0.0212395\ttotal: 12.2s\tremaining: 946ms\n",
            "928:\tlearn: 0.0212152\ttotal: 12.2s\tremaining: 933ms\n",
            "929:\tlearn: 0.0211756\ttotal: 12.2s\tremaining: 920ms\n",
            "930:\tlearn: 0.0211491\ttotal: 12.2s\tremaining: 908ms\n",
            "931:\tlearn: 0.0211018\ttotal: 12.3s\tremaining: 895ms\n",
            "932:\tlearn: 0.0210601\ttotal: 12.3s\tremaining: 883ms\n",
            "933:\tlearn: 0.0210373\ttotal: 12.3s\tremaining: 870ms\n",
            "934:\tlearn: 0.0209986\ttotal: 12.3s\tremaining: 857ms\n",
            "935:\tlearn: 0.0209561\ttotal: 12.3s\tremaining: 845ms\n",
            "936:\tlearn: 0.0209136\ttotal: 12.4s\tremaining: 832ms\n",
            "937:\tlearn: 0.0208843\ttotal: 12.4s\tremaining: 819ms\n",
            "938:\tlearn: 0.0208537\ttotal: 12.4s\tremaining: 806ms\n",
            "939:\tlearn: 0.0208228\ttotal: 12.4s\tremaining: 794ms\n",
            "940:\tlearn: 0.0207906\ttotal: 12.5s\tremaining: 781ms\n",
            "941:\tlearn: 0.0207501\ttotal: 12.5s\tremaining: 769ms\n",
            "942:\tlearn: 0.0206981\ttotal: 12.5s\tremaining: 756ms\n",
            "943:\tlearn: 0.0206658\ttotal: 12.5s\tremaining: 743ms\n",
            "944:\tlearn: 0.0206244\ttotal: 12.6s\tremaining: 731ms\n",
            "945:\tlearn: 0.0205762\ttotal: 12.6s\tremaining: 718ms\n",
            "946:\tlearn: 0.0205332\ttotal: 12.6s\tremaining: 705ms\n",
            "947:\tlearn: 0.0204906\ttotal: 12.6s\tremaining: 692ms\n",
            "948:\tlearn: 0.0204486\ttotal: 12.6s\tremaining: 679ms\n",
            "949:\tlearn: 0.0204313\ttotal: 12.7s\tremaining: 666ms\n",
            "950:\tlearn: 0.0203964\ttotal: 12.7s\tremaining: 654ms\n",
            "951:\tlearn: 0.0203528\ttotal: 12.7s\tremaining: 640ms\n",
            "952:\tlearn: 0.0202942\ttotal: 12.7s\tremaining: 627ms\n",
            "953:\tlearn: 0.0202539\ttotal: 12.7s\tremaining: 614ms\n",
            "954:\tlearn: 0.0202324\ttotal: 12.8s\tremaining: 602ms\n",
            "955:\tlearn: 0.0201981\ttotal: 12.8s\tremaining: 588ms\n",
            "956:\tlearn: 0.0201662\ttotal: 12.8s\tremaining: 575ms\n",
            "957:\tlearn: 0.0201307\ttotal: 12.8s\tremaining: 561ms\n",
            "958:\tlearn: 0.0201066\ttotal: 12.8s\tremaining: 548ms\n",
            "959:\tlearn: 0.0200702\ttotal: 12.8s\tremaining: 534ms\n",
            "960:\tlearn: 0.0200452\ttotal: 12.8s\tremaining: 521ms\n",
            "961:\tlearn: 0.0200140\ttotal: 12.8s\tremaining: 507ms\n",
            "962:\tlearn: 0.0199852\ttotal: 12.9s\tremaining: 494ms\n",
            "963:\tlearn: 0.0199585\ttotal: 12.9s\tremaining: 481ms\n",
            "964:\tlearn: 0.0199096\ttotal: 12.9s\tremaining: 467ms\n",
            "965:\tlearn: 0.0198927\ttotal: 12.9s\tremaining: 454ms\n",
            "966:\tlearn: 0.0198659\ttotal: 12.9s\tremaining: 440ms\n",
            "967:\tlearn: 0.0198340\ttotal: 12.9s\tremaining: 427ms\n",
            "968:\tlearn: 0.0197985\ttotal: 12.9s\tremaining: 413ms\n",
            "969:\tlearn: 0.0197702\ttotal: 12.9s\tremaining: 400ms\n",
            "970:\tlearn: 0.0197405\ttotal: 12.9s\tremaining: 387ms\n",
            "971:\tlearn: 0.0197288\ttotal: 13s\tremaining: 373ms\n",
            "972:\tlearn: 0.0197028\ttotal: 13s\tremaining: 360ms\n",
            "973:\tlearn: 0.0196687\ttotal: 13s\tremaining: 346ms\n",
            "974:\tlearn: 0.0196153\ttotal: 13s\tremaining: 333ms\n",
            "975:\tlearn: 0.0195826\ttotal: 13s\tremaining: 320ms\n",
            "976:\tlearn: 0.0195529\ttotal: 13s\tremaining: 306ms\n",
            "977:\tlearn: 0.0195169\ttotal: 13s\tremaining: 293ms\n",
            "978:\tlearn: 0.0194789\ttotal: 13s\tremaining: 280ms\n",
            "979:\tlearn: 0.0194696\ttotal: 13s\tremaining: 266ms\n",
            "980:\tlearn: 0.0194309\ttotal: 13.1s\tremaining: 253ms\n",
            "981:\tlearn: 0.0193961\ttotal: 13.1s\tremaining: 239ms\n",
            "982:\tlearn: 0.0193687\ttotal: 13.1s\tremaining: 226ms\n",
            "983:\tlearn: 0.0193509\ttotal: 13.1s\tremaining: 213ms\n",
            "984:\tlearn: 0.0193143\ttotal: 13.1s\tremaining: 199ms\n",
            "985:\tlearn: 0.0192671\ttotal: 13.1s\tremaining: 186ms\n",
            "986:\tlearn: 0.0192349\ttotal: 13.1s\tremaining: 173ms\n",
            "987:\tlearn: 0.0191929\ttotal: 13.1s\tremaining: 159ms\n",
            "988:\tlearn: 0.0191602\ttotal: 13.1s\tremaining: 146ms\n",
            "989:\tlearn: 0.0191263\ttotal: 13.1s\tremaining: 133ms\n",
            "990:\tlearn: 0.0190789\ttotal: 13.2s\tremaining: 120ms\n",
            "991:\tlearn: 0.0190350\ttotal: 13.2s\tremaining: 106ms\n",
            "992:\tlearn: 0.0189987\ttotal: 13.2s\tremaining: 92.9ms\n",
            "993:\tlearn: 0.0189606\ttotal: 13.2s\tremaining: 79.7ms\n",
            "994:\tlearn: 0.0189414\ttotal: 13.2s\tremaining: 66.4ms\n",
            "995:\tlearn: 0.0189009\ttotal: 13.2s\tremaining: 53.1ms\n",
            "996:\tlearn: 0.0188786\ttotal: 13.2s\tremaining: 39.8ms\n",
            "997:\tlearn: 0.0188326\ttotal: 13.2s\tremaining: 26.5ms\n",
            "998:\tlearn: 0.0188071\ttotal: 13.2s\tremaining: 13.3ms\n",
            "999:\tlearn: 0.0187926\ttotal: 13.3s\tremaining: 0us\n",
            "Learning rate set to 0.007856\n",
            "0:\tlearn: 0.6815107\ttotal: 14.5ms\tremaining: 14.5s\n",
            "1:\tlearn: 0.6699731\ttotal: 25ms\tremaining: 12.5s\n",
            "2:\tlearn: 0.6593301\ttotal: 35.4ms\tremaining: 11.8s\n",
            "3:\tlearn: 0.6487465\ttotal: 45.9ms\tremaining: 11.4s\n",
            "4:\tlearn: 0.6383615\ttotal: 56.3ms\tremaining: 11.2s\n",
            "5:\tlearn: 0.6283803\ttotal: 68.2ms\tremaining: 11.3s\n",
            "6:\tlearn: 0.6182513\ttotal: 80.7ms\tremaining: 11.4s\n",
            "7:\tlearn: 0.6080814\ttotal: 91ms\tremaining: 11.3s\n",
            "8:\tlearn: 0.5991310\ttotal: 106ms\tremaining: 11.7s\n",
            "9:\tlearn: 0.5897144\ttotal: 121ms\tremaining: 12s\n",
            "10:\tlearn: 0.5813662\ttotal: 132ms\tremaining: 11.9s\n",
            "11:\tlearn: 0.5724016\ttotal: 142ms\tremaining: 11.7s\n",
            "12:\tlearn: 0.5635033\ttotal: 152ms\tremaining: 11.6s\n",
            "13:\tlearn: 0.5546926\ttotal: 163ms\tremaining: 11.4s\n",
            "14:\tlearn: 0.5453880\ttotal: 174ms\tremaining: 11.5s\n",
            "15:\tlearn: 0.5366729\ttotal: 185ms\tremaining: 11.4s\n",
            "16:\tlearn: 0.5278793\ttotal: 195ms\tremaining: 11.3s\n",
            "17:\tlearn: 0.5197390\ttotal: 205ms\tremaining: 11.2s\n",
            "18:\tlearn: 0.5122183\ttotal: 216ms\tremaining: 11.1s\n",
            "19:\tlearn: 0.5042893\ttotal: 226ms\tremaining: 11.1s\n",
            "20:\tlearn: 0.4972293\ttotal: 236ms\tremaining: 11s\n",
            "21:\tlearn: 0.4895225\ttotal: 258ms\tremaining: 11.5s\n",
            "22:\tlearn: 0.4831542\ttotal: 279ms\tremaining: 11.8s\n",
            "23:\tlearn: 0.4756441\ttotal: 288ms\tremaining: 11.7s\n",
            "24:\tlearn: 0.4693473\ttotal: 299ms\tremaining: 11.6s\n",
            "25:\tlearn: 0.4626268\ttotal: 309ms\tremaining: 11.6s\n",
            "26:\tlearn: 0.4565793\ttotal: 319ms\tremaining: 11.5s\n",
            "27:\tlearn: 0.4497653\ttotal: 329ms\tremaining: 11.4s\n",
            "28:\tlearn: 0.4434151\ttotal: 340ms\tremaining: 11.4s\n",
            "29:\tlearn: 0.4371298\ttotal: 350ms\tremaining: 11.3s\n",
            "30:\tlearn: 0.4318086\ttotal: 360ms\tremaining: 11.3s\n",
            "31:\tlearn: 0.4256442\ttotal: 370ms\tremaining: 11.2s\n",
            "32:\tlearn: 0.4197978\ttotal: 380ms\tremaining: 11.1s\n",
            "33:\tlearn: 0.4143822\ttotal: 392ms\tremaining: 11.1s\n",
            "34:\tlearn: 0.4086038\ttotal: 405ms\tremaining: 11.2s\n",
            "35:\tlearn: 0.4029996\ttotal: 415ms\tremaining: 11.1s\n",
            "36:\tlearn: 0.3974727\ttotal: 425ms\tremaining: 11.1s\n",
            "37:\tlearn: 0.3930441\ttotal: 436ms\tremaining: 11s\n",
            "38:\tlearn: 0.3869839\ttotal: 446ms\tremaining: 11s\n",
            "39:\tlearn: 0.3820313\ttotal: 457ms\tremaining: 11s\n",
            "40:\tlearn: 0.3776310\ttotal: 467ms\tremaining: 10.9s\n",
            "41:\tlearn: 0.3721504\ttotal: 480ms\tremaining: 11s\n",
            "42:\tlearn: 0.3669163\ttotal: 495ms\tremaining: 11s\n",
            "43:\tlearn: 0.3620827\ttotal: 506ms\tremaining: 11s\n",
            "44:\tlearn: 0.3579147\ttotal: 516ms\tremaining: 10.9s\n",
            "45:\tlearn: 0.3530069\ttotal: 526ms\tremaining: 10.9s\n",
            "46:\tlearn: 0.3494583\ttotal: 536ms\tremaining: 10.9s\n",
            "47:\tlearn: 0.3450209\ttotal: 546ms\tremaining: 10.8s\n",
            "48:\tlearn: 0.3402397\ttotal: 557ms\tremaining: 10.8s\n",
            "49:\tlearn: 0.3367993\ttotal: 570ms\tremaining: 10.8s\n",
            "50:\tlearn: 0.3321202\ttotal: 592ms\tremaining: 11s\n",
            "51:\tlearn: 0.3277416\ttotal: 603ms\tremaining: 11s\n",
            "52:\tlearn: 0.3236066\ttotal: 614ms\tremaining: 11s\n",
            "53:\tlearn: 0.3193541\ttotal: 624ms\tremaining: 10.9s\n",
            "54:\tlearn: 0.3153174\ttotal: 634ms\tremaining: 10.9s\n",
            "55:\tlearn: 0.3109880\ttotal: 644ms\tremaining: 10.9s\n",
            "56:\tlearn: 0.3068056\ttotal: 654ms\tremaining: 10.8s\n",
            "57:\tlearn: 0.3034908\ttotal: 664ms\tremaining: 10.8s\n",
            "58:\tlearn: 0.2997949\ttotal: 675ms\tremaining: 10.8s\n",
            "59:\tlearn: 0.2958680\ttotal: 690ms\tremaining: 10.8s\n",
            "60:\tlearn: 0.2925285\ttotal: 700ms\tremaining: 10.8s\n",
            "61:\tlearn: 0.2894652\ttotal: 710ms\tremaining: 10.7s\n",
            "62:\tlearn: 0.2859092\ttotal: 720ms\tremaining: 10.7s\n",
            "63:\tlearn: 0.2824903\ttotal: 730ms\tremaining: 10.7s\n",
            "64:\tlearn: 0.2793285\ttotal: 741ms\tremaining: 10.7s\n",
            "65:\tlearn: 0.2757739\ttotal: 751ms\tremaining: 10.6s\n",
            "66:\tlearn: 0.2729372\ttotal: 762ms\tremaining: 10.6s\n",
            "67:\tlearn: 0.2693929\ttotal: 772ms\tremaining: 10.6s\n",
            "68:\tlearn: 0.2662608\ttotal: 783ms\tremaining: 10.6s\n",
            "69:\tlearn: 0.2630428\ttotal: 793ms\tremaining: 10.5s\n",
            "70:\tlearn: 0.2601417\ttotal: 805ms\tremaining: 10.5s\n",
            "71:\tlearn: 0.2570815\ttotal: 815ms\tremaining: 10.5s\n",
            "72:\tlearn: 0.2540455\ttotal: 826ms\tremaining: 10.5s\n",
            "73:\tlearn: 0.2514577\ttotal: 836ms\tremaining: 10.5s\n",
            "74:\tlearn: 0.2485895\ttotal: 846ms\tremaining: 10.4s\n",
            "75:\tlearn: 0.2463373\ttotal: 857ms\tremaining: 10.4s\n",
            "76:\tlearn: 0.2439089\ttotal: 867ms\tremaining: 10.4s\n",
            "77:\tlearn: 0.2414218\ttotal: 877ms\tremaining: 10.4s\n",
            "78:\tlearn: 0.2388070\ttotal: 887ms\tremaining: 10.3s\n",
            "79:\tlearn: 0.2364000\ttotal: 904ms\tremaining: 10.4s\n",
            "80:\tlearn: 0.2339191\ttotal: 915ms\tremaining: 10.4s\n",
            "81:\tlearn: 0.2313820\ttotal: 925ms\tremaining: 10.4s\n",
            "82:\tlearn: 0.2288266\ttotal: 935ms\tremaining: 10.3s\n",
            "83:\tlearn: 0.2262408\ttotal: 946ms\tremaining: 10.3s\n",
            "84:\tlearn: 0.2240409\ttotal: 956ms\tremaining: 10.3s\n",
            "85:\tlearn: 0.2220197\ttotal: 966ms\tremaining: 10.3s\n",
            "86:\tlearn: 0.2195550\ttotal: 976ms\tremaining: 10.2s\n",
            "87:\tlearn: 0.2175698\ttotal: 986ms\tremaining: 10.2s\n",
            "88:\tlearn: 0.2153701\ttotal: 996ms\tremaining: 10.2s\n",
            "89:\tlearn: 0.2131761\ttotal: 1.01s\tremaining: 10.2s\n",
            "90:\tlearn: 0.2112317\ttotal: 1.02s\tremaining: 10.1s\n",
            "91:\tlearn: 0.2091546\ttotal: 1.02s\tremaining: 10.1s\n",
            "92:\tlearn: 0.2071472\ttotal: 1.04s\tremaining: 10.1s\n",
            "93:\tlearn: 0.2056214\ttotal: 1.05s\tremaining: 10.1s\n",
            "94:\tlearn: 0.2043815\ttotal: 1.06s\tremaining: 10.1s\n",
            "95:\tlearn: 0.2024892\ttotal: 1.07s\tremaining: 10.1s\n",
            "96:\tlearn: 0.2006362\ttotal: 1.08s\tremaining: 10.1s\n",
            "97:\tlearn: 0.1986527\ttotal: 1.1s\tremaining: 10.1s\n",
            "98:\tlearn: 0.1965793\ttotal: 1.11s\tremaining: 10.1s\n",
            "99:\tlearn: 0.1951004\ttotal: 1.12s\tremaining: 10.1s\n",
            "100:\tlearn: 0.1931545\ttotal: 1.13s\tremaining: 10.1s\n",
            "101:\tlearn: 0.1913459\ttotal: 1.15s\tremaining: 10.1s\n",
            "102:\tlearn: 0.1893606\ttotal: 1.16s\tremaining: 10.1s\n",
            "103:\tlearn: 0.1876124\ttotal: 1.17s\tremaining: 10.1s\n",
            "104:\tlearn: 0.1861279\ttotal: 1.18s\tremaining: 10.1s\n",
            "105:\tlearn: 0.1844784\ttotal: 1.19s\tremaining: 10.1s\n",
            "106:\tlearn: 0.1829034\ttotal: 1.2s\tremaining: 10s\n",
            "107:\tlearn: 0.1816174\ttotal: 1.21s\tremaining: 10s\n",
            "108:\tlearn: 0.1799382\ttotal: 1.22s\tremaining: 9.99s\n",
            "109:\tlearn: 0.1782524\ttotal: 1.23s\tremaining: 9.97s\n",
            "110:\tlearn: 0.1768373\ttotal: 1.25s\tremaining: 10s\n",
            "111:\tlearn: 0.1752715\ttotal: 1.27s\tremaining: 10.1s\n",
            "112:\tlearn: 0.1738840\ttotal: 1.28s\tremaining: 10s\n",
            "113:\tlearn: 0.1725966\ttotal: 1.29s\tremaining: 10s\n",
            "114:\tlearn: 0.1712904\ttotal: 1.3s\tremaining: 10s\n",
            "115:\tlearn: 0.1698865\ttotal: 1.31s\tremaining: 9.98s\n",
            "116:\tlearn: 0.1686685\ttotal: 1.32s\tremaining: 9.99s\n",
            "117:\tlearn: 0.1675313\ttotal: 1.33s\tremaining: 9.97s\n",
            "118:\tlearn: 0.1664173\ttotal: 1.34s\tremaining: 9.95s\n",
            "119:\tlearn: 0.1650526\ttotal: 1.35s\tremaining: 9.93s\n",
            "120:\tlearn: 0.1639931\ttotal: 1.36s\tremaining: 9.91s\n",
            "121:\tlearn: 0.1627055\ttotal: 1.38s\tremaining: 9.9s\n",
            "122:\tlearn: 0.1615778\ttotal: 1.39s\tremaining: 9.88s\n",
            "123:\tlearn: 0.1603314\ttotal: 1.4s\tremaining: 9.86s\n",
            "124:\tlearn: 0.1589498\ttotal: 1.41s\tremaining: 9.84s\n",
            "125:\tlearn: 0.1577692\ttotal: 1.42s\tremaining: 9.82s\n",
            "126:\tlearn: 0.1564950\ttotal: 1.43s\tremaining: 9.81s\n",
            "127:\tlearn: 0.1553683\ttotal: 1.44s\tremaining: 9.79s\n",
            "128:\tlearn: 0.1543111\ttotal: 1.45s\tremaining: 9.77s\n",
            "129:\tlearn: 0.1530591\ttotal: 1.46s\tremaining: 9.76s\n",
            "130:\tlearn: 0.1519204\ttotal: 1.47s\tremaining: 9.75s\n",
            "131:\tlearn: 0.1508408\ttotal: 1.48s\tremaining: 9.73s\n",
            "132:\tlearn: 0.1496014\ttotal: 1.49s\tremaining: 9.72s\n",
            "133:\tlearn: 0.1486613\ttotal: 1.5s\tremaining: 9.7s\n",
            "134:\tlearn: 0.1475685\ttotal: 1.51s\tremaining: 9.68s\n",
            "135:\tlearn: 0.1464041\ttotal: 1.52s\tremaining: 9.67s\n",
            "136:\tlearn: 0.1454462\ttotal: 1.54s\tremaining: 9.71s\n",
            "137:\tlearn: 0.1443781\ttotal: 1.55s\tremaining: 9.7s\n",
            "138:\tlearn: 0.1434450\ttotal: 1.56s\tremaining: 9.69s\n",
            "139:\tlearn: 0.1425423\ttotal: 1.57s\tremaining: 9.67s\n",
            "140:\tlearn: 0.1413581\ttotal: 1.58s\tremaining: 9.65s\n",
            "141:\tlearn: 0.1404242\ttotal: 1.59s\tremaining: 9.63s\n",
            "142:\tlearn: 0.1393732\ttotal: 1.6s\tremaining: 9.61s\n",
            "143:\tlearn: 0.1383161\ttotal: 1.61s\tremaining: 9.59s\n",
            "144:\tlearn: 0.1372503\ttotal: 1.62s\tremaining: 9.57s\n",
            "145:\tlearn: 0.1364417\ttotal: 1.63s\tremaining: 9.56s\n",
            "146:\tlearn: 0.1356243\ttotal: 1.65s\tremaining: 9.55s\n",
            "147:\tlearn: 0.1348019\ttotal: 1.66s\tremaining: 9.53s\n",
            "148:\tlearn: 0.1338530\ttotal: 1.67s\tremaining: 9.51s\n",
            "149:\tlearn: 0.1330499\ttotal: 1.68s\tremaining: 9.49s\n",
            "150:\tlearn: 0.1320154\ttotal: 1.69s\tremaining: 9.48s\n",
            "151:\tlearn: 0.1313735\ttotal: 1.7s\tremaining: 9.46s\n",
            "152:\tlearn: 0.1304396\ttotal: 1.71s\tremaining: 9.45s\n",
            "153:\tlearn: 0.1294200\ttotal: 1.72s\tremaining: 9.43s\n",
            "154:\tlearn: 0.1287768\ttotal: 1.73s\tremaining: 9.41s\n",
            "155:\tlearn: 0.1279289\ttotal: 1.74s\tremaining: 9.39s\n",
            "156:\tlearn: 0.1271874\ttotal: 1.75s\tremaining: 9.41s\n",
            "157:\tlearn: 0.1265840\ttotal: 1.76s\tremaining: 9.39s\n",
            "158:\tlearn: 0.1260048\ttotal: 1.77s\tremaining: 9.37s\n",
            "159:\tlearn: 0.1253225\ttotal: 1.78s\tremaining: 9.36s\n",
            "160:\tlearn: 0.1243919\ttotal: 1.79s\tremaining: 9.34s\n",
            "161:\tlearn: 0.1236157\ttotal: 1.8s\tremaining: 9.32s\n",
            "162:\tlearn: 0.1229973\ttotal: 1.81s\tremaining: 9.31s\n",
            "163:\tlearn: 0.1220936\ttotal: 1.82s\tremaining: 9.29s\n",
            "164:\tlearn: 0.1212371\ttotal: 1.83s\tremaining: 9.27s\n",
            "165:\tlearn: 0.1206029\ttotal: 1.84s\tremaining: 9.26s\n",
            "166:\tlearn: 0.1198483\ttotal: 1.85s\tremaining: 9.24s\n",
            "167:\tlearn: 0.1191895\ttotal: 1.86s\tremaining: 9.22s\n",
            "168:\tlearn: 0.1185213\ttotal: 1.87s\tremaining: 9.21s\n",
            "169:\tlearn: 0.1177616\ttotal: 1.88s\tremaining: 9.19s\n",
            "170:\tlearn: 0.1169791\ttotal: 1.89s\tremaining: 9.18s\n",
            "171:\tlearn: 0.1162590\ttotal: 1.9s\tremaining: 9.16s\n",
            "172:\tlearn: 0.1156370\ttotal: 1.91s\tremaining: 9.14s\n",
            "173:\tlearn: 0.1149962\ttotal: 1.92s\tremaining: 9.13s\n",
            "174:\tlearn: 0.1143125\ttotal: 1.93s\tremaining: 9.11s\n",
            "175:\tlearn: 0.1134770\ttotal: 1.94s\tremaining: 9.1s\n",
            "176:\tlearn: 0.1129549\ttotal: 1.96s\tremaining: 9.11s\n",
            "177:\tlearn: 0.1121839\ttotal: 1.97s\tremaining: 9.09s\n",
            "178:\tlearn: 0.1116320\ttotal: 1.98s\tremaining: 9.08s\n",
            "179:\tlearn: 0.1111893\ttotal: 1.99s\tremaining: 9.06s\n",
            "180:\tlearn: 0.1106333\ttotal: 2s\tremaining: 9.04s\n",
            "181:\tlearn: 0.1100292\ttotal: 2.01s\tremaining: 9.03s\n",
            "182:\tlearn: 0.1093392\ttotal: 2.02s\tremaining: 9.01s\n",
            "183:\tlearn: 0.1087115\ttotal: 2.03s\tremaining: 9s\n",
            "184:\tlearn: 0.1081308\ttotal: 2.04s\tremaining: 8.98s\n",
            "185:\tlearn: 0.1076298\ttotal: 2.05s\tremaining: 8.98s\n",
            "186:\tlearn: 0.1069164\ttotal: 2.07s\tremaining: 8.99s\n",
            "187:\tlearn: 0.1063029\ttotal: 2.08s\tremaining: 8.98s\n",
            "188:\tlearn: 0.1057319\ttotal: 2.09s\tremaining: 8.96s\n",
            "189:\tlearn: 0.1052333\ttotal: 2.1s\tremaining: 8.95s\n",
            "190:\tlearn: 0.1046160\ttotal: 2.11s\tremaining: 8.93s\n",
            "191:\tlearn: 0.1039178\ttotal: 2.12s\tremaining: 8.92s\n",
            "192:\tlearn: 0.1034166\ttotal: 2.13s\tremaining: 8.9s\n",
            "193:\tlearn: 0.1029291\ttotal: 2.14s\tremaining: 8.89s\n",
            "194:\tlearn: 0.1023844\ttotal: 2.15s\tremaining: 8.87s\n",
            "195:\tlearn: 0.1018651\ttotal: 2.16s\tremaining: 8.87s\n",
            "196:\tlearn: 0.1012898\ttotal: 2.17s\tremaining: 8.86s\n",
            "197:\tlearn: 0.1008344\ttotal: 2.18s\tremaining: 8.84s\n",
            "198:\tlearn: 0.1002492\ttotal: 2.19s\tremaining: 8.83s\n",
            "199:\tlearn: 0.0996792\ttotal: 2.2s\tremaining: 8.81s\n",
            "200:\tlearn: 0.0990561\ttotal: 2.21s\tremaining: 8.8s\n",
            "201:\tlearn: 0.0984472\ttotal: 2.22s\tremaining: 8.78s\n",
            "202:\tlearn: 0.0979316\ttotal: 2.23s\tremaining: 8.77s\n",
            "203:\tlearn: 0.0974422\ttotal: 2.25s\tremaining: 8.77s\n",
            "204:\tlearn: 0.0970075\ttotal: 2.27s\tremaining: 8.8s\n",
            "205:\tlearn: 0.0965781\ttotal: 2.28s\tremaining: 8.79s\n",
            "206:\tlearn: 0.0960991\ttotal: 2.29s\tremaining: 8.78s\n",
            "207:\tlearn: 0.0957009\ttotal: 2.3s\tremaining: 8.76s\n",
            "208:\tlearn: 0.0951712\ttotal: 2.31s\tremaining: 8.74s\n",
            "209:\tlearn: 0.0946524\ttotal: 2.32s\tremaining: 8.73s\n",
            "210:\tlearn: 0.0941927\ttotal: 2.33s\tremaining: 8.71s\n",
            "211:\tlearn: 0.0937270\ttotal: 2.34s\tremaining: 8.7s\n",
            "212:\tlearn: 0.0932653\ttotal: 2.35s\tremaining: 8.69s\n",
            "213:\tlearn: 0.0929143\ttotal: 2.37s\tremaining: 8.69s\n",
            "214:\tlearn: 0.0924851\ttotal: 2.38s\tremaining: 8.68s\n",
            "215:\tlearn: 0.0920551\ttotal: 2.39s\tremaining: 8.66s\n",
            "216:\tlearn: 0.0915726\ttotal: 2.4s\tremaining: 8.65s\n",
            "217:\tlearn: 0.0910657\ttotal: 2.41s\tremaining: 8.64s\n",
            "218:\tlearn: 0.0905855\ttotal: 2.42s\tremaining: 8.63s\n",
            "219:\tlearn: 0.0902174\ttotal: 2.43s\tremaining: 8.61s\n",
            "220:\tlearn: 0.0897594\ttotal: 2.44s\tremaining: 8.6s\n",
            "221:\tlearn: 0.0893750\ttotal: 2.45s\tremaining: 8.6s\n",
            "222:\tlearn: 0.0891194\ttotal: 2.46s\tremaining: 8.58s\n",
            "223:\tlearn: 0.0887359\ttotal: 2.47s\tremaining: 8.57s\n",
            "224:\tlearn: 0.0884049\ttotal: 2.48s\tremaining: 8.55s\n",
            "225:\tlearn: 0.0880017\ttotal: 2.49s\tremaining: 8.54s\n",
            "226:\tlearn: 0.0876427\ttotal: 2.5s\tremaining: 8.53s\n",
            "227:\tlearn: 0.0873607\ttotal: 2.51s\tremaining: 8.51s\n",
            "228:\tlearn: 0.0870002\ttotal: 2.52s\tremaining: 8.5s\n",
            "229:\tlearn: 0.0865850\ttotal: 2.54s\tremaining: 8.49s\n",
            "230:\tlearn: 0.0861683\ttotal: 2.55s\tremaining: 8.48s\n",
            "231:\tlearn: 0.0857993\ttotal: 2.56s\tremaining: 8.46s\n",
            "232:\tlearn: 0.0853432\ttotal: 2.57s\tremaining: 8.48s\n",
            "233:\tlearn: 0.0849789\ttotal: 2.58s\tremaining: 8.46s\n",
            "234:\tlearn: 0.0845662\ttotal: 2.6s\tremaining: 8.45s\n",
            "235:\tlearn: 0.0841279\ttotal: 2.6s\tremaining: 8.44s\n",
            "236:\tlearn: 0.0837227\ttotal: 2.62s\tremaining: 8.42s\n",
            "237:\tlearn: 0.0833718\ttotal: 2.63s\tremaining: 8.41s\n",
            "238:\tlearn: 0.0830651\ttotal: 2.64s\tremaining: 8.39s\n",
            "239:\tlearn: 0.0827115\ttotal: 2.65s\tremaining: 8.38s\n",
            "240:\tlearn: 0.0823359\ttotal: 2.66s\tremaining: 8.36s\n",
            "241:\tlearn: 0.0820281\ttotal: 2.67s\tremaining: 8.35s\n",
            "242:\tlearn: 0.0816372\ttotal: 2.68s\tremaining: 8.34s\n",
            "243:\tlearn: 0.0812589\ttotal: 2.69s\tremaining: 8.35s\n",
            "244:\tlearn: 0.0809943\ttotal: 2.71s\tremaining: 8.36s\n",
            "245:\tlearn: 0.0806879\ttotal: 2.72s\tremaining: 8.35s\n",
            "246:\tlearn: 0.0804249\ttotal: 2.73s\tremaining: 8.34s\n",
            "247:\tlearn: 0.0801409\ttotal: 2.74s\tremaining: 8.32s\n",
            "248:\tlearn: 0.0798888\ttotal: 2.75s\tremaining: 8.31s\n",
            "249:\tlearn: 0.0795534\ttotal: 2.76s\tremaining: 8.29s\n",
            "250:\tlearn: 0.0792687\ttotal: 2.78s\tremaining: 8.3s\n",
            "251:\tlearn: 0.0789295\ttotal: 2.79s\tremaining: 8.29s\n",
            "252:\tlearn: 0.0785912\ttotal: 2.8s\tremaining: 8.27s\n",
            "253:\tlearn: 0.0782910\ttotal: 2.81s\tremaining: 8.26s\n",
            "254:\tlearn: 0.0779442\ttotal: 2.82s\tremaining: 8.25s\n",
            "255:\tlearn: 0.0776673\ttotal: 2.83s\tremaining: 8.24s\n",
            "256:\tlearn: 0.0774117\ttotal: 2.84s\tremaining: 8.22s\n",
            "257:\tlearn: 0.0771720\ttotal: 2.85s\tremaining: 8.21s\n",
            "258:\tlearn: 0.0768024\ttotal: 2.87s\tremaining: 8.2s\n",
            "259:\tlearn: 0.0765100\ttotal: 2.88s\tremaining: 8.19s\n",
            "260:\tlearn: 0.0761920\ttotal: 2.89s\tremaining: 8.17s\n",
            "261:\tlearn: 0.0758904\ttotal: 2.9s\tremaining: 8.16s\n",
            "262:\tlearn: 0.0755490\ttotal: 2.91s\tremaining: 8.15s\n",
            "263:\tlearn: 0.0752425\ttotal: 2.92s\tremaining: 8.13s\n",
            "264:\tlearn: 0.0749339\ttotal: 2.93s\tremaining: 8.12s\n",
            "265:\tlearn: 0.0745411\ttotal: 2.94s\tremaining: 8.11s\n",
            "266:\tlearn: 0.0742187\ttotal: 2.95s\tremaining: 8.09s\n",
            "267:\tlearn: 0.0738799\ttotal: 2.96s\tremaining: 8.08s\n",
            "268:\tlearn: 0.0735699\ttotal: 2.97s\tremaining: 8.06s\n",
            "269:\tlearn: 0.0733241\ttotal: 2.98s\tremaining: 8.05s\n",
            "270:\tlearn: 0.0731041\ttotal: 2.99s\tremaining: 8.05s\n",
            "271:\tlearn: 0.0728568\ttotal: 3s\tremaining: 8.04s\n",
            "272:\tlearn: 0.0725392\ttotal: 3.01s\tremaining: 8.03s\n",
            "273:\tlearn: 0.0722313\ttotal: 3.03s\tremaining: 8.03s\n",
            "274:\tlearn: 0.0720048\ttotal: 3.04s\tremaining: 8.03s\n",
            "275:\tlearn: 0.0717542\ttotal: 3.05s\tremaining: 8.01s\n",
            "276:\tlearn: 0.0715150\ttotal: 3.06s\tremaining: 8s\n",
            "277:\tlearn: 0.0711576\ttotal: 3.07s\tremaining: 7.98s\n",
            "278:\tlearn: 0.0708085\ttotal: 3.08s\tremaining: 7.97s\n",
            "279:\tlearn: 0.0706092\ttotal: 3.09s\tremaining: 7.96s\n",
            "280:\tlearn: 0.0702823\ttotal: 3.11s\tremaining: 7.97s\n",
            "281:\tlearn: 0.0700375\ttotal: 3.13s\tremaining: 7.96s\n",
            "282:\tlearn: 0.0697419\ttotal: 3.13s\tremaining: 7.94s\n",
            "283:\tlearn: 0.0695853\ttotal: 3.15s\tremaining: 7.93s\n",
            "284:\tlearn: 0.0693936\ttotal: 3.15s\tremaining: 7.92s\n",
            "285:\tlearn: 0.0691048\ttotal: 3.17s\tremaining: 7.9s\n",
            "286:\tlearn: 0.0687955\ttotal: 3.18s\tremaining: 7.89s\n",
            "287:\tlearn: 0.0685405\ttotal: 3.19s\tremaining: 7.88s\n",
            "288:\tlearn: 0.0683280\ttotal: 3.2s\tremaining: 7.88s\n",
            "289:\tlearn: 0.0680904\ttotal: 3.21s\tremaining: 7.87s\n",
            "290:\tlearn: 0.0678140\ttotal: 3.22s\tremaining: 7.85s\n",
            "291:\tlearn: 0.0675327\ttotal: 3.23s\tremaining: 7.84s\n",
            "292:\tlearn: 0.0673568\ttotal: 3.24s\tremaining: 7.83s\n",
            "293:\tlearn: 0.0671312\ttotal: 3.26s\tremaining: 7.83s\n",
            "294:\tlearn: 0.0669435\ttotal: 3.28s\tremaining: 7.84s\n",
            "295:\tlearn: 0.0667251\ttotal: 3.29s\tremaining: 7.82s\n",
            "296:\tlearn: 0.0665068\ttotal: 3.3s\tremaining: 7.81s\n",
            "297:\tlearn: 0.0663430\ttotal: 3.31s\tremaining: 7.8s\n",
            "298:\tlearn: 0.0661167\ttotal: 3.32s\tremaining: 7.78s\n",
            "299:\tlearn: 0.0659752\ttotal: 3.33s\tremaining: 7.77s\n",
            "300:\tlearn: 0.0656654\ttotal: 3.34s\tremaining: 7.76s\n",
            "301:\tlearn: 0.0654051\ttotal: 3.35s\tremaining: 7.75s\n",
            "302:\tlearn: 0.0651892\ttotal: 3.36s\tremaining: 7.73s\n",
            "303:\tlearn: 0.0650124\ttotal: 3.37s\tremaining: 7.72s\n",
            "304:\tlearn: 0.0648549\ttotal: 3.38s\tremaining: 7.71s\n",
            "305:\tlearn: 0.0646477\ttotal: 3.39s\tremaining: 7.69s\n",
            "306:\tlearn: 0.0643715\ttotal: 3.4s\tremaining: 7.69s\n",
            "307:\tlearn: 0.0641917\ttotal: 3.42s\tremaining: 7.68s\n",
            "308:\tlearn: 0.0639568\ttotal: 3.43s\tremaining: 7.67s\n",
            "309:\tlearn: 0.0638445\ttotal: 3.44s\tremaining: 7.65s\n",
            "310:\tlearn: 0.0636797\ttotal: 3.45s\tremaining: 7.64s\n",
            "311:\tlearn: 0.0634892\ttotal: 3.46s\tremaining: 7.63s\n",
            "312:\tlearn: 0.0632397\ttotal: 3.47s\tremaining: 7.62s\n",
            "313:\tlearn: 0.0630749\ttotal: 3.48s\tremaining: 7.6s\n",
            "314:\tlearn: 0.0628301\ttotal: 3.49s\tremaining: 7.59s\n",
            "315:\tlearn: 0.0625410\ttotal: 3.5s\tremaining: 7.58s\n",
            "316:\tlearn: 0.0622894\ttotal: 3.51s\tremaining: 7.57s\n",
            "317:\tlearn: 0.0620544\ttotal: 3.52s\tremaining: 7.56s\n",
            "318:\tlearn: 0.0617750\ttotal: 3.54s\tremaining: 7.55s\n",
            "319:\tlearn: 0.0615913\ttotal: 3.54s\tremaining: 7.53s\n",
            "320:\tlearn: 0.0614035\ttotal: 3.56s\tremaining: 7.52s\n",
            "321:\tlearn: 0.0611694\ttotal: 3.57s\tremaining: 7.51s\n",
            "322:\tlearn: 0.0609210\ttotal: 3.58s\tremaining: 7.5s\n",
            "323:\tlearn: 0.0606900\ttotal: 3.59s\tremaining: 7.49s\n",
            "324:\tlearn: 0.0603991\ttotal: 3.6s\tremaining: 7.47s\n",
            "325:\tlearn: 0.0601737\ttotal: 3.62s\tremaining: 7.48s\n",
            "326:\tlearn: 0.0599220\ttotal: 3.63s\tremaining: 7.47s\n",
            "327:\tlearn: 0.0597324\ttotal: 3.64s\tremaining: 7.45s\n",
            "328:\tlearn: 0.0595441\ttotal: 3.65s\tremaining: 7.44s\n",
            "329:\tlearn: 0.0593695\ttotal: 3.66s\tremaining: 7.43s\n",
            "330:\tlearn: 0.0592156\ttotal: 3.67s\tremaining: 7.42s\n",
            "331:\tlearn: 0.0590253\ttotal: 3.68s\tremaining: 7.4s\n",
            "332:\tlearn: 0.0588384\ttotal: 3.69s\tremaining: 7.39s\n",
            "333:\tlearn: 0.0586596\ttotal: 3.7s\tremaining: 7.38s\n",
            "334:\tlearn: 0.0584504\ttotal: 3.71s\tremaining: 7.37s\n",
            "335:\tlearn: 0.0582219\ttotal: 3.72s\tremaining: 7.36s\n",
            "336:\tlearn: 0.0580224\ttotal: 3.73s\tremaining: 7.34s\n",
            "337:\tlearn: 0.0578547\ttotal: 3.74s\tremaining: 7.33s\n",
            "338:\tlearn: 0.0576928\ttotal: 3.75s\tremaining: 7.32s\n",
            "339:\tlearn: 0.0575484\ttotal: 3.76s\tremaining: 7.31s\n",
            "340:\tlearn: 0.0574087\ttotal: 3.77s\tremaining: 7.29s\n",
            "341:\tlearn: 0.0572085\ttotal: 3.78s\tremaining: 7.28s\n",
            "342:\tlearn: 0.0569886\ttotal: 3.79s\tremaining: 7.27s\n",
            "343:\tlearn: 0.0567758\ttotal: 3.8s\tremaining: 7.25s\n",
            "344:\tlearn: 0.0565961\ttotal: 3.82s\tremaining: 7.25s\n",
            "345:\tlearn: 0.0563738\ttotal: 3.83s\tremaining: 7.24s\n",
            "346:\tlearn: 0.0562102\ttotal: 3.84s\tremaining: 7.23s\n",
            "347:\tlearn: 0.0560537\ttotal: 3.85s\tremaining: 7.21s\n",
            "348:\tlearn: 0.0558838\ttotal: 3.86s\tremaining: 7.2s\n",
            "349:\tlearn: 0.0556938\ttotal: 3.87s\tremaining: 7.19s\n",
            "350:\tlearn: 0.0555767\ttotal: 3.88s\tremaining: 7.17s\n",
            "351:\tlearn: 0.0554344\ttotal: 3.89s\tremaining: 7.16s\n",
            "352:\tlearn: 0.0552160\ttotal: 3.9s\tremaining: 7.15s\n",
            "353:\tlearn: 0.0550579\ttotal: 3.91s\tremaining: 7.14s\n",
            "354:\tlearn: 0.0548497\ttotal: 3.92s\tremaining: 7.12s\n",
            "355:\tlearn: 0.0547147\ttotal: 3.93s\tremaining: 7.11s\n",
            "356:\tlearn: 0.0545725\ttotal: 3.94s\tremaining: 7.1s\n",
            "357:\tlearn: 0.0544261\ttotal: 3.95s\tremaining: 7.08s\n",
            "358:\tlearn: 0.0542747\ttotal: 3.96s\tremaining: 7.07s\n",
            "359:\tlearn: 0.0541678\ttotal: 3.97s\tremaining: 7.06s\n",
            "360:\tlearn: 0.0540327\ttotal: 3.98s\tremaining: 7.05s\n",
            "361:\tlearn: 0.0538578\ttotal: 3.99s\tremaining: 7.04s\n",
            "362:\tlearn: 0.0536948\ttotal: 4.01s\tremaining: 7.03s\n",
            "363:\tlearn: 0.0535227\ttotal: 4.03s\tremaining: 7.04s\n",
            "364:\tlearn: 0.0533673\ttotal: 4.04s\tremaining: 7.03s\n",
            "365:\tlearn: 0.0531238\ttotal: 4.05s\tremaining: 7.02s\n",
            "366:\tlearn: 0.0529326\ttotal: 4.06s\tremaining: 7.01s\n",
            "367:\tlearn: 0.0527543\ttotal: 4.07s\tremaining: 6.99s\n",
            "368:\tlearn: 0.0525602\ttotal: 4.08s\tremaining: 6.98s\n",
            "369:\tlearn: 0.0524024\ttotal: 4.09s\tremaining: 6.97s\n",
            "370:\tlearn: 0.0522910\ttotal: 4.1s\tremaining: 6.95s\n",
            "371:\tlearn: 0.0521262\ttotal: 4.11s\tremaining: 6.94s\n",
            "372:\tlearn: 0.0520160\ttotal: 4.12s\tremaining: 6.93s\n",
            "373:\tlearn: 0.0518307\ttotal: 4.13s\tremaining: 6.92s\n",
            "374:\tlearn: 0.0516564\ttotal: 4.14s\tremaining: 6.9s\n",
            "375:\tlearn: 0.0514443\ttotal: 4.15s\tremaining: 6.89s\n",
            "376:\tlearn: 0.0512972\ttotal: 4.16s\tremaining: 6.88s\n",
            "377:\tlearn: 0.0511261\ttotal: 4.17s\tremaining: 6.87s\n",
            "378:\tlearn: 0.0509357\ttotal: 4.18s\tremaining: 6.85s\n",
            "379:\tlearn: 0.0507436\ttotal: 4.19s\tremaining: 6.84s\n",
            "380:\tlearn: 0.0506081\ttotal: 4.2s\tremaining: 6.83s\n",
            "381:\tlearn: 0.0504519\ttotal: 4.21s\tremaining: 6.81s\n",
            "382:\tlearn: 0.0503373\ttotal: 4.22s\tremaining: 6.8s\n",
            "383:\tlearn: 0.0501913\ttotal: 4.24s\tremaining: 6.8s\n",
            "384:\tlearn: 0.0500221\ttotal: 4.25s\tremaining: 6.79s\n",
            "385:\tlearn: 0.0499336\ttotal: 4.27s\tremaining: 6.79s\n",
            "386:\tlearn: 0.0498061\ttotal: 4.28s\tremaining: 6.78s\n",
            "387:\tlearn: 0.0496452\ttotal: 4.29s\tremaining: 6.77s\n",
            "388:\tlearn: 0.0495110\ttotal: 4.3s\tremaining: 6.76s\n",
            "389:\tlearn: 0.0493316\ttotal: 4.31s\tremaining: 6.75s\n",
            "390:\tlearn: 0.0492366\ttotal: 4.33s\tremaining: 6.74s\n",
            "391:\tlearn: 0.0490846\ttotal: 4.33s\tremaining: 6.72s\n",
            "392:\tlearn: 0.0488973\ttotal: 4.34s\tremaining: 6.71s\n",
            "393:\tlearn: 0.0487624\ttotal: 4.36s\tremaining: 6.7s\n",
            "394:\tlearn: 0.0486513\ttotal: 4.37s\tremaining: 6.69s\n",
            "395:\tlearn: 0.0485241\ttotal: 4.38s\tremaining: 6.67s\n",
            "396:\tlearn: 0.0484199\ttotal: 4.39s\tremaining: 6.66s\n",
            "397:\tlearn: 0.0482552\ttotal: 4.4s\tremaining: 6.65s\n",
            "398:\tlearn: 0.0480882\ttotal: 4.41s\tremaining: 6.64s\n",
            "399:\tlearn: 0.0479577\ttotal: 4.42s\tremaining: 6.63s\n",
            "400:\tlearn: 0.0477804\ttotal: 4.43s\tremaining: 6.62s\n",
            "401:\tlearn: 0.0476334\ttotal: 4.44s\tremaining: 6.61s\n",
            "402:\tlearn: 0.0475386\ttotal: 4.46s\tremaining: 6.6s\n",
            "403:\tlearn: 0.0474197\ttotal: 4.46s\tremaining: 6.59s\n",
            "404:\tlearn: 0.0472743\ttotal: 4.48s\tremaining: 6.58s\n",
            "405:\tlearn: 0.0471401\ttotal: 4.49s\tremaining: 6.56s\n",
            "406:\tlearn: 0.0469894\ttotal: 4.5s\tremaining: 6.55s\n",
            "407:\tlearn: 0.0468225\ttotal: 4.51s\tremaining: 6.54s\n",
            "408:\tlearn: 0.0467243\ttotal: 4.52s\tremaining: 6.54s\n",
            "409:\tlearn: 0.0466192\ttotal: 4.53s\tremaining: 6.52s\n",
            "410:\tlearn: 0.0464502\ttotal: 4.54s\tremaining: 6.51s\n",
            "411:\tlearn: 0.0463266\ttotal: 4.55s\tremaining: 6.5s\n",
            "412:\tlearn: 0.0462034\ttotal: 4.56s\tremaining: 6.49s\n",
            "413:\tlearn: 0.0459767\ttotal: 4.57s\tremaining: 6.47s\n",
            "414:\tlearn: 0.0458573\ttotal: 4.58s\tremaining: 6.46s\n",
            "415:\tlearn: 0.0457663\ttotal: 4.59s\tremaining: 6.45s\n",
            "416:\tlearn: 0.0456332\ttotal: 4.61s\tremaining: 6.44s\n",
            "417:\tlearn: 0.0454511\ttotal: 4.62s\tremaining: 6.43s\n",
            "418:\tlearn: 0.0452860\ttotal: 4.63s\tremaining: 6.42s\n",
            "419:\tlearn: 0.0451483\ttotal: 4.64s\tremaining: 6.4s\n",
            "420:\tlearn: 0.0450328\ttotal: 4.65s\tremaining: 6.4s\n",
            "421:\tlearn: 0.0449001\ttotal: 4.66s\tremaining: 6.38s\n",
            "422:\tlearn: 0.0448131\ttotal: 4.67s\tremaining: 6.37s\n",
            "423:\tlearn: 0.0446693\ttotal: 4.68s\tremaining: 6.36s\n",
            "424:\tlearn: 0.0445038\ttotal: 4.69s\tremaining: 6.35s\n",
            "425:\tlearn: 0.0443349\ttotal: 4.7s\tremaining: 6.34s\n",
            "426:\tlearn: 0.0441458\ttotal: 4.71s\tremaining: 6.32s\n",
            "427:\tlearn: 0.0440511\ttotal: 4.72s\tremaining: 6.31s\n",
            "428:\tlearn: 0.0439737\ttotal: 4.73s\tremaining: 6.3s\n",
            "429:\tlearn: 0.0438679\ttotal: 4.74s\tremaining: 6.29s\n",
            "430:\tlearn: 0.0437715\ttotal: 4.75s\tremaining: 6.28s\n",
            "431:\tlearn: 0.0436591\ttotal: 4.76s\tremaining: 6.26s\n",
            "432:\tlearn: 0.0435813\ttotal: 4.77s\tremaining: 6.25s\n",
            "433:\tlearn: 0.0435024\ttotal: 4.78s\tremaining: 6.24s\n",
            "434:\tlearn: 0.0433976\ttotal: 4.79s\tremaining: 6.23s\n",
            "435:\tlearn: 0.0432792\ttotal: 4.8s\tremaining: 6.22s\n",
            "436:\tlearn: 0.0431145\ttotal: 4.82s\tremaining: 6.2s\n",
            "437:\tlearn: 0.0429942\ttotal: 4.83s\tremaining: 6.19s\n",
            "438:\tlearn: 0.0428855\ttotal: 4.84s\tremaining: 6.18s\n",
            "439:\tlearn: 0.0428079\ttotal: 4.85s\tremaining: 6.17s\n",
            "440:\tlearn: 0.0427124\ttotal: 4.86s\tremaining: 6.16s\n",
            "441:\tlearn: 0.0426287\ttotal: 4.87s\tremaining: 6.15s\n",
            "442:\tlearn: 0.0425104\ttotal: 4.88s\tremaining: 6.14s\n",
            "443:\tlearn: 0.0423427\ttotal: 4.89s\tremaining: 6.13s\n",
            "444:\tlearn: 0.0422317\ttotal: 4.9s\tremaining: 6.12s\n",
            "445:\tlearn: 0.0420388\ttotal: 4.91s\tremaining: 6.1s\n",
            "446:\tlearn: 0.0419445\ttotal: 4.92s\tremaining: 6.09s\n",
            "447:\tlearn: 0.0418283\ttotal: 4.93s\tremaining: 6.08s\n",
            "448:\tlearn: 0.0416875\ttotal: 4.94s\tremaining: 6.07s\n",
            "449:\tlearn: 0.0416157\ttotal: 4.95s\tremaining: 6.05s\n",
            "450:\tlearn: 0.0415223\ttotal: 4.96s\tremaining: 6.04s\n",
            "451:\tlearn: 0.0414186\ttotal: 4.98s\tremaining: 6.03s\n",
            "452:\tlearn: 0.0412830\ttotal: 4.99s\tremaining: 6.03s\n",
            "453:\tlearn: 0.0411957\ttotal: 5s\tremaining: 6.02s\n",
            "454:\tlearn: 0.0411288\ttotal: 5.01s\tremaining: 6s\n",
            "455:\tlearn: 0.0409717\ttotal: 5.02s\tremaining: 5.99s\n",
            "456:\tlearn: 0.0408637\ttotal: 5.04s\tremaining: 5.98s\n",
            "457:\tlearn: 0.0407481\ttotal: 5.04s\tremaining: 5.97s\n",
            "458:\tlearn: 0.0406472\ttotal: 5.05s\tremaining: 5.96s\n",
            "459:\tlearn: 0.0405667\ttotal: 5.07s\tremaining: 5.96s\n",
            "460:\tlearn: 0.0404882\ttotal: 5.08s\tremaining: 5.94s\n",
            "461:\tlearn: 0.0404083\ttotal: 5.1s\tremaining: 5.94s\n",
            "462:\tlearn: 0.0402818\ttotal: 5.11s\tremaining: 5.92s\n",
            "463:\tlearn: 0.0402002\ttotal: 5.12s\tremaining: 5.91s\n",
            "464:\tlearn: 0.0401200\ttotal: 5.13s\tremaining: 5.9s\n",
            "465:\tlearn: 0.0400035\ttotal: 5.14s\tremaining: 5.89s\n",
            "466:\tlearn: 0.0399256\ttotal: 5.15s\tremaining: 5.88s\n",
            "467:\tlearn: 0.0398468\ttotal: 5.16s\tremaining: 5.87s\n",
            "468:\tlearn: 0.0397770\ttotal: 5.17s\tremaining: 5.85s\n",
            "469:\tlearn: 0.0396302\ttotal: 5.18s\tremaining: 5.84s\n",
            "470:\tlearn: 0.0395687\ttotal: 5.19s\tremaining: 5.83s\n",
            "471:\tlearn: 0.0394775\ttotal: 5.2s\tremaining: 5.82s\n",
            "472:\tlearn: 0.0393859\ttotal: 5.21s\tremaining: 5.81s\n",
            "473:\tlearn: 0.0393068\ttotal: 5.22s\tremaining: 5.79s\n",
            "474:\tlearn: 0.0392170\ttotal: 5.23s\tremaining: 5.78s\n",
            "475:\tlearn: 0.0391727\ttotal: 5.24s\tremaining: 5.77s\n",
            "476:\tlearn: 0.0390222\ttotal: 5.25s\tremaining: 5.76s\n",
            "477:\tlearn: 0.0389166\ttotal: 5.27s\tremaining: 5.75s\n",
            "478:\tlearn: 0.0388247\ttotal: 5.29s\tremaining: 5.75s\n",
            "479:\tlearn: 0.0387276\ttotal: 5.3s\tremaining: 5.74s\n",
            "480:\tlearn: 0.0386217\ttotal: 5.31s\tremaining: 5.73s\n",
            "481:\tlearn: 0.0385240\ttotal: 5.32s\tremaining: 5.72s\n",
            "482:\tlearn: 0.0384557\ttotal: 5.33s\tremaining: 5.71s\n",
            "483:\tlearn: 0.0383715\ttotal: 5.34s\tremaining: 5.7s\n",
            "484:\tlearn: 0.0382736\ttotal: 5.35s\tremaining: 5.68s\n",
            "485:\tlearn: 0.0381878\ttotal: 5.36s\tremaining: 5.67s\n",
            "486:\tlearn: 0.0380698\ttotal: 5.37s\tremaining: 5.66s\n",
            "487:\tlearn: 0.0379734\ttotal: 5.38s\tremaining: 5.65s\n",
            "488:\tlearn: 0.0378776\ttotal: 5.39s\tremaining: 5.64s\n",
            "489:\tlearn: 0.0377799\ttotal: 5.41s\tremaining: 5.63s\n",
            "490:\tlearn: 0.0376433\ttotal: 5.42s\tremaining: 5.61s\n",
            "491:\tlearn: 0.0375353\ttotal: 5.43s\tremaining: 5.6s\n",
            "492:\tlearn: 0.0374466\ttotal: 5.44s\tremaining: 5.59s\n",
            "493:\tlearn: 0.0373533\ttotal: 5.45s\tremaining: 5.58s\n",
            "494:\tlearn: 0.0372595\ttotal: 5.46s\tremaining: 5.57s\n",
            "495:\tlearn: 0.0371906\ttotal: 5.47s\tremaining: 5.56s\n",
            "496:\tlearn: 0.0370816\ttotal: 5.48s\tremaining: 5.55s\n",
            "497:\tlearn: 0.0370307\ttotal: 5.5s\tremaining: 5.54s\n",
            "498:\tlearn: 0.0369677\ttotal: 5.51s\tremaining: 5.53s\n",
            "499:\tlearn: 0.0368764\ttotal: 5.52s\tremaining: 5.52s\n",
            "500:\tlearn: 0.0368199\ttotal: 5.53s\tremaining: 5.51s\n",
            "501:\tlearn: 0.0367016\ttotal: 5.54s\tremaining: 5.5s\n",
            "502:\tlearn: 0.0366004\ttotal: 5.55s\tremaining: 5.48s\n",
            "503:\tlearn: 0.0365147\ttotal: 5.56s\tremaining: 5.47s\n",
            "504:\tlearn: 0.0364521\ttotal: 5.57s\tremaining: 5.46s\n",
            "505:\tlearn: 0.0363452\ttotal: 5.58s\tremaining: 5.45s\n",
            "506:\tlearn: 0.0362526\ttotal: 5.59s\tremaining: 5.44s\n",
            "507:\tlearn: 0.0361342\ttotal: 5.6s\tremaining: 5.43s\n",
            "508:\tlearn: 0.0360185\ttotal: 5.61s\tremaining: 5.41s\n",
            "509:\tlearn: 0.0359165\ttotal: 5.62s\tremaining: 5.4s\n",
            "510:\tlearn: 0.0358382\ttotal: 5.63s\tremaining: 5.39s\n",
            "511:\tlearn: 0.0357155\ttotal: 5.65s\tremaining: 5.38s\n",
            "512:\tlearn: 0.0356381\ttotal: 5.66s\tremaining: 5.37s\n",
            "513:\tlearn: 0.0355324\ttotal: 5.67s\tremaining: 5.36s\n",
            "514:\tlearn: 0.0353956\ttotal: 5.68s\tremaining: 5.35s\n",
            "515:\tlearn: 0.0352894\ttotal: 5.69s\tremaining: 5.33s\n",
            "516:\tlearn: 0.0351724\ttotal: 5.7s\tremaining: 5.33s\n",
            "517:\tlearn: 0.0350865\ttotal: 5.71s\tremaining: 5.32s\n",
            "518:\tlearn: 0.0349383\ttotal: 5.72s\tremaining: 5.3s\n",
            "519:\tlearn: 0.0348683\ttotal: 5.73s\tremaining: 5.29s\n",
            "520:\tlearn: 0.0348154\ttotal: 5.74s\tremaining: 5.28s\n",
            "521:\tlearn: 0.0347391\ttotal: 5.75s\tremaining: 5.27s\n",
            "522:\tlearn: 0.0346577\ttotal: 5.76s\tremaining: 5.26s\n",
            "523:\tlearn: 0.0345835\ttotal: 5.78s\tremaining: 5.25s\n",
            "524:\tlearn: 0.0345378\ttotal: 5.79s\tremaining: 5.23s\n",
            "525:\tlearn: 0.0344430\ttotal: 5.8s\tremaining: 5.22s\n",
            "526:\tlearn: 0.0343984\ttotal: 5.81s\tremaining: 5.21s\n",
            "527:\tlearn: 0.0342801\ttotal: 5.82s\tremaining: 5.2s\n",
            "528:\tlearn: 0.0342222\ttotal: 5.83s\tremaining: 5.19s\n",
            "529:\tlearn: 0.0341304\ttotal: 5.84s\tremaining: 5.18s\n",
            "530:\tlearn: 0.0340501\ttotal: 5.85s\tremaining: 5.16s\n",
            "531:\tlearn: 0.0339868\ttotal: 5.86s\tremaining: 5.15s\n",
            "532:\tlearn: 0.0339154\ttotal: 5.87s\tremaining: 5.14s\n",
            "533:\tlearn: 0.0338314\ttotal: 5.88s\tremaining: 5.13s\n",
            "534:\tlearn: 0.0337607\ttotal: 5.89s\tremaining: 5.12s\n",
            "535:\tlearn: 0.0336918\ttotal: 5.9s\tremaining: 5.11s\n",
            "536:\tlearn: 0.0336088\ttotal: 5.91s\tremaining: 5.1s\n",
            "537:\tlearn: 0.0335585\ttotal: 5.92s\tremaining: 5.09s\n",
            "538:\tlearn: 0.0334939\ttotal: 5.93s\tremaining: 5.08s\n",
            "539:\tlearn: 0.0334282\ttotal: 5.94s\tremaining: 5.06s\n",
            "540:\tlearn: 0.0333440\ttotal: 5.96s\tremaining: 5.06s\n",
            "541:\tlearn: 0.0332607\ttotal: 5.97s\tremaining: 5.05s\n",
            "542:\tlearn: 0.0331904\ttotal: 5.98s\tremaining: 5.04s\n",
            "543:\tlearn: 0.0331032\ttotal: 5.99s\tremaining: 5.02s\n",
            "544:\tlearn: 0.0330169\ttotal: 6s\tremaining: 5.01s\n",
            "545:\tlearn: 0.0328956\ttotal: 6.03s\tremaining: 5.01s\n",
            "546:\tlearn: 0.0328230\ttotal: 6.05s\tremaining: 5.01s\n",
            "547:\tlearn: 0.0327295\ttotal: 6.07s\tremaining: 5s\n",
            "548:\tlearn: 0.0326536\ttotal: 6.09s\tremaining: 5s\n",
            "549:\tlearn: 0.0325428\ttotal: 6.11s\tremaining: 5s\n",
            "550:\tlearn: 0.0324555\ttotal: 6.13s\tremaining: 4.99s\n",
            "551:\tlearn: 0.0323718\ttotal: 6.14s\tremaining: 4.98s\n",
            "552:\tlearn: 0.0322932\ttotal: 6.15s\tremaining: 4.97s\n",
            "553:\tlearn: 0.0322515\ttotal: 6.16s\tremaining: 4.96s\n",
            "554:\tlearn: 0.0321620\ttotal: 6.17s\tremaining: 4.95s\n",
            "555:\tlearn: 0.0320618\ttotal: 6.18s\tremaining: 4.93s\n",
            "556:\tlearn: 0.0319595\ttotal: 6.19s\tremaining: 4.92s\n",
            "557:\tlearn: 0.0318937\ttotal: 6.2s\tremaining: 4.91s\n",
            "558:\tlearn: 0.0318340\ttotal: 6.21s\tremaining: 4.9s\n",
            "559:\tlearn: 0.0317701\ttotal: 6.22s\tremaining: 4.88s\n",
            "560:\tlearn: 0.0316722\ttotal: 6.23s\tremaining: 4.87s\n",
            "561:\tlearn: 0.0316020\ttotal: 6.24s\tremaining: 4.86s\n",
            "562:\tlearn: 0.0315198\ttotal: 6.25s\tremaining: 4.86s\n",
            "563:\tlearn: 0.0314543\ttotal: 6.26s\tremaining: 4.84s\n",
            "564:\tlearn: 0.0313879\ttotal: 6.29s\tremaining: 4.84s\n",
            "565:\tlearn: 0.0313076\ttotal: 6.3s\tremaining: 4.83s\n",
            "566:\tlearn: 0.0312412\ttotal: 6.31s\tremaining: 4.82s\n",
            "567:\tlearn: 0.0311862\ttotal: 6.33s\tremaining: 4.82s\n",
            "568:\tlearn: 0.0311269\ttotal: 6.34s\tremaining: 4.8s\n",
            "569:\tlearn: 0.0310463\ttotal: 6.35s\tremaining: 4.79s\n",
            "570:\tlearn: 0.0309905\ttotal: 6.37s\tremaining: 4.78s\n",
            "571:\tlearn: 0.0309210\ttotal: 6.38s\tremaining: 4.77s\n",
            "572:\tlearn: 0.0308503\ttotal: 6.39s\tremaining: 4.76s\n",
            "573:\tlearn: 0.0307676\ttotal: 6.4s\tremaining: 4.75s\n",
            "574:\tlearn: 0.0307157\ttotal: 6.41s\tremaining: 4.74s\n",
            "575:\tlearn: 0.0306301\ttotal: 6.42s\tremaining: 4.72s\n",
            "576:\tlearn: 0.0304969\ttotal: 6.43s\tremaining: 4.71s\n",
            "577:\tlearn: 0.0304480\ttotal: 6.44s\tremaining: 4.7s\n",
            "578:\tlearn: 0.0303628\ttotal: 6.45s\tremaining: 4.69s\n",
            "579:\tlearn: 0.0303089\ttotal: 6.46s\tremaining: 4.68s\n",
            "580:\tlearn: 0.0302504\ttotal: 6.47s\tremaining: 4.67s\n",
            "581:\tlearn: 0.0301845\ttotal: 6.48s\tremaining: 4.65s\n",
            "582:\tlearn: 0.0301277\ttotal: 6.49s\tremaining: 4.64s\n",
            "583:\tlearn: 0.0300748\ttotal: 6.5s\tremaining: 4.63s\n",
            "584:\tlearn: 0.0300247\ttotal: 6.51s\tremaining: 4.62s\n",
            "585:\tlearn: 0.0299654\ttotal: 6.52s\tremaining: 4.61s\n",
            "586:\tlearn: 0.0298781\ttotal: 6.53s\tremaining: 4.59s\n",
            "587:\tlearn: 0.0298351\ttotal: 6.55s\tremaining: 4.59s\n",
            "588:\tlearn: 0.0297548\ttotal: 6.56s\tremaining: 4.58s\n",
            "589:\tlearn: 0.0296640\ttotal: 6.57s\tremaining: 4.56s\n",
            "590:\tlearn: 0.0295813\ttotal: 6.58s\tremaining: 4.55s\n",
            "591:\tlearn: 0.0295276\ttotal: 6.59s\tremaining: 4.54s\n",
            "592:\tlearn: 0.0294818\ttotal: 6.6s\tremaining: 4.53s\n",
            "593:\tlearn: 0.0294427\ttotal: 6.61s\tremaining: 4.52s\n",
            "594:\tlearn: 0.0293793\ttotal: 6.62s\tremaining: 4.5s\n",
            "595:\tlearn: 0.0292668\ttotal: 6.63s\tremaining: 4.49s\n",
            "596:\tlearn: 0.0292192\ttotal: 6.64s\tremaining: 4.48s\n",
            "597:\tlearn: 0.0291640\ttotal: 6.65s\tremaining: 4.47s\n",
            "598:\tlearn: 0.0291090\ttotal: 6.66s\tremaining: 4.46s\n",
            "599:\tlearn: 0.0290501\ttotal: 6.67s\tremaining: 4.45s\n",
            "600:\tlearn: 0.0289560\ttotal: 6.68s\tremaining: 4.44s\n",
            "601:\tlearn: 0.0289059\ttotal: 6.69s\tremaining: 4.42s\n",
            "602:\tlearn: 0.0288349\ttotal: 6.7s\tremaining: 4.41s\n",
            "603:\tlearn: 0.0287712\ttotal: 6.71s\tremaining: 4.4s\n",
            "604:\tlearn: 0.0287448\ttotal: 6.72s\tremaining: 4.39s\n",
            "605:\tlearn: 0.0287036\ttotal: 6.73s\tremaining: 4.38s\n",
            "606:\tlearn: 0.0286533\ttotal: 6.74s\tremaining: 4.37s\n",
            "607:\tlearn: 0.0285964\ttotal: 6.76s\tremaining: 4.36s\n",
            "608:\tlearn: 0.0285282\ttotal: 6.77s\tremaining: 4.35s\n",
            "609:\tlearn: 0.0284827\ttotal: 6.78s\tremaining: 4.33s\n",
            "610:\tlearn: 0.0284442\ttotal: 6.79s\tremaining: 4.32s\n",
            "611:\tlearn: 0.0283688\ttotal: 6.8s\tremaining: 4.31s\n",
            "612:\tlearn: 0.0283102\ttotal: 6.81s\tremaining: 4.3s\n",
            "613:\tlearn: 0.0282724\ttotal: 6.82s\tremaining: 4.29s\n",
            "614:\tlearn: 0.0282120\ttotal: 6.83s\tremaining: 4.28s\n",
            "615:\tlearn: 0.0281469\ttotal: 6.84s\tremaining: 4.26s\n",
            "616:\tlearn: 0.0280835\ttotal: 6.85s\tremaining: 4.25s\n",
            "617:\tlearn: 0.0280399\ttotal: 6.86s\tremaining: 4.24s\n",
            "618:\tlearn: 0.0279838\ttotal: 6.87s\tremaining: 4.23s\n",
            "619:\tlearn: 0.0279233\ttotal: 6.88s\tremaining: 4.22s\n",
            "620:\tlearn: 0.0278768\ttotal: 6.89s\tremaining: 4.21s\n",
            "621:\tlearn: 0.0278205\ttotal: 6.9s\tremaining: 4.19s\n",
            "622:\tlearn: 0.0277360\ttotal: 6.92s\tremaining: 4.18s\n",
            "623:\tlearn: 0.0276711\ttotal: 6.93s\tremaining: 4.17s\n",
            "624:\tlearn: 0.0275927\ttotal: 6.95s\tremaining: 4.17s\n",
            "625:\tlearn: 0.0275388\ttotal: 6.96s\tremaining: 4.16s\n",
            "626:\tlearn: 0.0274945\ttotal: 6.97s\tremaining: 4.15s\n",
            "627:\tlearn: 0.0274186\ttotal: 6.99s\tremaining: 4.14s\n",
            "628:\tlearn: 0.0273721\ttotal: 7s\tremaining: 4.13s\n",
            "629:\tlearn: 0.0273256\ttotal: 7.01s\tremaining: 4.12s\n",
            "630:\tlearn: 0.0272734\ttotal: 7.02s\tremaining: 4.11s\n",
            "631:\tlearn: 0.0272358\ttotal: 7.03s\tremaining: 4.09s\n",
            "632:\tlearn: 0.0271944\ttotal: 7.04s\tremaining: 4.08s\n",
            "633:\tlearn: 0.0271210\ttotal: 7.05s\tremaining: 4.07s\n",
            "634:\tlearn: 0.0270494\ttotal: 7.06s\tremaining: 4.06s\n",
            "635:\tlearn: 0.0270000\ttotal: 7.07s\tremaining: 4.05s\n",
            "636:\tlearn: 0.0269183\ttotal: 7.08s\tremaining: 4.04s\n",
            "637:\tlearn: 0.0268804\ttotal: 7.09s\tremaining: 4.02s\n",
            "638:\tlearn: 0.0268175\ttotal: 7.1s\tremaining: 4.01s\n",
            "639:\tlearn: 0.0267728\ttotal: 7.11s\tremaining: 4s\n",
            "640:\tlearn: 0.0267222\ttotal: 7.12s\tremaining: 3.99s\n",
            "641:\tlearn: 0.0266708\ttotal: 7.13s\tremaining: 3.98s\n",
            "642:\tlearn: 0.0266103\ttotal: 7.14s\tremaining: 3.97s\n",
            "643:\tlearn: 0.0265578\ttotal: 7.16s\tremaining: 3.96s\n",
            "644:\tlearn: 0.0265120\ttotal: 7.17s\tremaining: 3.95s\n",
            "645:\tlearn: 0.0264724\ttotal: 7.18s\tremaining: 3.94s\n",
            "646:\tlearn: 0.0264012\ttotal: 7.19s\tremaining: 3.92s\n",
            "647:\tlearn: 0.0263553\ttotal: 7.2s\tremaining: 3.91s\n",
            "648:\tlearn: 0.0263261\ttotal: 7.21s\tremaining: 3.9s\n",
            "649:\tlearn: 0.0263037\ttotal: 7.22s\tremaining: 3.89s\n",
            "650:\tlearn: 0.0262527\ttotal: 7.23s\tremaining: 3.88s\n",
            "651:\tlearn: 0.0262004\ttotal: 7.24s\tremaining: 3.87s\n",
            "652:\tlearn: 0.0261587\ttotal: 7.25s\tremaining: 3.85s\n",
            "653:\tlearn: 0.0260925\ttotal: 7.26s\tremaining: 3.84s\n",
            "654:\tlearn: 0.0260166\ttotal: 7.27s\tremaining: 3.83s\n",
            "655:\tlearn: 0.0259432\ttotal: 7.3s\tremaining: 3.83s\n",
            "656:\tlearn: 0.0258832\ttotal: 7.31s\tremaining: 3.82s\n",
            "657:\tlearn: 0.0258006\ttotal: 7.32s\tremaining: 3.8s\n",
            "658:\tlearn: 0.0257395\ttotal: 7.33s\tremaining: 3.79s\n",
            "659:\tlearn: 0.0256752\ttotal: 7.34s\tremaining: 3.78s\n",
            "660:\tlearn: 0.0256142\ttotal: 7.35s\tremaining: 3.77s\n",
            "661:\tlearn: 0.0255732\ttotal: 7.36s\tremaining: 3.76s\n",
            "662:\tlearn: 0.0255449\ttotal: 7.38s\tremaining: 3.75s\n",
            "663:\tlearn: 0.0255107\ttotal: 7.39s\tremaining: 3.74s\n",
            "664:\tlearn: 0.0254675\ttotal: 7.4s\tremaining: 3.73s\n",
            "665:\tlearn: 0.0253921\ttotal: 7.42s\tremaining: 3.72s\n",
            "666:\tlearn: 0.0253399\ttotal: 7.42s\tremaining: 3.71s\n",
            "667:\tlearn: 0.0252998\ttotal: 7.44s\tremaining: 3.7s\n",
            "668:\tlearn: 0.0252677\ttotal: 7.45s\tremaining: 3.69s\n",
            "669:\tlearn: 0.0252182\ttotal: 7.46s\tremaining: 3.67s\n",
            "670:\tlearn: 0.0251811\ttotal: 7.47s\tremaining: 3.66s\n",
            "671:\tlearn: 0.0251287\ttotal: 7.48s\tremaining: 3.65s\n",
            "672:\tlearn: 0.0251033\ttotal: 7.49s\tremaining: 3.64s\n",
            "673:\tlearn: 0.0250584\ttotal: 7.5s\tremaining: 3.63s\n",
            "674:\tlearn: 0.0249924\ttotal: 7.51s\tremaining: 3.62s\n",
            "675:\tlearn: 0.0249400\ttotal: 7.52s\tremaining: 3.6s\n",
            "676:\tlearn: 0.0248672\ttotal: 7.53s\tremaining: 3.59s\n",
            "677:\tlearn: 0.0248236\ttotal: 7.54s\tremaining: 3.58s\n",
            "678:\tlearn: 0.0247700\ttotal: 7.55s\tremaining: 3.57s\n",
            "679:\tlearn: 0.0247171\ttotal: 7.56s\tremaining: 3.56s\n",
            "680:\tlearn: 0.0246715\ttotal: 7.57s\tremaining: 3.55s\n",
            "681:\tlearn: 0.0246419\ttotal: 7.59s\tremaining: 3.54s\n",
            "682:\tlearn: 0.0245977\ttotal: 7.6s\tremaining: 3.53s\n",
            "683:\tlearn: 0.0245345\ttotal: 7.61s\tremaining: 3.51s\n",
            "684:\tlearn: 0.0244826\ttotal: 7.62s\tremaining: 3.5s\n",
            "685:\tlearn: 0.0244316\ttotal: 7.63s\tremaining: 3.49s\n",
            "686:\tlearn: 0.0243580\ttotal: 7.65s\tremaining: 3.48s\n",
            "687:\tlearn: 0.0243288\ttotal: 7.66s\tremaining: 3.47s\n",
            "688:\tlearn: 0.0242561\ttotal: 7.67s\tremaining: 3.46s\n",
            "689:\tlearn: 0.0241908\ttotal: 7.68s\tremaining: 3.45s\n",
            "690:\tlearn: 0.0241432\ttotal: 7.69s\tremaining: 3.44s\n",
            "691:\tlearn: 0.0240917\ttotal: 7.7s\tremaining: 3.43s\n",
            "692:\tlearn: 0.0240452\ttotal: 7.71s\tremaining: 3.41s\n",
            "693:\tlearn: 0.0239982\ttotal: 7.72s\tremaining: 3.4s\n",
            "694:\tlearn: 0.0239449\ttotal: 7.73s\tremaining: 3.39s\n",
            "695:\tlearn: 0.0238851\ttotal: 7.74s\tremaining: 3.38s\n",
            "696:\tlearn: 0.0238384\ttotal: 7.75s\tremaining: 3.37s\n",
            "697:\tlearn: 0.0237860\ttotal: 7.76s\tremaining: 3.36s\n",
            "698:\tlearn: 0.0237361\ttotal: 7.77s\tremaining: 3.35s\n",
            "699:\tlearn: 0.0236791\ttotal: 7.79s\tremaining: 3.34s\n",
            "700:\tlearn: 0.0236144\ttotal: 7.8s\tremaining: 3.33s\n",
            "701:\tlearn: 0.0235621\ttotal: 7.81s\tremaining: 3.31s\n",
            "702:\tlearn: 0.0234922\ttotal: 7.82s\tremaining: 3.3s\n",
            "703:\tlearn: 0.0234419\ttotal: 7.83s\tremaining: 3.29s\n",
            "704:\tlearn: 0.0234305\ttotal: 7.84s\tremaining: 3.28s\n",
            "705:\tlearn: 0.0233558\ttotal: 7.85s\tremaining: 3.27s\n",
            "706:\tlearn: 0.0233047\ttotal: 7.86s\tremaining: 3.26s\n",
            "707:\tlearn: 0.0232775\ttotal: 7.87s\tremaining: 3.25s\n",
            "708:\tlearn: 0.0232240\ttotal: 7.88s\tremaining: 3.23s\n",
            "709:\tlearn: 0.0231732\ttotal: 7.89s\tremaining: 3.22s\n",
            "710:\tlearn: 0.0231230\ttotal: 7.9s\tremaining: 3.21s\n",
            "711:\tlearn: 0.0230959\ttotal: 7.92s\tremaining: 3.2s\n",
            "712:\tlearn: 0.0230402\ttotal: 7.93s\tremaining: 3.19s\n",
            "713:\tlearn: 0.0230006\ttotal: 7.94s\tremaining: 3.18s\n",
            "714:\tlearn: 0.0229415\ttotal: 7.95s\tremaining: 3.17s\n",
            "715:\tlearn: 0.0229111\ttotal: 7.96s\tremaining: 3.16s\n",
            "716:\tlearn: 0.0228620\ttotal: 7.97s\tremaining: 3.15s\n",
            "717:\tlearn: 0.0228066\ttotal: 7.98s\tremaining: 3.13s\n",
            "718:\tlearn: 0.0227706\ttotal: 7.99s\tremaining: 3.12s\n",
            "719:\tlearn: 0.0227056\ttotal: 8s\tremaining: 3.11s\n",
            "720:\tlearn: 0.0226437\ttotal: 8.01s\tremaining: 3.1s\n",
            "721:\tlearn: 0.0226094\ttotal: 8.03s\tremaining: 3.09s\n",
            "722:\tlearn: 0.0225657\ttotal: 8.04s\tremaining: 3.08s\n",
            "723:\tlearn: 0.0225183\ttotal: 8.04s\tremaining: 3.07s\n",
            "724:\tlearn: 0.0224892\ttotal: 8.05s\tremaining: 3.06s\n",
            "725:\tlearn: 0.0224402\ttotal: 8.06s\tremaining: 3.04s\n",
            "726:\tlearn: 0.0223722\ttotal: 8.08s\tremaining: 3.03s\n",
            "727:\tlearn: 0.0223156\ttotal: 8.09s\tremaining: 3.02s\n",
            "728:\tlearn: 0.0222802\ttotal: 8.1s\tremaining: 3.01s\n",
            "729:\tlearn: 0.0222423\ttotal: 8.11s\tremaining: 3s\n",
            "730:\tlearn: 0.0221960\ttotal: 8.12s\tremaining: 2.99s\n",
            "731:\tlearn: 0.0221382\ttotal: 8.13s\tremaining: 2.98s\n",
            "732:\tlearn: 0.0220924\ttotal: 8.14s\tremaining: 2.96s\n",
            "733:\tlearn: 0.0220542\ttotal: 8.15s\tremaining: 2.95s\n",
            "734:\tlearn: 0.0220047\ttotal: 8.16s\tremaining: 2.94s\n",
            "735:\tlearn: 0.0219543\ttotal: 8.17s\tremaining: 2.93s\n",
            "736:\tlearn: 0.0219220\ttotal: 8.18s\tremaining: 2.92s\n",
            "737:\tlearn: 0.0218806\ttotal: 8.19s\tremaining: 2.91s\n",
            "738:\tlearn: 0.0218446\ttotal: 8.21s\tremaining: 2.9s\n",
            "739:\tlearn: 0.0217898\ttotal: 8.22s\tremaining: 2.89s\n",
            "740:\tlearn: 0.0217623\ttotal: 8.23s\tremaining: 2.88s\n",
            "741:\tlearn: 0.0217228\ttotal: 8.24s\tremaining: 2.87s\n",
            "742:\tlearn: 0.0216529\ttotal: 8.26s\tremaining: 2.85s\n",
            "743:\tlearn: 0.0215996\ttotal: 8.27s\tremaining: 2.84s\n",
            "744:\tlearn: 0.0215560\ttotal: 8.28s\tremaining: 2.83s\n",
            "745:\tlearn: 0.0215056\ttotal: 8.3s\tremaining: 2.82s\n",
            "746:\tlearn: 0.0214663\ttotal: 8.31s\tremaining: 2.81s\n",
            "747:\tlearn: 0.0214346\ttotal: 8.32s\tremaining: 2.8s\n",
            "748:\tlearn: 0.0214038\ttotal: 8.34s\tremaining: 2.79s\n",
            "749:\tlearn: 0.0213594\ttotal: 8.35s\tremaining: 2.78s\n",
            "750:\tlearn: 0.0213119\ttotal: 8.36s\tremaining: 2.77s\n",
            "751:\tlearn: 0.0212674\ttotal: 8.37s\tremaining: 2.76s\n",
            "752:\tlearn: 0.0212394\ttotal: 8.38s\tremaining: 2.75s\n",
            "753:\tlearn: 0.0211900\ttotal: 8.39s\tremaining: 2.74s\n",
            "754:\tlearn: 0.0211439\ttotal: 8.4s\tremaining: 2.72s\n",
            "755:\tlearn: 0.0210995\ttotal: 8.41s\tremaining: 2.71s\n",
            "756:\tlearn: 0.0210388\ttotal: 8.43s\tremaining: 2.7s\n",
            "757:\tlearn: 0.0209905\ttotal: 8.44s\tremaining: 2.69s\n",
            "758:\tlearn: 0.0209319\ttotal: 8.45s\tremaining: 2.68s\n",
            "759:\tlearn: 0.0208840\ttotal: 8.46s\tremaining: 2.67s\n",
            "760:\tlearn: 0.0208452\ttotal: 8.47s\tremaining: 2.66s\n",
            "761:\tlearn: 0.0207993\ttotal: 8.48s\tremaining: 2.65s\n",
            "762:\tlearn: 0.0207467\ttotal: 8.49s\tremaining: 2.64s\n",
            "763:\tlearn: 0.0207313\ttotal: 8.5s\tremaining: 2.62s\n",
            "764:\tlearn: 0.0206912\ttotal: 8.51s\tremaining: 2.61s\n",
            "765:\tlearn: 0.0206478\ttotal: 8.52s\tremaining: 2.6s\n",
            "766:\tlearn: 0.0206012\ttotal: 8.53s\tremaining: 2.59s\n",
            "767:\tlearn: 0.0205470\ttotal: 8.54s\tremaining: 2.58s\n",
            "768:\tlearn: 0.0205145\ttotal: 8.55s\tremaining: 2.57s\n",
            "769:\tlearn: 0.0204817\ttotal: 8.56s\tremaining: 2.56s\n",
            "770:\tlearn: 0.0204405\ttotal: 8.57s\tremaining: 2.54s\n",
            "771:\tlearn: 0.0204001\ttotal: 8.58s\tremaining: 2.53s\n",
            "772:\tlearn: 0.0203526\ttotal: 8.59s\tremaining: 2.52s\n",
            "773:\tlearn: 0.0203198\ttotal: 8.6s\tremaining: 2.51s\n",
            "774:\tlearn: 0.0202880\ttotal: 8.61s\tremaining: 2.5s\n",
            "775:\tlearn: 0.0202360\ttotal: 8.63s\tremaining: 2.49s\n",
            "776:\tlearn: 0.0202030\ttotal: 8.64s\tremaining: 2.48s\n",
            "777:\tlearn: 0.0201694\ttotal: 8.65s\tremaining: 2.47s\n",
            "778:\tlearn: 0.0201309\ttotal: 8.66s\tremaining: 2.46s\n",
            "779:\tlearn: 0.0200793\ttotal: 8.67s\tremaining: 2.44s\n",
            "780:\tlearn: 0.0200354\ttotal: 8.68s\tremaining: 2.43s\n",
            "781:\tlearn: 0.0199945\ttotal: 8.69s\tremaining: 2.42s\n",
            "782:\tlearn: 0.0199739\ttotal: 8.7s\tremaining: 2.41s\n",
            "783:\tlearn: 0.0199361\ttotal: 8.71s\tremaining: 2.4s\n",
            "784:\tlearn: 0.0199075\ttotal: 8.72s\tremaining: 2.39s\n",
            "785:\tlearn: 0.0198738\ttotal: 8.73s\tremaining: 2.38s\n",
            "786:\tlearn: 0.0198265\ttotal: 8.74s\tremaining: 2.37s\n",
            "787:\tlearn: 0.0197982\ttotal: 8.75s\tremaining: 2.35s\n",
            "788:\tlearn: 0.0197659\ttotal: 8.76s\tremaining: 2.34s\n",
            "789:\tlearn: 0.0197278\ttotal: 8.77s\tremaining: 2.33s\n",
            "790:\tlearn: 0.0196782\ttotal: 8.78s\tremaining: 2.32s\n",
            "791:\tlearn: 0.0196479\ttotal: 8.79s\tremaining: 2.31s\n",
            "792:\tlearn: 0.0196200\ttotal: 8.8s\tremaining: 2.3s\n",
            "793:\tlearn: 0.0195902\ttotal: 8.82s\tremaining: 2.29s\n",
            "794:\tlearn: 0.0195435\ttotal: 8.83s\tremaining: 2.28s\n",
            "795:\tlearn: 0.0194835\ttotal: 8.84s\tremaining: 2.27s\n",
            "796:\tlearn: 0.0194579\ttotal: 8.85s\tremaining: 2.25s\n",
            "797:\tlearn: 0.0194324\ttotal: 8.86s\tremaining: 2.24s\n",
            "798:\tlearn: 0.0193964\ttotal: 8.87s\tremaining: 2.23s\n",
            "799:\tlearn: 0.0193667\ttotal: 8.88s\tremaining: 2.22s\n",
            "800:\tlearn: 0.0193284\ttotal: 8.9s\tremaining: 2.21s\n",
            "801:\tlearn: 0.0192892\ttotal: 8.91s\tremaining: 2.2s\n",
            "802:\tlearn: 0.0192537\ttotal: 8.92s\tremaining: 2.19s\n",
            "803:\tlearn: 0.0192135\ttotal: 8.93s\tremaining: 2.18s\n",
            "804:\tlearn: 0.0191829\ttotal: 8.94s\tremaining: 2.17s\n",
            "805:\tlearn: 0.0191376\ttotal: 8.95s\tremaining: 2.15s\n",
            "806:\tlearn: 0.0191081\ttotal: 8.96s\tremaining: 2.14s\n",
            "807:\tlearn: 0.0190703\ttotal: 8.97s\tremaining: 2.13s\n",
            "808:\tlearn: 0.0190322\ttotal: 8.98s\tremaining: 2.12s\n",
            "809:\tlearn: 0.0189919\ttotal: 8.99s\tremaining: 2.11s\n",
            "810:\tlearn: 0.0189607\ttotal: 9.01s\tremaining: 2.1s\n",
            "811:\tlearn: 0.0189329\ttotal: 9.02s\tremaining: 2.09s\n",
            "812:\tlearn: 0.0189034\ttotal: 9.03s\tremaining: 2.08s\n",
            "813:\tlearn: 0.0188524\ttotal: 9.04s\tremaining: 2.07s\n",
            "814:\tlearn: 0.0188217\ttotal: 9.05s\tremaining: 2.06s\n",
            "815:\tlearn: 0.0187857\ttotal: 9.07s\tremaining: 2.04s\n",
            "816:\tlearn: 0.0187461\ttotal: 9.07s\tremaining: 2.03s\n",
            "817:\tlearn: 0.0186965\ttotal: 9.09s\tremaining: 2.02s\n",
            "818:\tlearn: 0.0186561\ttotal: 9.1s\tremaining: 2.01s\n",
            "819:\tlearn: 0.0186283\ttotal: 9.11s\tremaining: 2s\n",
            "820:\tlearn: 0.0186054\ttotal: 9.12s\tremaining: 1.99s\n",
            "821:\tlearn: 0.0185589\ttotal: 9.13s\tremaining: 1.98s\n",
            "822:\tlearn: 0.0185296\ttotal: 9.14s\tremaining: 1.96s\n",
            "823:\tlearn: 0.0184990\ttotal: 9.15s\tremaining: 1.95s\n",
            "824:\tlearn: 0.0184644\ttotal: 9.16s\tremaining: 1.94s\n",
            "825:\tlearn: 0.0184094\ttotal: 9.17s\tremaining: 1.93s\n",
            "826:\tlearn: 0.0183766\ttotal: 9.18s\tremaining: 1.92s\n",
            "827:\tlearn: 0.0183537\ttotal: 9.19s\tremaining: 1.91s\n",
            "828:\tlearn: 0.0183295\ttotal: 9.2s\tremaining: 1.9s\n",
            "829:\tlearn: 0.0183021\ttotal: 9.21s\tremaining: 1.89s\n",
            "830:\tlearn: 0.0182731\ttotal: 9.22s\tremaining: 1.87s\n",
            "831:\tlearn: 0.0182497\ttotal: 9.23s\tremaining: 1.86s\n",
            "832:\tlearn: 0.0182065\ttotal: 9.25s\tremaining: 1.85s\n",
            "833:\tlearn: 0.0181697\ttotal: 9.27s\tremaining: 1.84s\n",
            "834:\tlearn: 0.0181381\ttotal: 9.29s\tremaining: 1.83s\n",
            "835:\tlearn: 0.0180965\ttotal: 9.31s\tremaining: 1.83s\n",
            "836:\tlearn: 0.0180605\ttotal: 9.33s\tremaining: 1.82s\n",
            "837:\tlearn: 0.0180265\ttotal: 9.35s\tremaining: 1.81s\n",
            "838:\tlearn: 0.0179964\ttotal: 9.36s\tremaining: 1.8s\n",
            "839:\tlearn: 0.0179429\ttotal: 9.37s\tremaining: 1.78s\n",
            "840:\tlearn: 0.0178928\ttotal: 9.4s\tremaining: 1.78s\n",
            "841:\tlearn: 0.0178567\ttotal: 9.41s\tremaining: 1.77s\n",
            "842:\tlearn: 0.0178142\ttotal: 9.43s\tremaining: 1.76s\n",
            "843:\tlearn: 0.0177744\ttotal: 9.45s\tremaining: 1.75s\n",
            "844:\tlearn: 0.0177441\ttotal: 9.47s\tremaining: 1.74s\n",
            "845:\tlearn: 0.0177103\ttotal: 9.49s\tremaining: 1.73s\n",
            "846:\tlearn: 0.0176898\ttotal: 9.51s\tremaining: 1.72s\n",
            "847:\tlearn: 0.0176649\ttotal: 9.53s\tremaining: 1.71s\n",
            "848:\tlearn: 0.0176305\ttotal: 9.54s\tremaining: 1.7s\n",
            "849:\tlearn: 0.0175956\ttotal: 9.57s\tremaining: 1.69s\n",
            "850:\tlearn: 0.0175567\ttotal: 9.59s\tremaining: 1.68s\n",
            "851:\tlearn: 0.0175209\ttotal: 9.61s\tremaining: 1.67s\n",
            "852:\tlearn: 0.0174988\ttotal: 9.63s\tremaining: 1.66s\n",
            "853:\tlearn: 0.0174748\ttotal: 9.66s\tremaining: 1.65s\n",
            "854:\tlearn: 0.0174542\ttotal: 9.69s\tremaining: 1.64s\n",
            "855:\tlearn: 0.0174260\ttotal: 9.71s\tremaining: 1.63s\n",
            "856:\tlearn: 0.0173841\ttotal: 9.72s\tremaining: 1.62s\n",
            "857:\tlearn: 0.0173516\ttotal: 9.74s\tremaining: 1.61s\n",
            "858:\tlearn: 0.0173250\ttotal: 9.76s\tremaining: 1.6s\n",
            "859:\tlearn: 0.0172925\ttotal: 9.78s\tremaining: 1.59s\n",
            "860:\tlearn: 0.0172519\ttotal: 9.8s\tremaining: 1.58s\n",
            "861:\tlearn: 0.0172274\ttotal: 9.82s\tremaining: 1.57s\n",
            "862:\tlearn: 0.0171940\ttotal: 9.84s\tremaining: 1.56s\n",
            "863:\tlearn: 0.0171593\ttotal: 9.88s\tremaining: 1.55s\n",
            "864:\tlearn: 0.0171302\ttotal: 9.9s\tremaining: 1.54s\n",
            "865:\tlearn: 0.0171083\ttotal: 9.92s\tremaining: 1.53s\n",
            "866:\tlearn: 0.0170706\ttotal: 9.95s\tremaining: 1.52s\n",
            "867:\tlearn: 0.0170274\ttotal: 9.97s\tremaining: 1.52s\n",
            "868:\tlearn: 0.0169884\ttotal: 9.99s\tremaining: 1.51s\n",
            "869:\tlearn: 0.0169632\ttotal: 10s\tremaining: 1.5s\n",
            "870:\tlearn: 0.0169252\ttotal: 10s\tremaining: 1.49s\n",
            "871:\tlearn: 0.0168828\ttotal: 10.1s\tremaining: 1.48s\n",
            "872:\tlearn: 0.0168519\ttotal: 10.1s\tremaining: 1.47s\n",
            "873:\tlearn: 0.0168234\ttotal: 10.1s\tremaining: 1.46s\n",
            "874:\tlearn: 0.0167864\ttotal: 10.1s\tremaining: 1.45s\n",
            "875:\tlearn: 0.0167489\ttotal: 10.1s\tremaining: 1.44s\n",
            "876:\tlearn: 0.0166906\ttotal: 10.2s\tremaining: 1.43s\n",
            "877:\tlearn: 0.0166610\ttotal: 10.2s\tremaining: 1.42s\n",
            "878:\tlearn: 0.0166329\ttotal: 10.2s\tremaining: 1.41s\n",
            "879:\tlearn: 0.0166000\ttotal: 10.2s\tremaining: 1.4s\n",
            "880:\tlearn: 0.0165639\ttotal: 10.3s\tremaining: 1.38s\n",
            "881:\tlearn: 0.0165361\ttotal: 10.3s\tremaining: 1.37s\n",
            "882:\tlearn: 0.0164987\ttotal: 10.3s\tremaining: 1.36s\n",
            "883:\tlearn: 0.0164716\ttotal: 10.3s\tremaining: 1.35s\n",
            "884:\tlearn: 0.0164387\ttotal: 10.3s\tremaining: 1.34s\n",
            "885:\tlearn: 0.0164114\ttotal: 10.4s\tremaining: 1.33s\n",
            "886:\tlearn: 0.0163838\ttotal: 10.4s\tremaining: 1.32s\n",
            "887:\tlearn: 0.0163539\ttotal: 10.4s\tremaining: 1.31s\n",
            "888:\tlearn: 0.0163295\ttotal: 10.4s\tremaining: 1.3s\n",
            "889:\tlearn: 0.0163015\ttotal: 10.4s\tremaining: 1.29s\n",
            "890:\tlearn: 0.0162643\ttotal: 10.5s\tremaining: 1.28s\n",
            "891:\tlearn: 0.0162433\ttotal: 10.5s\tremaining: 1.27s\n",
            "892:\tlearn: 0.0162236\ttotal: 10.5s\tremaining: 1.26s\n",
            "893:\tlearn: 0.0161920\ttotal: 10.5s\tremaining: 1.25s\n",
            "894:\tlearn: 0.0161752\ttotal: 10.5s\tremaining: 1.23s\n",
            "895:\tlearn: 0.0161596\ttotal: 10.5s\tremaining: 1.22s\n",
            "896:\tlearn: 0.0161369\ttotal: 10.5s\tremaining: 1.21s\n",
            "897:\tlearn: 0.0161039\ttotal: 10.6s\tremaining: 1.2s\n",
            "898:\tlearn: 0.0160611\ttotal: 10.6s\tremaining: 1.19s\n",
            "899:\tlearn: 0.0160341\ttotal: 10.6s\tremaining: 1.18s\n",
            "900:\tlearn: 0.0160187\ttotal: 10.6s\tremaining: 1.17s\n",
            "901:\tlearn: 0.0159820\ttotal: 10.6s\tremaining: 1.15s\n",
            "902:\tlearn: 0.0159591\ttotal: 10.6s\tremaining: 1.14s\n",
            "903:\tlearn: 0.0159282\ttotal: 10.7s\tremaining: 1.13s\n",
            "904:\tlearn: 0.0158980\ttotal: 10.7s\tremaining: 1.12s\n",
            "905:\tlearn: 0.0158653\ttotal: 10.7s\tremaining: 1.11s\n",
            "906:\tlearn: 0.0158326\ttotal: 10.7s\tremaining: 1.1s\n",
            "907:\tlearn: 0.0158209\ttotal: 10.8s\tremaining: 1.09s\n",
            "908:\tlearn: 0.0157793\ttotal: 10.8s\tremaining: 1.08s\n",
            "909:\tlearn: 0.0157516\ttotal: 10.8s\tremaining: 1.07s\n",
            "910:\tlearn: 0.0157304\ttotal: 10.8s\tremaining: 1.06s\n",
            "911:\tlearn: 0.0157004\ttotal: 10.8s\tremaining: 1.04s\n",
            "912:\tlearn: 0.0156691\ttotal: 10.9s\tremaining: 1.03s\n",
            "913:\tlearn: 0.0156428\ttotal: 10.9s\tremaining: 1.02s\n",
            "914:\tlearn: 0.0156193\ttotal: 10.9s\tremaining: 1.01s\n",
            "915:\tlearn: 0.0155894\ttotal: 10.9s\tremaining: 1s\n",
            "916:\tlearn: 0.0155614\ttotal: 10.9s\tremaining: 991ms\n",
            "917:\tlearn: 0.0155379\ttotal: 11s\tremaining: 979ms\n",
            "918:\tlearn: 0.0155240\ttotal: 11s\tremaining: 968ms\n",
            "919:\tlearn: 0.0154928\ttotal: 11s\tremaining: 957ms\n",
            "920:\tlearn: 0.0154550\ttotal: 11s\tremaining: 947ms\n",
            "921:\tlearn: 0.0154287\ttotal: 11.1s\tremaining: 935ms\n",
            "922:\tlearn: 0.0154019\ttotal: 11.1s\tremaining: 923ms\n",
            "923:\tlearn: 0.0153592\ttotal: 11.1s\tremaining: 913ms\n",
            "924:\tlearn: 0.0153369\ttotal: 11.1s\tremaining: 902ms\n",
            "925:\tlearn: 0.0153093\ttotal: 11.1s\tremaining: 890ms\n",
            "926:\tlearn: 0.0152730\ttotal: 11.2s\tremaining: 878ms\n",
            "927:\tlearn: 0.0152423\ttotal: 11.2s\tremaining: 867ms\n",
            "928:\tlearn: 0.0152136\ttotal: 11.2s\tremaining: 856ms\n",
            "929:\tlearn: 0.0151831\ttotal: 11.2s\tremaining: 845ms\n",
            "930:\tlearn: 0.0151503\ttotal: 11.2s\tremaining: 833ms\n",
            "931:\tlearn: 0.0151315\ttotal: 11.3s\tremaining: 821ms\n",
            "932:\tlearn: 0.0150813\ttotal: 11.3s\tremaining: 809ms\n",
            "933:\tlearn: 0.0150509\ttotal: 11.3s\tremaining: 798ms\n",
            "934:\tlearn: 0.0150256\ttotal: 11.3s\tremaining: 786ms\n",
            "935:\tlearn: 0.0150059\ttotal: 11.3s\tremaining: 775ms\n",
            "936:\tlearn: 0.0149777\ttotal: 11.3s\tremaining: 763ms\n",
            "937:\tlearn: 0.0149547\ttotal: 11.4s\tremaining: 751ms\n",
            "938:\tlearn: 0.0149112\ttotal: 11.4s\tremaining: 740ms\n",
            "939:\tlearn: 0.0148909\ttotal: 11.4s\tremaining: 728ms\n",
            "940:\tlearn: 0.0148551\ttotal: 11.4s\tremaining: 716ms\n",
            "941:\tlearn: 0.0148411\ttotal: 11.4s\tremaining: 705ms\n",
            "942:\tlearn: 0.0148169\ttotal: 11.5s\tremaining: 693ms\n",
            "943:\tlearn: 0.0147918\ttotal: 11.5s\tremaining: 682ms\n",
            "944:\tlearn: 0.0147748\ttotal: 11.5s\tremaining: 670ms\n",
            "945:\tlearn: 0.0147485\ttotal: 11.5s\tremaining: 659ms\n",
            "946:\tlearn: 0.0147205\ttotal: 11.6s\tremaining: 647ms\n",
            "947:\tlearn: 0.0146956\ttotal: 11.6s\tremaining: 635ms\n",
            "948:\tlearn: 0.0146794\ttotal: 11.6s\tremaining: 623ms\n",
            "949:\tlearn: 0.0146532\ttotal: 11.6s\tremaining: 612ms\n",
            "950:\tlearn: 0.0146126\ttotal: 11.6s\tremaining: 600ms\n",
            "951:\tlearn: 0.0145802\ttotal: 11.7s\tremaining: 588ms\n",
            "952:\tlearn: 0.0145625\ttotal: 11.7s\tremaining: 576ms\n",
            "953:\tlearn: 0.0145393\ttotal: 11.7s\tremaining: 565ms\n",
            "954:\tlearn: 0.0144990\ttotal: 11.7s\tremaining: 553ms\n",
            "955:\tlearn: 0.0144678\ttotal: 11.8s\tremaining: 541ms\n",
            "956:\tlearn: 0.0144494\ttotal: 11.8s\tremaining: 529ms\n",
            "957:\tlearn: 0.0144304\ttotal: 11.8s\tremaining: 517ms\n",
            "958:\tlearn: 0.0144062\ttotal: 11.8s\tremaining: 505ms\n",
            "959:\tlearn: 0.0143797\ttotal: 11.8s\tremaining: 493ms\n",
            "960:\tlearn: 0.0143585\ttotal: 11.9s\tremaining: 481ms\n",
            "961:\tlearn: 0.0143276\ttotal: 11.9s\tremaining: 469ms\n",
            "962:\tlearn: 0.0143027\ttotal: 11.9s\tremaining: 457ms\n",
            "963:\tlearn: 0.0142740\ttotal: 11.9s\tremaining: 445ms\n",
            "964:\tlearn: 0.0142563\ttotal: 11.9s\tremaining: 433ms\n",
            "965:\tlearn: 0.0142258\ttotal: 12s\tremaining: 421ms\n",
            "966:\tlearn: 0.0142002\ttotal: 12s\tremaining: 409ms\n",
            "967:\tlearn: 0.0141654\ttotal: 12s\tremaining: 397ms\n",
            "968:\tlearn: 0.0141462\ttotal: 12s\tremaining: 385ms\n",
            "969:\tlearn: 0.0141278\ttotal: 12.1s\tremaining: 373ms\n",
            "970:\tlearn: 0.0141027\ttotal: 12.1s\tremaining: 361ms\n",
            "971:\tlearn: 0.0140689\ttotal: 12.1s\tremaining: 349ms\n",
            "972:\tlearn: 0.0140303\ttotal: 12.1s\tremaining: 337ms\n",
            "973:\tlearn: 0.0139867\ttotal: 12.1s\tremaining: 324ms\n",
            "974:\tlearn: 0.0139630\ttotal: 12.2s\tremaining: 312ms\n",
            "975:\tlearn: 0.0139287\ttotal: 12.2s\tremaining: 300ms\n",
            "976:\tlearn: 0.0139132\ttotal: 12.2s\tremaining: 288ms\n",
            "977:\tlearn: 0.0138756\ttotal: 12.2s\tremaining: 275ms\n",
            "978:\tlearn: 0.0138480\ttotal: 12.3s\tremaining: 263ms\n",
            "979:\tlearn: 0.0138183\ttotal: 12.3s\tremaining: 251ms\n",
            "980:\tlearn: 0.0137969\ttotal: 12.3s\tremaining: 238ms\n",
            "981:\tlearn: 0.0137805\ttotal: 12.3s\tremaining: 226ms\n",
            "982:\tlearn: 0.0137509\ttotal: 12.3s\tremaining: 214ms\n",
            "983:\tlearn: 0.0137325\ttotal: 12.4s\tremaining: 201ms\n",
            "984:\tlearn: 0.0137197\ttotal: 12.4s\tremaining: 189ms\n",
            "985:\tlearn: 0.0136986\ttotal: 12.4s\tremaining: 176ms\n",
            "986:\tlearn: 0.0136639\ttotal: 12.4s\tremaining: 164ms\n",
            "987:\tlearn: 0.0136377\ttotal: 12.5s\tremaining: 151ms\n",
            "988:\tlearn: 0.0136156\ttotal: 12.5s\tremaining: 139ms\n",
            "989:\tlearn: 0.0135988\ttotal: 12.5s\tremaining: 126ms\n",
            "990:\tlearn: 0.0135772\ttotal: 12.5s\tremaining: 114ms\n",
            "991:\tlearn: 0.0135515\ttotal: 12.6s\tremaining: 101ms\n",
            "992:\tlearn: 0.0135389\ttotal: 12.6s\tremaining: 88.7ms\n",
            "993:\tlearn: 0.0135196\ttotal: 12.6s\tremaining: 76.1ms\n",
            "994:\tlearn: 0.0134984\ttotal: 12.6s\tremaining: 63.5ms\n",
            "995:\tlearn: 0.0134687\ttotal: 12.7s\tremaining: 50.8ms\n",
            "996:\tlearn: 0.0134357\ttotal: 12.7s\tremaining: 38.1ms\n",
            "997:\tlearn: 0.0134161\ttotal: 12.7s\tremaining: 25.4ms\n",
            "998:\tlearn: 0.0133996\ttotal: 12.7s\tremaining: 12.7ms\n",
            "999:\tlearn: 0.0133737\ttotal: 12.7s\tremaining: 0us\n",
            "Learning rate set to 0.007862\n",
            "0:\tlearn: 0.6821949\ttotal: 46.8ms\tremaining: 46.7s\n",
            "1:\tlearn: 0.6720743\ttotal: 68.4ms\tremaining: 34.1s\n",
            "2:\tlearn: 0.6629153\ttotal: 90.6ms\tremaining: 30.1s\n",
            "3:\tlearn: 0.6528442\ttotal: 113ms\tremaining: 28.2s\n",
            "4:\tlearn: 0.6433598\ttotal: 136ms\tremaining: 27.1s\n",
            "5:\tlearn: 0.6347479\ttotal: 157ms\tremaining: 26.1s\n",
            "6:\tlearn: 0.6267702\ttotal: 180ms\tremaining: 25.5s\n",
            "7:\tlearn: 0.6187206\ttotal: 211ms\tremaining: 26.1s\n",
            "8:\tlearn: 0.6099720\ttotal: 235ms\tremaining: 25.9s\n",
            "9:\tlearn: 0.6009233\ttotal: 256ms\tremaining: 25.4s\n",
            "10:\tlearn: 0.5924931\ttotal: 278ms\tremaining: 25s\n",
            "11:\tlearn: 0.5832363\ttotal: 299ms\tremaining: 24.6s\n",
            "12:\tlearn: 0.5752474\ttotal: 320ms\tremaining: 24.3s\n",
            "13:\tlearn: 0.5667634\ttotal: 342ms\tremaining: 24.1s\n",
            "14:\tlearn: 0.5585322\ttotal: 367ms\tremaining: 24.1s\n",
            "15:\tlearn: 0.5512153\ttotal: 419ms\tremaining: 25.8s\n",
            "16:\tlearn: 0.5437267\ttotal: 480ms\tremaining: 27.7s\n",
            "17:\tlearn: 0.5362955\ttotal: 507ms\tremaining: 27.7s\n",
            "18:\tlearn: 0.5290878\ttotal: 538ms\tremaining: 27.8s\n",
            "19:\tlearn: 0.5216947\ttotal: 565ms\tremaining: 27.7s\n",
            "20:\tlearn: 0.5149331\ttotal: 588ms\tremaining: 27.4s\n",
            "21:\tlearn: 0.5075810\ttotal: 611ms\tremaining: 27.1s\n",
            "22:\tlearn: 0.5009626\ttotal: 642ms\tremaining: 27.3s\n",
            "23:\tlearn: 0.4937426\ttotal: 667ms\tremaining: 27.1s\n",
            "24:\tlearn: 0.4876409\ttotal: 689ms\tremaining: 26.9s\n",
            "25:\tlearn: 0.4817453\ttotal: 716ms\tremaining: 26.8s\n",
            "26:\tlearn: 0.4748490\ttotal: 745ms\tremaining: 26.8s\n",
            "27:\tlearn: 0.4680655\ttotal: 776ms\tremaining: 26.9s\n",
            "28:\tlearn: 0.4626685\ttotal: 822ms\tremaining: 27.5s\n",
            "29:\tlearn: 0.4577335\ttotal: 866ms\tremaining: 28s\n",
            "30:\tlearn: 0.4519594\ttotal: 893ms\tremaining: 27.9s\n",
            "31:\tlearn: 0.4457577\ttotal: 915ms\tremaining: 27.7s\n",
            "32:\tlearn: 0.4408284\ttotal: 939ms\tremaining: 27.5s\n",
            "33:\tlearn: 0.4353816\ttotal: 961ms\tremaining: 27.3s\n",
            "34:\tlearn: 0.4301406\ttotal: 983ms\tremaining: 27.1s\n",
            "35:\tlearn: 0.4244211\ttotal: 1s\tremaining: 26.9s\n",
            "36:\tlearn: 0.4190989\ttotal: 1.03s\tremaining: 26.7s\n",
            "37:\tlearn: 0.4135723\ttotal: 1.05s\tremaining: 26.6s\n",
            "38:\tlearn: 0.4083972\ttotal: 1.08s\tremaining: 26.6s\n",
            "39:\tlearn: 0.4032213\ttotal: 1.1s\tremaining: 26.5s\n",
            "40:\tlearn: 0.3981942\ttotal: 1.12s\tremaining: 26.3s\n",
            "41:\tlearn: 0.3933075\ttotal: 1.15s\tremaining: 26.2s\n",
            "42:\tlearn: 0.3889791\ttotal: 1.17s\tremaining: 26s\n",
            "43:\tlearn: 0.3846256\ttotal: 1.18s\tremaining: 25.7s\n",
            "44:\tlearn: 0.3795046\ttotal: 1.2s\tremaining: 25.4s\n",
            "45:\tlearn: 0.3752353\ttotal: 1.21s\tremaining: 25.1s\n",
            "46:\tlearn: 0.3708942\ttotal: 1.22s\tremaining: 24.8s\n",
            "47:\tlearn: 0.3662219\ttotal: 1.24s\tremaining: 24.5s\n",
            "48:\tlearn: 0.3620007\ttotal: 1.25s\tremaining: 24.2s\n",
            "49:\tlearn: 0.3584547\ttotal: 1.26s\tremaining: 24s\n",
            "50:\tlearn: 0.3543415\ttotal: 1.28s\tremaining: 23.8s\n",
            "51:\tlearn: 0.3500540\ttotal: 1.3s\tremaining: 23.6s\n",
            "52:\tlearn: 0.3461273\ttotal: 1.31s\tremaining: 23.4s\n",
            "53:\tlearn: 0.3425423\ttotal: 1.32s\tremaining: 23.2s\n",
            "54:\tlearn: 0.3383603\ttotal: 1.34s\tremaining: 23.1s\n",
            "55:\tlearn: 0.3346510\ttotal: 1.36s\tremaining: 22.9s\n",
            "56:\tlearn: 0.3309249\ttotal: 1.38s\tremaining: 22.8s\n",
            "57:\tlearn: 0.3272193\ttotal: 1.39s\tremaining: 22.6s\n",
            "58:\tlearn: 0.3235508\ttotal: 1.41s\tremaining: 22.5s\n",
            "59:\tlearn: 0.3200325\ttotal: 1.43s\tremaining: 22.4s\n",
            "60:\tlearn: 0.3169747\ttotal: 1.46s\tremaining: 22.4s\n",
            "61:\tlearn: 0.3142932\ttotal: 1.48s\tremaining: 22.4s\n",
            "62:\tlearn: 0.3109903\ttotal: 1.51s\tremaining: 22.4s\n",
            "63:\tlearn: 0.3079654\ttotal: 1.53s\tremaining: 22.4s\n",
            "64:\tlearn: 0.3047924\ttotal: 1.55s\tremaining: 22.4s\n",
            "65:\tlearn: 0.3015260\ttotal: 1.58s\tremaining: 22.3s\n",
            "66:\tlearn: 0.2986411\ttotal: 1.6s\tremaining: 22.3s\n",
            "67:\tlearn: 0.2954941\ttotal: 1.62s\tremaining: 22.2s\n",
            "68:\tlearn: 0.2923824\ttotal: 1.65s\tremaining: 22.2s\n",
            "69:\tlearn: 0.2896725\ttotal: 1.67s\tremaining: 22.1s\n",
            "70:\tlearn: 0.2870223\ttotal: 1.69s\tremaining: 22.1s\n",
            "71:\tlearn: 0.2839592\ttotal: 1.71s\tremaining: 22.1s\n",
            "72:\tlearn: 0.2813526\ttotal: 1.74s\tremaining: 22s\n",
            "73:\tlearn: 0.2791127\ttotal: 1.76s\tremaining: 22s\n",
            "74:\tlearn: 0.2763700\ttotal: 1.78s\tremaining: 22s\n",
            "75:\tlearn: 0.2744740\ttotal: 1.79s\tremaining: 21.8s\n",
            "76:\tlearn: 0.2719699\ttotal: 1.8s\tremaining: 21.6s\n",
            "77:\tlearn: 0.2696350\ttotal: 1.81s\tremaining: 21.4s\n",
            "78:\tlearn: 0.2674045\ttotal: 1.82s\tremaining: 21.3s\n",
            "79:\tlearn: 0.2651827\ttotal: 1.83s\tremaining: 21.1s\n",
            "80:\tlearn: 0.2629490\ttotal: 1.84s\tremaining: 20.9s\n",
            "81:\tlearn: 0.2606811\ttotal: 1.85s\tremaining: 20.8s\n",
            "82:\tlearn: 0.2580114\ttotal: 1.86s\tremaining: 20.6s\n",
            "83:\tlearn: 0.2560958\ttotal: 1.87s\tremaining: 20.4s\n",
            "84:\tlearn: 0.2538509\ttotal: 1.89s\tremaining: 20.3s\n",
            "85:\tlearn: 0.2518763\ttotal: 1.9s\tremaining: 20.2s\n",
            "86:\tlearn: 0.2495106\ttotal: 1.91s\tremaining: 20.1s\n",
            "87:\tlearn: 0.2470778\ttotal: 1.92s\tremaining: 19.9s\n",
            "88:\tlearn: 0.2447802\ttotal: 1.93s\tremaining: 19.8s\n",
            "89:\tlearn: 0.2426433\ttotal: 1.95s\tremaining: 19.7s\n",
            "90:\tlearn: 0.2403923\ttotal: 1.96s\tremaining: 19.6s\n",
            "91:\tlearn: 0.2381135\ttotal: 1.97s\tremaining: 19.4s\n",
            "92:\tlearn: 0.2359441\ttotal: 1.98s\tremaining: 19.3s\n",
            "93:\tlearn: 0.2340144\ttotal: 1.99s\tremaining: 19.2s\n",
            "94:\tlearn: 0.2324500\ttotal: 2s\tremaining: 19s\n",
            "95:\tlearn: 0.2307765\ttotal: 2.01s\tremaining: 18.9s\n",
            "96:\tlearn: 0.2289987\ttotal: 2.02s\tremaining: 18.8s\n",
            "97:\tlearn: 0.2270044\ttotal: 2.03s\tremaining: 18.7s\n",
            "98:\tlearn: 0.2251858\ttotal: 2.04s\tremaining: 18.6s\n",
            "99:\tlearn: 0.2235436\ttotal: 2.05s\tremaining: 18.4s\n",
            "100:\tlearn: 0.2219955\ttotal: 2.06s\tremaining: 18.3s\n",
            "101:\tlearn: 0.2204504\ttotal: 2.07s\tremaining: 18.2s\n",
            "102:\tlearn: 0.2184274\ttotal: 2.08s\tremaining: 18.1s\n",
            "103:\tlearn: 0.2169956\ttotal: 2.09s\tremaining: 18s\n",
            "104:\tlearn: 0.2151543\ttotal: 2.1s\tremaining: 17.9s\n",
            "105:\tlearn: 0.2134182\ttotal: 2.12s\tremaining: 17.9s\n",
            "106:\tlearn: 0.2122260\ttotal: 2.13s\tremaining: 17.8s\n",
            "107:\tlearn: 0.2105340\ttotal: 2.14s\tremaining: 17.7s\n",
            "108:\tlearn: 0.2089570\ttotal: 2.15s\tremaining: 17.6s\n",
            "109:\tlearn: 0.2073378\ttotal: 2.16s\tremaining: 17.5s\n",
            "110:\tlearn: 0.2055968\ttotal: 2.17s\tremaining: 17.4s\n",
            "111:\tlearn: 0.2041533\ttotal: 2.18s\tremaining: 17.3s\n",
            "112:\tlearn: 0.2028709\ttotal: 2.19s\tremaining: 17.2s\n",
            "113:\tlearn: 0.2013639\ttotal: 2.2s\tremaining: 17.1s\n",
            "114:\tlearn: 0.1997669\ttotal: 2.21s\tremaining: 17s\n",
            "115:\tlearn: 0.1981904\ttotal: 2.22s\tremaining: 16.9s\n",
            "116:\tlearn: 0.1969909\ttotal: 2.23s\tremaining: 16.8s\n",
            "117:\tlearn: 0.1957771\ttotal: 2.24s\tremaining: 16.8s\n",
            "118:\tlearn: 0.1945265\ttotal: 2.25s\tremaining: 16.7s\n",
            "119:\tlearn: 0.1933422\ttotal: 2.26s\tremaining: 16.6s\n",
            "120:\tlearn: 0.1920620\ttotal: 2.27s\tremaining: 16.5s\n",
            "121:\tlearn: 0.1906523\ttotal: 2.28s\tremaining: 16.4s\n",
            "122:\tlearn: 0.1896567\ttotal: 2.29s\tremaining: 16.4s\n",
            "123:\tlearn: 0.1885023\ttotal: 2.31s\tremaining: 16.3s\n",
            "124:\tlearn: 0.1871130\ttotal: 2.32s\tremaining: 16.2s\n",
            "125:\tlearn: 0.1859122\ttotal: 2.33s\tremaining: 16.2s\n",
            "126:\tlearn: 0.1846468\ttotal: 2.34s\tremaining: 16.1s\n",
            "127:\tlearn: 0.1832759\ttotal: 2.35s\tremaining: 16s\n",
            "128:\tlearn: 0.1820869\ttotal: 2.36s\tremaining: 16s\n",
            "129:\tlearn: 0.1807007\ttotal: 2.37s\tremaining: 15.9s\n",
            "130:\tlearn: 0.1793005\ttotal: 2.38s\tremaining: 15.8s\n",
            "131:\tlearn: 0.1779794\ttotal: 2.39s\tremaining: 15.7s\n",
            "132:\tlearn: 0.1765885\ttotal: 2.4s\tremaining: 15.7s\n",
            "133:\tlearn: 0.1754835\ttotal: 2.42s\tremaining: 15.6s\n",
            "134:\tlearn: 0.1746149\ttotal: 2.42s\tremaining: 15.5s\n",
            "135:\tlearn: 0.1735342\ttotal: 2.44s\tremaining: 15.5s\n",
            "136:\tlearn: 0.1721870\ttotal: 2.44s\tremaining: 15.4s\n",
            "137:\tlearn: 0.1711852\ttotal: 2.46s\tremaining: 15.3s\n",
            "138:\tlearn: 0.1701111\ttotal: 2.47s\tremaining: 15.3s\n",
            "139:\tlearn: 0.1691708\ttotal: 2.48s\tremaining: 15.2s\n",
            "140:\tlearn: 0.1683074\ttotal: 2.49s\tremaining: 15.2s\n",
            "141:\tlearn: 0.1674116\ttotal: 2.5s\tremaining: 15.1s\n",
            "142:\tlearn: 0.1662523\ttotal: 2.51s\tremaining: 15.1s\n",
            "143:\tlearn: 0.1653183\ttotal: 2.53s\tremaining: 15s\n",
            "144:\tlearn: 0.1644778\ttotal: 2.54s\tremaining: 15s\n",
            "145:\tlearn: 0.1636403\ttotal: 2.56s\tremaining: 14.9s\n",
            "146:\tlearn: 0.1627236\ttotal: 2.58s\tremaining: 14.9s\n",
            "147:\tlearn: 0.1618938\ttotal: 2.59s\tremaining: 14.9s\n",
            "148:\tlearn: 0.1610234\ttotal: 2.6s\tremaining: 14.8s\n",
            "149:\tlearn: 0.1602445\ttotal: 2.61s\tremaining: 14.8s\n",
            "150:\tlearn: 0.1593983\ttotal: 2.62s\tremaining: 14.7s\n",
            "151:\tlearn: 0.1588252\ttotal: 2.63s\tremaining: 14.7s\n",
            "152:\tlearn: 0.1581487\ttotal: 2.64s\tremaining: 14.6s\n",
            "153:\tlearn: 0.1573680\ttotal: 2.65s\tremaining: 14.5s\n",
            "154:\tlearn: 0.1563742\ttotal: 2.66s\tremaining: 14.5s\n",
            "155:\tlearn: 0.1554034\ttotal: 2.67s\tremaining: 14.4s\n",
            "156:\tlearn: 0.1546458\ttotal: 2.68s\tremaining: 14.4s\n",
            "157:\tlearn: 0.1536286\ttotal: 2.69s\tremaining: 14.3s\n",
            "158:\tlearn: 0.1528566\ttotal: 2.7s\tremaining: 14.3s\n",
            "159:\tlearn: 0.1519463\ttotal: 2.71s\tremaining: 14.2s\n",
            "160:\tlearn: 0.1510805\ttotal: 2.73s\tremaining: 14.2s\n",
            "161:\tlearn: 0.1502540\ttotal: 2.74s\tremaining: 14.2s\n",
            "162:\tlearn: 0.1494161\ttotal: 2.75s\tremaining: 14.1s\n",
            "163:\tlearn: 0.1486302\ttotal: 2.77s\tremaining: 14.1s\n",
            "164:\tlearn: 0.1477851\ttotal: 2.77s\tremaining: 14s\n",
            "165:\tlearn: 0.1471907\ttotal: 2.79s\tremaining: 14s\n",
            "166:\tlearn: 0.1464129\ttotal: 2.8s\tremaining: 13.9s\n",
            "167:\tlearn: 0.1457459\ttotal: 2.81s\tremaining: 13.9s\n",
            "168:\tlearn: 0.1450090\ttotal: 2.82s\tremaining: 13.9s\n",
            "169:\tlearn: 0.1442144\ttotal: 2.83s\tremaining: 13.8s\n",
            "170:\tlearn: 0.1434684\ttotal: 2.85s\tremaining: 13.8s\n",
            "171:\tlearn: 0.1426564\ttotal: 2.86s\tremaining: 13.7s\n",
            "172:\tlearn: 0.1419770\ttotal: 2.87s\tremaining: 13.7s\n",
            "173:\tlearn: 0.1412692\ttotal: 2.88s\tremaining: 13.7s\n",
            "174:\tlearn: 0.1405979\ttotal: 2.89s\tremaining: 13.6s\n",
            "175:\tlearn: 0.1398636\ttotal: 2.9s\tremaining: 13.6s\n",
            "176:\tlearn: 0.1393135\ttotal: 2.91s\tremaining: 13.5s\n",
            "177:\tlearn: 0.1386372\ttotal: 2.92s\tremaining: 13.5s\n",
            "178:\tlearn: 0.1379187\ttotal: 2.94s\tremaining: 13.5s\n",
            "179:\tlearn: 0.1371757\ttotal: 2.95s\tremaining: 13.4s\n",
            "180:\tlearn: 0.1365395\ttotal: 2.96s\tremaining: 13.4s\n",
            "181:\tlearn: 0.1357582\ttotal: 2.97s\tremaining: 13.3s\n",
            "182:\tlearn: 0.1351430\ttotal: 2.98s\tremaining: 13.3s\n",
            "183:\tlearn: 0.1345546\ttotal: 2.99s\tremaining: 13.3s\n",
            "184:\tlearn: 0.1339562\ttotal: 3s\tremaining: 13.2s\n",
            "185:\tlearn: 0.1334058\ttotal: 3.01s\tremaining: 13.2s\n",
            "186:\tlearn: 0.1328768\ttotal: 3.02s\tremaining: 13.1s\n",
            "187:\tlearn: 0.1322650\ttotal: 3.03s\tremaining: 13.1s\n",
            "188:\tlearn: 0.1317082\ttotal: 3.04s\tremaining: 13s\n",
            "189:\tlearn: 0.1311348\ttotal: 3.05s\tremaining: 13s\n",
            "190:\tlearn: 0.1304415\ttotal: 3.06s\tremaining: 13s\n",
            "191:\tlearn: 0.1296726\ttotal: 3.07s\tremaining: 12.9s\n",
            "192:\tlearn: 0.1291757\ttotal: 3.08s\tremaining: 12.9s\n",
            "193:\tlearn: 0.1285665\ttotal: 3.09s\tremaining: 12.8s\n",
            "194:\tlearn: 0.1280394\ttotal: 3.1s\tremaining: 12.8s\n",
            "195:\tlearn: 0.1275003\ttotal: 3.11s\tremaining: 12.8s\n",
            "196:\tlearn: 0.1268050\ttotal: 3.12s\tremaining: 12.7s\n",
            "197:\tlearn: 0.1262039\ttotal: 3.14s\tremaining: 12.7s\n",
            "198:\tlearn: 0.1257435\ttotal: 3.15s\tremaining: 12.7s\n",
            "199:\tlearn: 0.1252484\ttotal: 3.16s\tremaining: 12.6s\n",
            "200:\tlearn: 0.1246210\ttotal: 3.17s\tremaining: 12.6s\n",
            "201:\tlearn: 0.1240751\ttotal: 3.18s\tremaining: 12.6s\n",
            "202:\tlearn: 0.1235388\ttotal: 3.19s\tremaining: 12.5s\n",
            "203:\tlearn: 0.1230194\ttotal: 3.2s\tremaining: 12.5s\n",
            "204:\tlearn: 0.1225129\ttotal: 3.21s\tremaining: 12.5s\n",
            "205:\tlearn: 0.1219683\ttotal: 3.22s\tremaining: 12.4s\n",
            "206:\tlearn: 0.1214752\ttotal: 3.23s\tremaining: 12.4s\n",
            "207:\tlearn: 0.1209548\ttotal: 3.25s\tremaining: 12.4s\n",
            "208:\tlearn: 0.1205017\ttotal: 3.25s\tremaining: 12.3s\n",
            "209:\tlearn: 0.1199660\ttotal: 3.27s\tremaining: 12.3s\n",
            "210:\tlearn: 0.1195155\ttotal: 3.27s\tremaining: 12.2s\n",
            "211:\tlearn: 0.1189945\ttotal: 3.29s\tremaining: 12.2s\n",
            "212:\tlearn: 0.1186051\ttotal: 3.3s\tremaining: 12.2s\n",
            "213:\tlearn: 0.1181919\ttotal: 3.31s\tremaining: 12.1s\n",
            "214:\tlearn: 0.1177557\ttotal: 3.32s\tremaining: 12.1s\n",
            "215:\tlearn: 0.1172022\ttotal: 3.34s\tremaining: 12.1s\n",
            "216:\tlearn: 0.1168100\ttotal: 3.35s\tremaining: 12.1s\n",
            "217:\tlearn: 0.1162345\ttotal: 3.36s\tremaining: 12.1s\n",
            "218:\tlearn: 0.1158027\ttotal: 3.37s\tremaining: 12s\n",
            "219:\tlearn: 0.1153072\ttotal: 3.38s\tremaining: 12s\n",
            "220:\tlearn: 0.1149095\ttotal: 3.39s\tremaining: 12s\n",
            "221:\tlearn: 0.1143921\ttotal: 3.4s\tremaining: 11.9s\n",
            "222:\tlearn: 0.1140351\ttotal: 3.41s\tremaining: 11.9s\n",
            "223:\tlearn: 0.1135791\ttotal: 3.42s\tremaining: 11.9s\n",
            "224:\tlearn: 0.1131437\ttotal: 3.43s\tremaining: 11.8s\n",
            "225:\tlearn: 0.1127848\ttotal: 3.44s\tremaining: 11.8s\n",
            "226:\tlearn: 0.1123346\ttotal: 3.45s\tremaining: 11.8s\n",
            "227:\tlearn: 0.1119658\ttotal: 3.46s\tremaining: 11.7s\n",
            "228:\tlearn: 0.1114200\ttotal: 3.47s\tremaining: 11.7s\n",
            "229:\tlearn: 0.1110449\ttotal: 3.48s\tremaining: 11.7s\n",
            "230:\tlearn: 0.1106741\ttotal: 3.5s\tremaining: 11.6s\n",
            "231:\tlearn: 0.1102824\ttotal: 3.5s\tremaining: 11.6s\n",
            "232:\tlearn: 0.1097405\ttotal: 3.52s\tremaining: 11.6s\n",
            "233:\tlearn: 0.1092789\ttotal: 3.52s\tremaining: 11.5s\n",
            "234:\tlearn: 0.1089384\ttotal: 3.54s\tremaining: 11.5s\n",
            "235:\tlearn: 0.1084777\ttotal: 3.56s\tremaining: 11.5s\n",
            "236:\tlearn: 0.1081492\ttotal: 3.58s\tremaining: 11.5s\n",
            "237:\tlearn: 0.1077671\ttotal: 3.59s\tremaining: 11.5s\n",
            "238:\tlearn: 0.1072939\ttotal: 3.6s\tremaining: 11.5s\n",
            "239:\tlearn: 0.1068850\ttotal: 3.61s\tremaining: 11.4s\n",
            "240:\tlearn: 0.1064557\ttotal: 3.62s\tremaining: 11.4s\n",
            "241:\tlearn: 0.1060677\ttotal: 3.63s\tremaining: 11.4s\n",
            "242:\tlearn: 0.1057222\ttotal: 3.64s\tremaining: 11.3s\n",
            "243:\tlearn: 0.1054652\ttotal: 3.65s\tremaining: 11.3s\n",
            "244:\tlearn: 0.1050492\ttotal: 3.67s\tremaining: 11.3s\n",
            "245:\tlearn: 0.1046335\ttotal: 3.68s\tremaining: 11.3s\n",
            "246:\tlearn: 0.1041255\ttotal: 3.69s\tremaining: 11.2s\n",
            "247:\tlearn: 0.1036622\ttotal: 3.7s\tremaining: 11.2s\n",
            "248:\tlearn: 0.1032626\ttotal: 3.71s\tremaining: 11.2s\n",
            "249:\tlearn: 0.1030112\ttotal: 3.73s\tremaining: 11.2s\n",
            "250:\tlearn: 0.1026068\ttotal: 3.73s\tremaining: 11.1s\n",
            "251:\tlearn: 0.1022885\ttotal: 3.75s\tremaining: 11.1s\n",
            "252:\tlearn: 0.1019061\ttotal: 3.76s\tremaining: 11.1s\n",
            "253:\tlearn: 0.1016357\ttotal: 3.77s\tremaining: 11.1s\n",
            "254:\tlearn: 0.1011659\ttotal: 3.78s\tremaining: 11.1s\n",
            "255:\tlearn: 0.1008291\ttotal: 3.79s\tremaining: 11s\n",
            "256:\tlearn: 0.1004470\ttotal: 3.81s\tremaining: 11s\n",
            "257:\tlearn: 0.1001051\ttotal: 3.81s\tremaining: 11s\n",
            "258:\tlearn: 0.0997424\ttotal: 3.83s\tremaining: 10.9s\n",
            "259:\tlearn: 0.0994245\ttotal: 3.84s\tremaining: 10.9s\n",
            "260:\tlearn: 0.0990974\ttotal: 3.85s\tremaining: 10.9s\n",
            "261:\tlearn: 0.0986968\ttotal: 3.86s\tremaining: 10.9s\n",
            "262:\tlearn: 0.0984391\ttotal: 3.87s\tremaining: 10.8s\n",
            "263:\tlearn: 0.0980903\ttotal: 3.88s\tremaining: 10.8s\n",
            "264:\tlearn: 0.0977083\ttotal: 3.89s\tremaining: 10.8s\n",
            "265:\tlearn: 0.0974349\ttotal: 3.9s\tremaining: 10.8s\n",
            "266:\tlearn: 0.0971124\ttotal: 3.91s\tremaining: 10.7s\n",
            "267:\tlearn: 0.0967744\ttotal: 3.92s\tremaining: 10.7s\n",
            "268:\tlearn: 0.0964359\ttotal: 3.93s\tremaining: 10.7s\n",
            "269:\tlearn: 0.0962000\ttotal: 3.94s\tremaining: 10.7s\n",
            "270:\tlearn: 0.0959750\ttotal: 3.95s\tremaining: 10.6s\n",
            "271:\tlearn: 0.0956622\ttotal: 3.97s\tremaining: 10.6s\n",
            "272:\tlearn: 0.0953345\ttotal: 3.98s\tremaining: 10.6s\n",
            "273:\tlearn: 0.0949691\ttotal: 3.99s\tremaining: 10.6s\n",
            "274:\tlearn: 0.0946913\ttotal: 4s\tremaining: 10.5s\n",
            "275:\tlearn: 0.0944426\ttotal: 4.01s\tremaining: 10.5s\n",
            "276:\tlearn: 0.0941047\ttotal: 4.02s\tremaining: 10.5s\n",
            "277:\tlearn: 0.0937846\ttotal: 4.03s\tremaining: 10.5s\n",
            "278:\tlearn: 0.0934851\ttotal: 4.04s\tremaining: 10.4s\n",
            "279:\tlearn: 0.0931946\ttotal: 4.05s\tremaining: 10.4s\n",
            "280:\tlearn: 0.0927274\ttotal: 4.06s\tremaining: 10.4s\n",
            "281:\tlearn: 0.0924142\ttotal: 4.07s\tremaining: 10.4s\n",
            "282:\tlearn: 0.0921048\ttotal: 4.08s\tremaining: 10.3s\n",
            "283:\tlearn: 0.0918168\ttotal: 4.09s\tremaining: 10.3s\n",
            "284:\tlearn: 0.0915949\ttotal: 4.1s\tremaining: 10.3s\n",
            "285:\tlearn: 0.0913811\ttotal: 4.11s\tremaining: 10.3s\n",
            "286:\tlearn: 0.0911891\ttotal: 4.12s\tremaining: 10.2s\n",
            "287:\tlearn: 0.0909165\ttotal: 4.13s\tremaining: 10.2s\n",
            "288:\tlearn: 0.0905626\ttotal: 4.14s\tremaining: 10.2s\n",
            "289:\tlearn: 0.0902883\ttotal: 4.16s\tremaining: 10.2s\n",
            "290:\tlearn: 0.0899667\ttotal: 4.17s\tremaining: 10.2s\n",
            "291:\tlearn: 0.0896811\ttotal: 4.18s\tremaining: 10.1s\n",
            "292:\tlearn: 0.0893521\ttotal: 4.19s\tremaining: 10.1s\n",
            "293:\tlearn: 0.0891360\ttotal: 4.2s\tremaining: 10.1s\n",
            "294:\tlearn: 0.0889193\ttotal: 4.21s\tremaining: 10.1s\n",
            "295:\tlearn: 0.0886058\ttotal: 4.22s\tremaining: 10s\n",
            "296:\tlearn: 0.0883655\ttotal: 4.23s\tremaining: 10s\n",
            "297:\tlearn: 0.0880546\ttotal: 4.24s\tremaining: 10s\n",
            "298:\tlearn: 0.0877808\ttotal: 4.25s\tremaining: 9.97s\n",
            "299:\tlearn: 0.0875484\ttotal: 4.26s\tremaining: 9.95s\n",
            "300:\tlearn: 0.0872095\ttotal: 4.28s\tremaining: 9.93s\n",
            "301:\tlearn: 0.0868948\ttotal: 4.29s\tremaining: 9.9s\n",
            "302:\tlearn: 0.0866790\ttotal: 4.29s\tremaining: 9.88s\n",
            "303:\tlearn: 0.0864411\ttotal: 4.31s\tremaining: 9.86s\n",
            "304:\tlearn: 0.0862355\ttotal: 4.32s\tremaining: 9.84s\n",
            "305:\tlearn: 0.0860499\ttotal: 4.33s\tremaining: 9.82s\n",
            "306:\tlearn: 0.0858224\ttotal: 4.34s\tremaining: 9.79s\n",
            "307:\tlearn: 0.0855802\ttotal: 4.35s\tremaining: 9.77s\n",
            "308:\tlearn: 0.0852364\ttotal: 4.37s\tremaining: 9.76s\n",
            "309:\tlearn: 0.0850077\ttotal: 4.38s\tremaining: 9.75s\n",
            "310:\tlearn: 0.0847008\ttotal: 4.39s\tremaining: 9.73s\n",
            "311:\tlearn: 0.0844171\ttotal: 4.4s\tremaining: 9.71s\n",
            "312:\tlearn: 0.0839933\ttotal: 4.41s\tremaining: 9.68s\n",
            "313:\tlearn: 0.0838104\ttotal: 4.42s\tremaining: 9.66s\n",
            "314:\tlearn: 0.0834764\ttotal: 4.43s\tremaining: 9.64s\n",
            "315:\tlearn: 0.0831453\ttotal: 4.44s\tremaining: 9.62s\n",
            "316:\tlearn: 0.0828361\ttotal: 4.45s\tremaining: 9.59s\n",
            "317:\tlearn: 0.0825106\ttotal: 4.46s\tremaining: 9.57s\n",
            "318:\tlearn: 0.0823078\ttotal: 4.47s\tremaining: 9.55s\n",
            "319:\tlearn: 0.0820146\ttotal: 4.48s\tremaining: 9.53s\n",
            "320:\tlearn: 0.0817866\ttotal: 4.49s\tremaining: 9.51s\n",
            "321:\tlearn: 0.0816041\ttotal: 4.5s\tremaining: 9.48s\n",
            "322:\tlearn: 0.0813942\ttotal: 4.51s\tremaining: 9.46s\n",
            "323:\tlearn: 0.0811487\ttotal: 4.53s\tremaining: 9.44s\n",
            "324:\tlearn: 0.0808824\ttotal: 4.54s\tremaining: 9.42s\n",
            "325:\tlearn: 0.0806630\ttotal: 4.54s\tremaining: 9.4s\n",
            "326:\tlearn: 0.0804376\ttotal: 4.56s\tremaining: 9.38s\n",
            "327:\tlearn: 0.0801424\ttotal: 4.58s\tremaining: 9.38s\n",
            "328:\tlearn: 0.0798371\ttotal: 4.6s\tremaining: 9.38s\n",
            "329:\tlearn: 0.0796119\ttotal: 4.61s\tremaining: 9.36s\n",
            "330:\tlearn: 0.0793685\ttotal: 4.62s\tremaining: 9.34s\n",
            "331:\tlearn: 0.0791148\ttotal: 4.63s\tremaining: 9.32s\n",
            "332:\tlearn: 0.0788740\ttotal: 4.64s\tremaining: 9.3s\n",
            "333:\tlearn: 0.0786027\ttotal: 4.65s\tremaining: 9.28s\n",
            "334:\tlearn: 0.0783805\ttotal: 4.66s\tremaining: 9.25s\n",
            "335:\tlearn: 0.0781118\ttotal: 4.67s\tremaining: 9.23s\n",
            "336:\tlearn: 0.0779008\ttotal: 4.69s\tremaining: 9.22s\n",
            "337:\tlearn: 0.0777314\ttotal: 4.7s\tremaining: 9.21s\n",
            "338:\tlearn: 0.0775216\ttotal: 4.71s\tremaining: 9.19s\n",
            "339:\tlearn: 0.0774188\ttotal: 4.72s\tremaining: 9.17s\n",
            "340:\tlearn: 0.0771807\ttotal: 4.73s\tremaining: 9.14s\n",
            "341:\tlearn: 0.0768724\ttotal: 4.74s\tremaining: 9.12s\n",
            "342:\tlearn: 0.0766920\ttotal: 4.75s\tremaining: 9.1s\n",
            "343:\tlearn: 0.0764840\ttotal: 4.76s\tremaining: 9.08s\n",
            "344:\tlearn: 0.0763246\ttotal: 4.77s\tremaining: 9.06s\n",
            "345:\tlearn: 0.0760715\ttotal: 4.79s\tremaining: 9.05s\n",
            "346:\tlearn: 0.0758948\ttotal: 4.8s\tremaining: 9.03s\n",
            "347:\tlearn: 0.0757204\ttotal: 4.81s\tremaining: 9.01s\n",
            "348:\tlearn: 0.0755109\ttotal: 4.82s\tremaining: 8.99s\n",
            "349:\tlearn: 0.0752931\ttotal: 4.83s\tremaining: 8.97s\n",
            "350:\tlearn: 0.0751522\ttotal: 4.84s\tremaining: 8.95s\n",
            "351:\tlearn: 0.0749414\ttotal: 4.85s\tremaining: 8.93s\n",
            "352:\tlearn: 0.0747468\ttotal: 4.86s\tremaining: 8.91s\n",
            "353:\tlearn: 0.0745984\ttotal: 4.87s\tremaining: 8.89s\n",
            "354:\tlearn: 0.0744444\ttotal: 4.88s\tremaining: 8.87s\n",
            "355:\tlearn: 0.0742571\ttotal: 4.89s\tremaining: 8.85s\n",
            "356:\tlearn: 0.0740693\ttotal: 4.91s\tremaining: 8.83s\n",
            "357:\tlearn: 0.0738990\ttotal: 4.92s\tremaining: 8.81s\n",
            "358:\tlearn: 0.0737153\ttotal: 4.93s\tremaining: 8.8s\n",
            "359:\tlearn: 0.0735043\ttotal: 4.94s\tremaining: 8.78s\n",
            "360:\tlearn: 0.0733275\ttotal: 4.95s\tremaining: 8.76s\n",
            "361:\tlearn: 0.0731473\ttotal: 4.96s\tremaining: 8.74s\n",
            "362:\tlearn: 0.0730245\ttotal: 4.97s\tremaining: 8.72s\n",
            "363:\tlearn: 0.0728155\ttotal: 4.98s\tremaining: 8.7s\n",
            "364:\tlearn: 0.0726435\ttotal: 4.99s\tremaining: 8.68s\n",
            "365:\tlearn: 0.0724027\ttotal: 5.01s\tremaining: 8.68s\n",
            "366:\tlearn: 0.0721571\ttotal: 5.02s\tremaining: 8.65s\n",
            "367:\tlearn: 0.0719229\ttotal: 5.03s\tremaining: 8.64s\n",
            "368:\tlearn: 0.0717224\ttotal: 5.04s\tremaining: 8.62s\n",
            "369:\tlearn: 0.0715758\ttotal: 5.05s\tremaining: 8.6s\n",
            "370:\tlearn: 0.0713697\ttotal: 5.06s\tremaining: 8.58s\n",
            "371:\tlearn: 0.0711905\ttotal: 5.07s\tremaining: 8.56s\n",
            "372:\tlearn: 0.0710549\ttotal: 5.08s\tremaining: 8.54s\n",
            "373:\tlearn: 0.0709114\ttotal: 5.09s\tremaining: 8.52s\n",
            "374:\tlearn: 0.0707003\ttotal: 5.1s\tremaining: 8.5s\n",
            "375:\tlearn: 0.0705360\ttotal: 5.11s\tremaining: 8.48s\n",
            "376:\tlearn: 0.0703741\ttotal: 5.12s\tremaining: 8.46s\n",
            "377:\tlearn: 0.0702076\ttotal: 5.13s\tremaining: 8.45s\n",
            "378:\tlearn: 0.0700244\ttotal: 5.14s\tremaining: 8.43s\n",
            "379:\tlearn: 0.0698792\ttotal: 5.15s\tremaining: 8.41s\n",
            "380:\tlearn: 0.0696743\ttotal: 5.16s\tremaining: 8.39s\n",
            "381:\tlearn: 0.0695029\ttotal: 5.17s\tremaining: 8.37s\n",
            "382:\tlearn: 0.0693574\ttotal: 5.18s\tremaining: 8.35s\n",
            "383:\tlearn: 0.0691358\ttotal: 5.2s\tremaining: 8.34s\n",
            "384:\tlearn: 0.0689593\ttotal: 5.21s\tremaining: 8.33s\n",
            "385:\tlearn: 0.0687124\ttotal: 5.22s\tremaining: 8.31s\n",
            "386:\tlearn: 0.0685270\ttotal: 5.24s\tremaining: 8.29s\n",
            "387:\tlearn: 0.0683433\ttotal: 5.25s\tremaining: 8.28s\n",
            "388:\tlearn: 0.0681578\ttotal: 5.26s\tremaining: 8.26s\n",
            "389:\tlearn: 0.0680320\ttotal: 5.27s\tremaining: 8.24s\n",
            "390:\tlearn: 0.0678575\ttotal: 5.28s\tremaining: 8.22s\n",
            "391:\tlearn: 0.0677042\ttotal: 5.29s\tremaining: 8.2s\n",
            "392:\tlearn: 0.0675733\ttotal: 5.3s\tremaining: 8.18s\n",
            "393:\tlearn: 0.0674793\ttotal: 5.31s\tremaining: 8.16s\n",
            "394:\tlearn: 0.0672519\ttotal: 5.32s\tremaining: 8.15s\n",
            "395:\tlearn: 0.0670853\ttotal: 5.33s\tremaining: 8.13s\n",
            "396:\tlearn: 0.0669811\ttotal: 5.34s\tremaining: 8.11s\n",
            "397:\tlearn: 0.0668152\ttotal: 5.35s\tremaining: 8.09s\n",
            "398:\tlearn: 0.0666684\ttotal: 5.36s\tremaining: 8.07s\n",
            "399:\tlearn: 0.0664639\ttotal: 5.37s\tremaining: 8.05s\n",
            "400:\tlearn: 0.0662840\ttotal: 5.38s\tremaining: 8.04s\n",
            "401:\tlearn: 0.0660482\ttotal: 5.39s\tremaining: 8.02s\n",
            "402:\tlearn: 0.0658553\ttotal: 5.4s\tremaining: 8s\n",
            "403:\tlearn: 0.0656979\ttotal: 5.42s\tremaining: 7.99s\n",
            "404:\tlearn: 0.0655507\ttotal: 5.43s\tremaining: 7.97s\n",
            "405:\tlearn: 0.0654472\ttotal: 5.44s\tremaining: 7.96s\n",
            "406:\tlearn: 0.0652903\ttotal: 5.45s\tremaining: 7.94s\n",
            "407:\tlearn: 0.0650653\ttotal: 5.46s\tremaining: 7.92s\n",
            "408:\tlearn: 0.0648764\ttotal: 5.47s\tremaining: 7.9s\n",
            "409:\tlearn: 0.0647581\ttotal: 5.48s\tremaining: 7.89s\n",
            "410:\tlearn: 0.0645646\ttotal: 5.49s\tremaining: 7.87s\n",
            "411:\tlearn: 0.0643996\ttotal: 5.5s\tremaining: 7.85s\n",
            "412:\tlearn: 0.0642421\ttotal: 5.51s\tremaining: 7.83s\n",
            "413:\tlearn: 0.0640705\ttotal: 5.52s\tremaining: 7.82s\n",
            "414:\tlearn: 0.0639156\ttotal: 5.53s\tremaining: 7.8s\n",
            "415:\tlearn: 0.0637683\ttotal: 5.54s\tremaining: 7.78s\n",
            "416:\tlearn: 0.0636267\ttotal: 5.55s\tremaining: 7.76s\n",
            "417:\tlearn: 0.0634292\ttotal: 5.56s\tremaining: 7.74s\n",
            "418:\tlearn: 0.0631895\ttotal: 5.57s\tremaining: 7.73s\n",
            "419:\tlearn: 0.0630173\ttotal: 5.59s\tremaining: 7.72s\n",
            "420:\tlearn: 0.0628960\ttotal: 5.61s\tremaining: 7.72s\n",
            "421:\tlearn: 0.0627249\ttotal: 5.63s\tremaining: 7.71s\n",
            "422:\tlearn: 0.0626040\ttotal: 5.63s\tremaining: 7.69s\n",
            "423:\tlearn: 0.0623962\ttotal: 5.64s\tremaining: 7.67s\n",
            "424:\tlearn: 0.0623032\ttotal: 5.66s\tremaining: 7.66s\n",
            "425:\tlearn: 0.0621844\ttotal: 5.67s\tremaining: 7.65s\n",
            "426:\tlearn: 0.0620306\ttotal: 5.68s\tremaining: 7.63s\n",
            "427:\tlearn: 0.0618086\ttotal: 5.7s\tremaining: 7.61s\n",
            "428:\tlearn: 0.0616936\ttotal: 5.71s\tremaining: 7.59s\n",
            "429:\tlearn: 0.0615428\ttotal: 5.72s\tremaining: 7.58s\n",
            "430:\tlearn: 0.0614919\ttotal: 5.73s\tremaining: 7.56s\n",
            "431:\tlearn: 0.0613621\ttotal: 5.74s\tremaining: 7.54s\n",
            "432:\tlearn: 0.0611703\ttotal: 5.75s\tremaining: 7.53s\n",
            "433:\tlearn: 0.0610444\ttotal: 5.76s\tremaining: 7.51s\n",
            "434:\tlearn: 0.0608846\ttotal: 5.77s\tremaining: 7.49s\n",
            "435:\tlearn: 0.0607541\ttotal: 5.78s\tremaining: 7.47s\n",
            "436:\tlearn: 0.0606292\ttotal: 5.79s\tremaining: 7.46s\n",
            "437:\tlearn: 0.0604729\ttotal: 5.8s\tremaining: 7.44s\n",
            "438:\tlearn: 0.0603050\ttotal: 5.81s\tremaining: 7.42s\n",
            "439:\tlearn: 0.0601713\ttotal: 5.83s\tremaining: 7.42s\n",
            "440:\tlearn: 0.0600590\ttotal: 5.84s\tremaining: 7.4s\n",
            "441:\tlearn: 0.0599255\ttotal: 5.85s\tremaining: 7.38s\n",
            "442:\tlearn: 0.0597927\ttotal: 5.86s\tremaining: 7.37s\n",
            "443:\tlearn: 0.0597128\ttotal: 5.87s\tremaining: 7.35s\n",
            "444:\tlearn: 0.0595804\ttotal: 5.88s\tremaining: 7.33s\n",
            "445:\tlearn: 0.0594127\ttotal: 5.89s\tremaining: 7.32s\n",
            "446:\tlearn: 0.0592275\ttotal: 5.9s\tremaining: 7.3s\n",
            "447:\tlearn: 0.0590417\ttotal: 5.91s\tremaining: 7.28s\n",
            "448:\tlearn: 0.0588647\ttotal: 5.92s\tremaining: 7.27s\n",
            "449:\tlearn: 0.0586727\ttotal: 5.93s\tremaining: 7.25s\n",
            "450:\tlearn: 0.0585796\ttotal: 5.94s\tremaining: 7.23s\n",
            "451:\tlearn: 0.0584013\ttotal: 5.96s\tremaining: 7.23s\n",
            "452:\tlearn: 0.0582979\ttotal: 5.97s\tremaining: 7.21s\n",
            "453:\tlearn: 0.0582004\ttotal: 5.98s\tremaining: 7.2s\n",
            "454:\tlearn: 0.0580713\ttotal: 5.99s\tremaining: 7.18s\n",
            "455:\tlearn: 0.0579029\ttotal: 6s\tremaining: 7.16s\n",
            "456:\tlearn: 0.0578228\ttotal: 6.01s\tremaining: 7.14s\n",
            "457:\tlearn: 0.0577128\ttotal: 6.02s\tremaining: 7.13s\n",
            "458:\tlearn: 0.0575912\ttotal: 6.04s\tremaining: 7.12s\n",
            "459:\tlearn: 0.0574690\ttotal: 6.05s\tremaining: 7.1s\n",
            "460:\tlearn: 0.0572756\ttotal: 6.06s\tremaining: 7.09s\n",
            "461:\tlearn: 0.0571668\ttotal: 6.07s\tremaining: 7.07s\n",
            "462:\tlearn: 0.0570041\ttotal: 6.08s\tremaining: 7.05s\n",
            "463:\tlearn: 0.0567982\ttotal: 6.09s\tremaining: 7.04s\n",
            "464:\tlearn: 0.0567137\ttotal: 6.1s\tremaining: 7.02s\n",
            "465:\tlearn: 0.0565515\ttotal: 6.12s\tremaining: 7.01s\n",
            "466:\tlearn: 0.0564382\ttotal: 6.13s\tremaining: 6.99s\n",
            "467:\tlearn: 0.0563240\ttotal: 6.14s\tremaining: 6.98s\n",
            "468:\tlearn: 0.0561956\ttotal: 6.15s\tremaining: 6.96s\n",
            "469:\tlearn: 0.0560276\ttotal: 6.16s\tremaining: 6.94s\n",
            "470:\tlearn: 0.0559051\ttotal: 6.17s\tremaining: 6.93s\n",
            "471:\tlearn: 0.0557775\ttotal: 6.18s\tremaining: 6.91s\n",
            "472:\tlearn: 0.0556962\ttotal: 6.19s\tremaining: 6.89s\n",
            "473:\tlearn: 0.0556229\ttotal: 6.2s\tremaining: 6.88s\n",
            "474:\tlearn: 0.0554669\ttotal: 6.21s\tremaining: 6.86s\n",
            "475:\tlearn: 0.0553241\ttotal: 6.22s\tremaining: 6.85s\n",
            "476:\tlearn: 0.0552070\ttotal: 6.23s\tremaining: 6.83s\n",
            "477:\tlearn: 0.0550585\ttotal: 6.24s\tremaining: 6.82s\n",
            "478:\tlearn: 0.0549323\ttotal: 6.26s\tremaining: 6.8s\n",
            "479:\tlearn: 0.0547404\ttotal: 6.27s\tremaining: 6.79s\n",
            "480:\tlearn: 0.0546418\ttotal: 6.28s\tremaining: 6.77s\n",
            "481:\tlearn: 0.0545391\ttotal: 6.29s\tremaining: 6.76s\n",
            "482:\tlearn: 0.0544106\ttotal: 6.3s\tremaining: 6.74s\n",
            "483:\tlearn: 0.0543074\ttotal: 6.31s\tremaining: 6.73s\n",
            "484:\tlearn: 0.0542392\ttotal: 6.32s\tremaining: 6.71s\n",
            "485:\tlearn: 0.0540226\ttotal: 6.33s\tremaining: 6.7s\n",
            "486:\tlearn: 0.0538827\ttotal: 6.34s\tremaining: 6.68s\n",
            "487:\tlearn: 0.0537634\ttotal: 6.35s\tremaining: 6.66s\n",
            "488:\tlearn: 0.0536371\ttotal: 6.36s\tremaining: 6.65s\n",
            "489:\tlearn: 0.0535342\ttotal: 6.37s\tremaining: 6.63s\n",
            "490:\tlearn: 0.0534105\ttotal: 6.38s\tremaining: 6.62s\n",
            "491:\tlearn: 0.0532955\ttotal: 6.39s\tremaining: 6.6s\n",
            "492:\tlearn: 0.0531696\ttotal: 6.4s\tremaining: 6.58s\n",
            "493:\tlearn: 0.0530702\ttotal: 6.41s\tremaining: 6.57s\n",
            "494:\tlearn: 0.0529707\ttotal: 6.42s\tremaining: 6.55s\n",
            "495:\tlearn: 0.0528751\ttotal: 6.43s\tremaining: 6.54s\n",
            "496:\tlearn: 0.0527899\ttotal: 6.45s\tremaining: 6.53s\n",
            "497:\tlearn: 0.0526958\ttotal: 6.46s\tremaining: 6.52s\n",
            "498:\tlearn: 0.0525474\ttotal: 6.47s\tremaining: 6.5s\n",
            "499:\tlearn: 0.0524071\ttotal: 6.49s\tremaining: 6.49s\n",
            "500:\tlearn: 0.0523157\ttotal: 6.5s\tremaining: 6.47s\n",
            "501:\tlearn: 0.0521573\ttotal: 6.51s\tremaining: 6.45s\n",
            "502:\tlearn: 0.0520307\ttotal: 6.52s\tremaining: 6.44s\n",
            "503:\tlearn: 0.0519578\ttotal: 6.53s\tremaining: 6.42s\n",
            "504:\tlearn: 0.0518734\ttotal: 6.54s\tremaining: 6.41s\n",
            "505:\tlearn: 0.0517692\ttotal: 6.55s\tremaining: 6.39s\n",
            "506:\tlearn: 0.0516119\ttotal: 6.56s\tremaining: 6.38s\n",
            "507:\tlearn: 0.0514754\ttotal: 6.57s\tremaining: 6.36s\n",
            "508:\tlearn: 0.0513786\ttotal: 6.58s\tremaining: 6.34s\n",
            "509:\tlearn: 0.0512513\ttotal: 6.59s\tremaining: 6.33s\n",
            "510:\tlearn: 0.0511510\ttotal: 6.61s\tremaining: 6.33s\n",
            "511:\tlearn: 0.0510127\ttotal: 6.62s\tremaining: 6.31s\n",
            "512:\tlearn: 0.0508960\ttotal: 6.64s\tremaining: 6.3s\n",
            "513:\tlearn: 0.0507368\ttotal: 6.65s\tremaining: 6.29s\n",
            "514:\tlearn: 0.0505884\ttotal: 6.67s\tremaining: 6.28s\n",
            "515:\tlearn: 0.0504447\ttotal: 6.68s\tremaining: 6.27s\n",
            "516:\tlearn: 0.0503362\ttotal: 6.69s\tremaining: 6.25s\n",
            "517:\tlearn: 0.0502077\ttotal: 6.7s\tremaining: 6.24s\n",
            "518:\tlearn: 0.0501052\ttotal: 6.71s\tremaining: 6.22s\n",
            "519:\tlearn: 0.0500459\ttotal: 6.72s\tremaining: 6.21s\n",
            "520:\tlearn: 0.0499676\ttotal: 6.73s\tremaining: 6.19s\n",
            "521:\tlearn: 0.0498666\ttotal: 6.74s\tremaining: 6.17s\n",
            "522:\tlearn: 0.0497328\ttotal: 6.75s\tremaining: 6.16s\n",
            "523:\tlearn: 0.0496471\ttotal: 6.76s\tremaining: 6.14s\n",
            "524:\tlearn: 0.0495498\ttotal: 6.77s\tremaining: 6.13s\n",
            "525:\tlearn: 0.0494540\ttotal: 6.79s\tremaining: 6.11s\n",
            "526:\tlearn: 0.0493409\ttotal: 6.79s\tremaining: 6.1s\n",
            "527:\tlearn: 0.0492194\ttotal: 6.8s\tremaining: 6.08s\n",
            "528:\tlearn: 0.0491492\ttotal: 6.82s\tremaining: 6.07s\n",
            "529:\tlearn: 0.0490525\ttotal: 6.83s\tremaining: 6.05s\n",
            "530:\tlearn: 0.0489375\ttotal: 6.84s\tremaining: 6.04s\n",
            "531:\tlearn: 0.0488303\ttotal: 6.85s\tremaining: 6.02s\n",
            "532:\tlearn: 0.0487592\ttotal: 6.86s\tremaining: 6.01s\n",
            "533:\tlearn: 0.0486521\ttotal: 6.87s\tremaining: 6s\n",
            "534:\tlearn: 0.0486089\ttotal: 6.88s\tremaining: 5.98s\n",
            "535:\tlearn: 0.0485093\ttotal: 6.89s\tremaining: 5.97s\n",
            "536:\tlearn: 0.0484198\ttotal: 6.91s\tremaining: 5.96s\n",
            "537:\tlearn: 0.0483519\ttotal: 6.92s\tremaining: 5.94s\n",
            "538:\tlearn: 0.0482387\ttotal: 6.93s\tremaining: 5.93s\n",
            "539:\tlearn: 0.0481188\ttotal: 6.94s\tremaining: 5.91s\n",
            "540:\tlearn: 0.0480698\ttotal: 6.95s\tremaining: 5.9s\n",
            "541:\tlearn: 0.0479664\ttotal: 6.96s\tremaining: 5.88s\n",
            "542:\tlearn: 0.0478608\ttotal: 6.97s\tremaining: 5.87s\n",
            "543:\tlearn: 0.0477534\ttotal: 6.98s\tremaining: 5.86s\n",
            "544:\tlearn: 0.0476531\ttotal: 7s\tremaining: 5.84s\n",
            "545:\tlearn: 0.0475251\ttotal: 7s\tremaining: 5.82s\n",
            "546:\tlearn: 0.0474261\ttotal: 7.01s\tremaining: 5.81s\n",
            "547:\tlearn: 0.0473429\ttotal: 7.03s\tremaining: 5.79s\n",
            "548:\tlearn: 0.0472523\ttotal: 7.04s\tremaining: 5.78s\n",
            "549:\tlearn: 0.0471122\ttotal: 7.05s\tremaining: 5.76s\n",
            "550:\tlearn: 0.0470007\ttotal: 7.06s\tremaining: 5.75s\n",
            "551:\tlearn: 0.0468894\ttotal: 7.07s\tremaining: 5.74s\n",
            "552:\tlearn: 0.0467845\ttotal: 7.08s\tremaining: 5.73s\n",
            "553:\tlearn: 0.0466992\ttotal: 7.1s\tremaining: 5.71s\n",
            "554:\tlearn: 0.0466201\ttotal: 7.11s\tremaining: 5.7s\n",
            "555:\tlearn: 0.0465159\ttotal: 7.12s\tremaining: 5.68s\n",
            "556:\tlearn: 0.0463901\ttotal: 7.13s\tremaining: 5.67s\n",
            "557:\tlearn: 0.0463038\ttotal: 7.14s\tremaining: 5.65s\n",
            "558:\tlearn: 0.0462628\ttotal: 7.15s\tremaining: 5.64s\n",
            "559:\tlearn: 0.0461427\ttotal: 7.16s\tremaining: 5.62s\n",
            "560:\tlearn: 0.0460628\ttotal: 7.17s\tremaining: 5.61s\n",
            "561:\tlearn: 0.0459757\ttotal: 7.18s\tremaining: 5.6s\n",
            "562:\tlearn: 0.0458367\ttotal: 7.19s\tremaining: 5.58s\n",
            "563:\tlearn: 0.0457358\ttotal: 7.21s\tremaining: 5.57s\n",
            "564:\tlearn: 0.0456486\ttotal: 7.22s\tremaining: 5.56s\n",
            "565:\tlearn: 0.0455765\ttotal: 7.23s\tremaining: 5.54s\n",
            "566:\tlearn: 0.0455332\ttotal: 7.24s\tremaining: 5.53s\n",
            "567:\tlearn: 0.0454119\ttotal: 7.25s\tremaining: 5.51s\n",
            "568:\tlearn: 0.0452757\ttotal: 7.26s\tremaining: 5.5s\n",
            "569:\tlearn: 0.0451658\ttotal: 7.27s\tremaining: 5.49s\n",
            "570:\tlearn: 0.0450120\ttotal: 7.29s\tremaining: 5.48s\n",
            "571:\tlearn: 0.0448404\ttotal: 7.3s\tremaining: 5.46s\n",
            "572:\tlearn: 0.0447813\ttotal: 7.31s\tremaining: 5.45s\n",
            "573:\tlearn: 0.0446407\ttotal: 7.32s\tremaining: 5.43s\n",
            "574:\tlearn: 0.0445639\ttotal: 7.33s\tremaining: 5.42s\n",
            "575:\tlearn: 0.0443897\ttotal: 7.34s\tremaining: 5.41s\n",
            "576:\tlearn: 0.0442888\ttotal: 7.36s\tremaining: 5.39s\n",
            "577:\tlearn: 0.0441850\ttotal: 7.37s\tremaining: 5.38s\n",
            "578:\tlearn: 0.0441095\ttotal: 7.38s\tremaining: 5.36s\n",
            "579:\tlearn: 0.0440118\ttotal: 7.39s\tremaining: 5.35s\n",
            "580:\tlearn: 0.0438987\ttotal: 7.4s\tremaining: 5.33s\n",
            "581:\tlearn: 0.0438071\ttotal: 7.41s\tremaining: 5.32s\n",
            "582:\tlearn: 0.0437167\ttotal: 7.42s\tremaining: 5.3s\n",
            "583:\tlearn: 0.0436546\ttotal: 7.43s\tremaining: 5.29s\n",
            "584:\tlearn: 0.0435649\ttotal: 7.44s\tremaining: 5.28s\n",
            "585:\tlearn: 0.0435011\ttotal: 7.45s\tremaining: 5.26s\n",
            "586:\tlearn: 0.0434016\ttotal: 7.46s\tremaining: 5.25s\n",
            "587:\tlearn: 0.0433250\ttotal: 7.47s\tremaining: 5.23s\n",
            "588:\tlearn: 0.0432201\ttotal: 7.49s\tremaining: 5.22s\n",
            "589:\tlearn: 0.0431289\ttotal: 7.5s\tremaining: 5.21s\n",
            "590:\tlearn: 0.0430377\ttotal: 7.51s\tremaining: 5.2s\n",
            "591:\tlearn: 0.0429514\ttotal: 7.52s\tremaining: 5.18s\n",
            "592:\tlearn: 0.0428395\ttotal: 7.53s\tremaining: 5.17s\n",
            "593:\tlearn: 0.0427827\ttotal: 7.54s\tremaining: 5.15s\n",
            "594:\tlearn: 0.0427151\ttotal: 7.55s\tremaining: 5.14s\n",
            "595:\tlearn: 0.0426457\ttotal: 7.56s\tremaining: 5.13s\n",
            "596:\tlearn: 0.0425483\ttotal: 7.57s\tremaining: 5.11s\n",
            "597:\tlearn: 0.0424679\ttotal: 7.58s\tremaining: 5.1s\n",
            "598:\tlearn: 0.0423826\ttotal: 7.59s\tremaining: 5.08s\n",
            "599:\tlearn: 0.0422986\ttotal: 7.62s\tremaining: 5.08s\n",
            "600:\tlearn: 0.0422354\ttotal: 7.63s\tremaining: 5.07s\n",
            "601:\tlearn: 0.0421721\ttotal: 7.64s\tremaining: 5.05s\n",
            "602:\tlearn: 0.0420933\ttotal: 7.66s\tremaining: 5.04s\n",
            "603:\tlearn: 0.0420401\ttotal: 7.67s\tremaining: 5.03s\n",
            "604:\tlearn: 0.0419837\ttotal: 7.68s\tremaining: 5.01s\n",
            "605:\tlearn: 0.0419408\ttotal: 7.7s\tremaining: 5s\n",
            "606:\tlearn: 0.0418174\ttotal: 7.71s\tremaining: 4.99s\n",
            "607:\tlearn: 0.0417433\ttotal: 7.72s\tremaining: 4.98s\n",
            "608:\tlearn: 0.0416756\ttotal: 7.73s\tremaining: 4.96s\n",
            "609:\tlearn: 0.0416274\ttotal: 7.74s\tremaining: 4.95s\n",
            "610:\tlearn: 0.0415774\ttotal: 7.75s\tremaining: 4.93s\n",
            "611:\tlearn: 0.0415102\ttotal: 7.76s\tremaining: 4.92s\n",
            "612:\tlearn: 0.0414337\ttotal: 7.77s\tremaining: 4.91s\n",
            "613:\tlearn: 0.0413674\ttotal: 7.78s\tremaining: 4.89s\n",
            "614:\tlearn: 0.0412520\ttotal: 7.79s\tremaining: 4.88s\n",
            "615:\tlearn: 0.0411649\ttotal: 7.8s\tremaining: 4.87s\n",
            "616:\tlearn: 0.0411117\ttotal: 7.81s\tremaining: 4.85s\n",
            "617:\tlearn: 0.0410102\ttotal: 7.83s\tremaining: 4.84s\n",
            "618:\tlearn: 0.0408816\ttotal: 7.84s\tremaining: 4.83s\n",
            "619:\tlearn: 0.0407843\ttotal: 7.86s\tremaining: 4.82s\n",
            "620:\tlearn: 0.0407208\ttotal: 7.87s\tremaining: 4.8s\n",
            "621:\tlearn: 0.0406552\ttotal: 7.88s\tremaining: 4.79s\n",
            "622:\tlearn: 0.0405749\ttotal: 7.89s\tremaining: 4.78s\n",
            "623:\tlearn: 0.0405010\ttotal: 7.91s\tremaining: 4.77s\n",
            "624:\tlearn: 0.0404016\ttotal: 7.92s\tremaining: 4.75s\n",
            "625:\tlearn: 0.0403398\ttotal: 7.93s\tremaining: 4.74s\n",
            "626:\tlearn: 0.0402700\ttotal: 7.94s\tremaining: 4.73s\n",
            "627:\tlearn: 0.0402258\ttotal: 7.96s\tremaining: 4.71s\n",
            "628:\tlearn: 0.0401441\ttotal: 7.96s\tremaining: 4.7s\n",
            "629:\tlearn: 0.0400491\ttotal: 7.98s\tremaining: 4.68s\n",
            "630:\tlearn: 0.0399523\ttotal: 7.99s\tremaining: 4.67s\n",
            "631:\tlearn: 0.0398253\ttotal: 8s\tremaining: 4.66s\n",
            "632:\tlearn: 0.0397615\ttotal: 8.01s\tremaining: 4.64s\n",
            "633:\tlearn: 0.0396684\ttotal: 8.02s\tremaining: 4.63s\n",
            "634:\tlearn: 0.0395933\ttotal: 8.03s\tremaining: 4.61s\n",
            "635:\tlearn: 0.0394919\ttotal: 8.04s\tremaining: 4.6s\n",
            "636:\tlearn: 0.0394120\ttotal: 8.05s\tremaining: 4.59s\n",
            "637:\tlearn: 0.0393127\ttotal: 8.06s\tremaining: 4.57s\n",
            "638:\tlearn: 0.0392401\ttotal: 8.07s\tremaining: 4.56s\n",
            "639:\tlearn: 0.0391714\ttotal: 8.08s\tremaining: 4.54s\n",
            "640:\tlearn: 0.0390805\ttotal: 8.09s\tremaining: 4.53s\n",
            "641:\tlearn: 0.0389872\ttotal: 8.1s\tremaining: 4.52s\n",
            "642:\tlearn: 0.0389025\ttotal: 8.12s\tremaining: 4.51s\n",
            "643:\tlearn: 0.0388092\ttotal: 8.13s\tremaining: 4.49s\n",
            "644:\tlearn: 0.0386930\ttotal: 8.14s\tremaining: 4.48s\n",
            "645:\tlearn: 0.0386244\ttotal: 8.15s\tremaining: 4.47s\n",
            "646:\tlearn: 0.0385701\ttotal: 8.16s\tremaining: 4.45s\n",
            "647:\tlearn: 0.0384767\ttotal: 8.17s\tremaining: 4.44s\n",
            "648:\tlearn: 0.0384274\ttotal: 8.18s\tremaining: 4.42s\n",
            "649:\tlearn: 0.0383910\ttotal: 8.19s\tremaining: 4.41s\n",
            "650:\tlearn: 0.0383346\ttotal: 8.2s\tremaining: 4.4s\n",
            "651:\tlearn: 0.0382686\ttotal: 8.21s\tremaining: 4.38s\n",
            "652:\tlearn: 0.0382080\ttotal: 8.22s\tremaining: 4.37s\n",
            "653:\tlearn: 0.0381607\ttotal: 8.23s\tremaining: 4.36s\n",
            "654:\tlearn: 0.0380288\ttotal: 8.24s\tremaining: 4.34s\n",
            "655:\tlearn: 0.0379300\ttotal: 8.26s\tremaining: 4.33s\n",
            "656:\tlearn: 0.0378770\ttotal: 8.27s\tremaining: 4.32s\n",
            "657:\tlearn: 0.0377823\ttotal: 8.28s\tremaining: 4.3s\n",
            "658:\tlearn: 0.0377128\ttotal: 8.29s\tremaining: 4.29s\n",
            "659:\tlearn: 0.0376939\ttotal: 8.3s\tremaining: 4.27s\n",
            "660:\tlearn: 0.0375917\ttotal: 8.31s\tremaining: 4.26s\n",
            "661:\tlearn: 0.0374936\ttotal: 8.32s\tremaining: 4.25s\n",
            "662:\tlearn: 0.0374587\ttotal: 8.34s\tremaining: 4.24s\n",
            "663:\tlearn: 0.0374207\ttotal: 8.35s\tremaining: 4.22s\n",
            "664:\tlearn: 0.0373786\ttotal: 8.36s\tremaining: 4.21s\n",
            "665:\tlearn: 0.0372728\ttotal: 8.37s\tremaining: 4.2s\n",
            "666:\tlearn: 0.0371990\ttotal: 8.38s\tremaining: 4.18s\n",
            "667:\tlearn: 0.0371416\ttotal: 8.39s\tremaining: 4.17s\n",
            "668:\tlearn: 0.0370680\ttotal: 8.4s\tremaining: 4.16s\n",
            "669:\tlearn: 0.0369984\ttotal: 8.41s\tremaining: 4.14s\n",
            "670:\tlearn: 0.0369189\ttotal: 8.42s\tremaining: 4.13s\n",
            "671:\tlearn: 0.0368578\ttotal: 8.43s\tremaining: 4.12s\n",
            "672:\tlearn: 0.0368121\ttotal: 8.44s\tremaining: 4.1s\n",
            "673:\tlearn: 0.0367656\ttotal: 8.45s\tremaining: 4.09s\n",
            "674:\tlearn: 0.0366895\ttotal: 8.46s\tremaining: 4.07s\n",
            "675:\tlearn: 0.0366522\ttotal: 8.47s\tremaining: 4.06s\n",
            "676:\tlearn: 0.0365715\ttotal: 8.48s\tremaining: 4.05s\n",
            "677:\tlearn: 0.0364874\ttotal: 8.49s\tremaining: 4.03s\n",
            "678:\tlearn: 0.0363700\ttotal: 8.5s\tremaining: 4.02s\n",
            "679:\tlearn: 0.0362676\ttotal: 8.51s\tremaining: 4.01s\n",
            "680:\tlearn: 0.0361709\ttotal: 8.52s\tremaining: 3.99s\n",
            "681:\tlearn: 0.0360810\ttotal: 8.53s\tremaining: 3.98s\n",
            "682:\tlearn: 0.0360080\ttotal: 8.55s\tremaining: 3.97s\n",
            "683:\tlearn: 0.0359124\ttotal: 8.57s\tremaining: 3.96s\n",
            "684:\tlearn: 0.0358272\ttotal: 8.58s\tremaining: 3.94s\n",
            "685:\tlearn: 0.0357839\ttotal: 8.59s\tremaining: 3.93s\n",
            "686:\tlearn: 0.0357087\ttotal: 8.61s\tremaining: 3.92s\n",
            "687:\tlearn: 0.0356250\ttotal: 8.63s\tremaining: 3.92s\n",
            "688:\tlearn: 0.0355429\ttotal: 8.65s\tremaining: 3.9s\n",
            "689:\tlearn: 0.0354682\ttotal: 8.66s\tremaining: 3.89s\n",
            "690:\tlearn: 0.0353960\ttotal: 8.67s\tremaining: 3.88s\n",
            "691:\tlearn: 0.0352913\ttotal: 8.68s\tremaining: 3.86s\n",
            "692:\tlearn: 0.0352423\ttotal: 8.69s\tremaining: 3.85s\n",
            "693:\tlearn: 0.0351452\ttotal: 8.7s\tremaining: 3.84s\n",
            "694:\tlearn: 0.0350789\ttotal: 8.71s\tremaining: 3.82s\n",
            "695:\tlearn: 0.0350068\ttotal: 8.72s\tremaining: 3.81s\n",
            "696:\tlearn: 0.0349696\ttotal: 8.74s\tremaining: 3.8s\n",
            "697:\tlearn: 0.0348761\ttotal: 8.75s\tremaining: 3.79s\n",
            "698:\tlearn: 0.0348078\ttotal: 8.76s\tremaining: 3.77s\n",
            "699:\tlearn: 0.0347389\ttotal: 8.77s\tremaining: 3.76s\n",
            "700:\tlearn: 0.0346754\ttotal: 8.78s\tremaining: 3.75s\n",
            "701:\tlearn: 0.0346052\ttotal: 8.79s\tremaining: 3.73s\n",
            "702:\tlearn: 0.0345410\ttotal: 8.8s\tremaining: 3.72s\n",
            "703:\tlearn: 0.0344789\ttotal: 8.81s\tremaining: 3.71s\n",
            "704:\tlearn: 0.0343990\ttotal: 8.82s\tremaining: 3.69s\n",
            "705:\tlearn: 0.0343570\ttotal: 8.83s\tremaining: 3.68s\n",
            "706:\tlearn: 0.0342910\ttotal: 8.84s\tremaining: 3.66s\n",
            "707:\tlearn: 0.0342356\ttotal: 8.85s\tremaining: 3.65s\n",
            "708:\tlearn: 0.0341752\ttotal: 8.86s\tremaining: 3.64s\n",
            "709:\tlearn: 0.0341321\ttotal: 8.87s\tremaining: 3.62s\n",
            "710:\tlearn: 0.0340743\ttotal: 8.89s\tremaining: 3.61s\n",
            "711:\tlearn: 0.0340480\ttotal: 8.89s\tremaining: 3.6s\n",
            "712:\tlearn: 0.0339949\ttotal: 8.9s\tremaining: 3.58s\n",
            "713:\tlearn: 0.0339190\ttotal: 8.91s\tremaining: 3.57s\n",
            "714:\tlearn: 0.0338446\ttotal: 8.92s\tremaining: 3.56s\n",
            "715:\tlearn: 0.0337905\ttotal: 8.93s\tremaining: 3.54s\n",
            "716:\tlearn: 0.0337382\ttotal: 8.95s\tremaining: 3.53s\n",
            "717:\tlearn: 0.0336296\ttotal: 8.97s\tremaining: 3.52s\n",
            "718:\tlearn: 0.0335757\ttotal: 8.98s\tremaining: 3.51s\n",
            "719:\tlearn: 0.0335212\ttotal: 8.99s\tremaining: 3.5s\n",
            "720:\tlearn: 0.0334341\ttotal: 9s\tremaining: 3.48s\n",
            "721:\tlearn: 0.0333816\ttotal: 9.01s\tremaining: 3.47s\n",
            "722:\tlearn: 0.0333080\ttotal: 9.02s\tremaining: 3.46s\n",
            "723:\tlearn: 0.0332705\ttotal: 9.03s\tremaining: 3.44s\n",
            "724:\tlearn: 0.0332388\ttotal: 9.04s\tremaining: 3.43s\n",
            "725:\tlearn: 0.0332174\ttotal: 9.05s\tremaining: 3.42s\n",
            "726:\tlearn: 0.0331664\ttotal: 9.06s\tremaining: 3.4s\n",
            "727:\tlearn: 0.0331370\ttotal: 9.07s\tremaining: 3.39s\n",
            "728:\tlearn: 0.0331041\ttotal: 9.08s\tremaining: 3.38s\n",
            "729:\tlearn: 0.0330112\ttotal: 9.09s\tremaining: 3.36s\n",
            "730:\tlearn: 0.0329553\ttotal: 9.1s\tremaining: 3.35s\n",
            "731:\tlearn: 0.0328827\ttotal: 9.11s\tremaining: 3.33s\n",
            "732:\tlearn: 0.0328187\ttotal: 9.12s\tremaining: 3.32s\n",
            "733:\tlearn: 0.0327421\ttotal: 9.13s\tremaining: 3.31s\n",
            "734:\tlearn: 0.0326829\ttotal: 9.14s\tremaining: 3.29s\n",
            "735:\tlearn: 0.0326071\ttotal: 9.15s\tremaining: 3.28s\n",
            "736:\tlearn: 0.0325364\ttotal: 9.17s\tremaining: 3.27s\n",
            "737:\tlearn: 0.0324660\ttotal: 9.18s\tremaining: 3.26s\n",
            "738:\tlearn: 0.0324179\ttotal: 9.19s\tremaining: 3.25s\n",
            "739:\tlearn: 0.0323679\ttotal: 9.2s\tremaining: 3.23s\n",
            "740:\tlearn: 0.0322949\ttotal: 9.21s\tremaining: 3.22s\n",
            "741:\tlearn: 0.0322600\ttotal: 9.23s\tremaining: 3.21s\n",
            "742:\tlearn: 0.0321830\ttotal: 9.24s\tremaining: 3.19s\n",
            "743:\tlearn: 0.0321083\ttotal: 9.25s\tremaining: 3.18s\n",
            "744:\tlearn: 0.0320583\ttotal: 9.26s\tremaining: 3.17s\n",
            "745:\tlearn: 0.0320061\ttotal: 9.27s\tremaining: 3.15s\n",
            "746:\tlearn: 0.0319308\ttotal: 9.28s\tremaining: 3.14s\n",
            "747:\tlearn: 0.0318573\ttotal: 9.29s\tremaining: 3.13s\n",
            "748:\tlearn: 0.0317882\ttotal: 9.3s\tremaining: 3.12s\n",
            "749:\tlearn: 0.0317181\ttotal: 9.31s\tremaining: 3.1s\n",
            "750:\tlearn: 0.0316567\ttotal: 9.32s\tremaining: 3.09s\n",
            "751:\tlearn: 0.0315767\ttotal: 9.34s\tremaining: 3.08s\n",
            "752:\tlearn: 0.0315412\ttotal: 9.35s\tremaining: 3.06s\n",
            "753:\tlearn: 0.0314827\ttotal: 9.36s\tremaining: 3.05s\n",
            "754:\tlearn: 0.0313872\ttotal: 9.37s\tremaining: 3.04s\n",
            "755:\tlearn: 0.0313227\ttotal: 9.38s\tremaining: 3.03s\n",
            "756:\tlearn: 0.0312570\ttotal: 9.39s\tremaining: 3.02s\n",
            "757:\tlearn: 0.0312246\ttotal: 9.41s\tremaining: 3s\n",
            "758:\tlearn: 0.0311679\ttotal: 9.42s\tremaining: 2.99s\n",
            "759:\tlearn: 0.0311430\ttotal: 9.43s\tremaining: 2.98s\n",
            "760:\tlearn: 0.0310981\ttotal: 9.44s\tremaining: 2.96s\n",
            "761:\tlearn: 0.0310357\ttotal: 9.45s\tremaining: 2.95s\n",
            "762:\tlearn: 0.0309761\ttotal: 9.46s\tremaining: 2.94s\n",
            "763:\tlearn: 0.0309369\ttotal: 9.47s\tremaining: 2.92s\n",
            "764:\tlearn: 0.0308630\ttotal: 9.48s\tremaining: 2.91s\n",
            "765:\tlearn: 0.0308300\ttotal: 9.49s\tremaining: 2.9s\n",
            "766:\tlearn: 0.0308049\ttotal: 9.5s\tremaining: 2.89s\n",
            "767:\tlearn: 0.0307656\ttotal: 9.51s\tremaining: 2.87s\n",
            "768:\tlearn: 0.0307120\ttotal: 9.52s\tremaining: 2.86s\n",
            "769:\tlearn: 0.0306517\ttotal: 9.53s\tremaining: 2.85s\n",
            "770:\tlearn: 0.0306002\ttotal: 9.54s\tremaining: 2.83s\n",
            "771:\tlearn: 0.0305192\ttotal: 9.55s\tremaining: 2.82s\n",
            "772:\tlearn: 0.0304617\ttotal: 9.58s\tremaining: 2.81s\n",
            "773:\tlearn: 0.0304340\ttotal: 9.6s\tremaining: 2.8s\n",
            "774:\tlearn: 0.0303658\ttotal: 9.61s\tremaining: 2.79s\n",
            "775:\tlearn: 0.0303127\ttotal: 9.63s\tremaining: 2.78s\n",
            "776:\tlearn: 0.0302787\ttotal: 9.64s\tremaining: 2.77s\n",
            "777:\tlearn: 0.0302266\ttotal: 9.65s\tremaining: 2.75s\n",
            "778:\tlearn: 0.0301797\ttotal: 9.66s\tremaining: 2.74s\n",
            "779:\tlearn: 0.0301182\ttotal: 9.68s\tremaining: 2.73s\n",
            "780:\tlearn: 0.0300606\ttotal: 9.69s\tremaining: 2.71s\n",
            "781:\tlearn: 0.0300114\ttotal: 9.7s\tremaining: 2.7s\n",
            "782:\tlearn: 0.0299741\ttotal: 9.71s\tremaining: 2.69s\n",
            "783:\tlearn: 0.0299314\ttotal: 9.71s\tremaining: 2.68s\n",
            "784:\tlearn: 0.0298686\ttotal: 9.73s\tremaining: 2.66s\n",
            "785:\tlearn: 0.0298194\ttotal: 9.74s\tremaining: 2.65s\n",
            "786:\tlearn: 0.0297423\ttotal: 9.75s\tremaining: 2.64s\n",
            "787:\tlearn: 0.0297125\ttotal: 9.76s\tremaining: 2.63s\n",
            "788:\tlearn: 0.0296429\ttotal: 9.77s\tremaining: 2.61s\n",
            "789:\tlearn: 0.0295889\ttotal: 9.78s\tremaining: 2.6s\n",
            "790:\tlearn: 0.0295357\ttotal: 9.8s\tremaining: 2.59s\n",
            "791:\tlearn: 0.0294845\ttotal: 9.81s\tremaining: 2.58s\n",
            "792:\tlearn: 0.0294454\ttotal: 9.82s\tremaining: 2.56s\n",
            "793:\tlearn: 0.0294066\ttotal: 9.83s\tremaining: 2.55s\n",
            "794:\tlearn: 0.0293585\ttotal: 9.84s\tremaining: 2.54s\n",
            "795:\tlearn: 0.0292790\ttotal: 9.85s\tremaining: 2.52s\n",
            "796:\tlearn: 0.0292429\ttotal: 9.86s\tremaining: 2.51s\n",
            "797:\tlearn: 0.0291682\ttotal: 9.87s\tremaining: 2.5s\n",
            "798:\tlearn: 0.0291422\ttotal: 9.88s\tremaining: 2.48s\n",
            "799:\tlearn: 0.0290832\ttotal: 9.89s\tremaining: 2.47s\n",
            "800:\tlearn: 0.0290213\ttotal: 9.9s\tremaining: 2.46s\n",
            "801:\tlearn: 0.0289742\ttotal: 9.91s\tremaining: 2.45s\n",
            "802:\tlearn: 0.0289048\ttotal: 9.92s\tremaining: 2.43s\n",
            "803:\tlearn: 0.0288174\ttotal: 9.93s\tremaining: 2.42s\n",
            "804:\tlearn: 0.0287455\ttotal: 9.94s\tremaining: 2.41s\n",
            "805:\tlearn: 0.0287070\ttotal: 9.95s\tremaining: 2.4s\n",
            "806:\tlearn: 0.0286000\ttotal: 9.96s\tremaining: 2.38s\n",
            "807:\tlearn: 0.0285794\ttotal: 9.97s\tremaining: 2.37s\n",
            "808:\tlearn: 0.0285400\ttotal: 9.99s\tremaining: 2.36s\n",
            "809:\tlearn: 0.0284559\ttotal: 10s\tremaining: 2.35s\n",
            "810:\tlearn: 0.0284205\ttotal: 10s\tremaining: 2.33s\n",
            "811:\tlearn: 0.0283739\ttotal: 10s\tremaining: 2.32s\n",
            "812:\tlearn: 0.0283085\ttotal: 10s\tremaining: 2.31s\n",
            "813:\tlearn: 0.0282606\ttotal: 10s\tremaining: 2.29s\n",
            "814:\tlearn: 0.0281988\ttotal: 10.1s\tremaining: 2.28s\n",
            "815:\tlearn: 0.0281391\ttotal: 10.1s\tremaining: 2.27s\n",
            "816:\tlearn: 0.0281015\ttotal: 10.1s\tremaining: 2.26s\n",
            "817:\tlearn: 0.0280593\ttotal: 10.1s\tremaining: 2.24s\n",
            "818:\tlearn: 0.0280175\ttotal: 10.1s\tremaining: 2.23s\n",
            "819:\tlearn: 0.0279617\ttotal: 10.1s\tremaining: 2.22s\n",
            "820:\tlearn: 0.0279093\ttotal: 10.1s\tremaining: 2.21s\n",
            "821:\tlearn: 0.0278748\ttotal: 10.1s\tremaining: 2.19s\n",
            "822:\tlearn: 0.0278273\ttotal: 10.1s\tremaining: 2.18s\n",
            "823:\tlearn: 0.0277873\ttotal: 10.1s\tremaining: 2.17s\n",
            "824:\tlearn: 0.0277290\ttotal: 10.2s\tremaining: 2.15s\n",
            "825:\tlearn: 0.0276798\ttotal: 10.2s\tremaining: 2.14s\n",
            "826:\tlearn: 0.0276405\ttotal: 10.2s\tremaining: 2.13s\n",
            "827:\tlearn: 0.0275804\ttotal: 10.2s\tremaining: 2.12s\n",
            "828:\tlearn: 0.0275307\ttotal: 10.2s\tremaining: 2.11s\n",
            "829:\tlearn: 0.0274878\ttotal: 10.2s\tremaining: 2.09s\n",
            "830:\tlearn: 0.0274440\ttotal: 10.2s\tremaining: 2.08s\n",
            "831:\tlearn: 0.0273729\ttotal: 10.2s\tremaining: 2.07s\n",
            "832:\tlearn: 0.0273082\ttotal: 10.3s\tremaining: 2.06s\n",
            "833:\tlearn: 0.0272924\ttotal: 10.3s\tremaining: 2.04s\n",
            "834:\tlearn: 0.0272501\ttotal: 10.3s\tremaining: 2.03s\n",
            "835:\tlearn: 0.0271918\ttotal: 10.3s\tremaining: 2.02s\n",
            "836:\tlearn: 0.0271253\ttotal: 10.3s\tremaining: 2s\n",
            "837:\tlearn: 0.0270832\ttotal: 10.3s\tremaining: 1.99s\n",
            "838:\tlearn: 0.0270128\ttotal: 10.3s\tremaining: 1.98s\n",
            "839:\tlearn: 0.0269675\ttotal: 10.3s\tremaining: 1.97s\n",
            "840:\tlearn: 0.0269182\ttotal: 10.3s\tremaining: 1.95s\n",
            "841:\tlearn: 0.0268613\ttotal: 10.3s\tremaining: 1.94s\n",
            "842:\tlearn: 0.0268211\ttotal: 10.4s\tremaining: 1.93s\n",
            "843:\tlearn: 0.0267583\ttotal: 10.4s\tremaining: 1.92s\n",
            "844:\tlearn: 0.0266856\ttotal: 10.4s\tremaining: 1.9s\n",
            "845:\tlearn: 0.0266576\ttotal: 10.4s\tremaining: 1.89s\n",
            "846:\tlearn: 0.0266408\ttotal: 10.4s\tremaining: 1.88s\n",
            "847:\tlearn: 0.0266029\ttotal: 10.4s\tremaining: 1.87s\n",
            "848:\tlearn: 0.0265418\ttotal: 10.4s\tremaining: 1.85s\n",
            "849:\tlearn: 0.0264715\ttotal: 10.4s\tremaining: 1.84s\n",
            "850:\tlearn: 0.0264142\ttotal: 10.4s\tremaining: 1.83s\n",
            "851:\tlearn: 0.0263473\ttotal: 10.5s\tremaining: 1.82s\n",
            "852:\tlearn: 0.0263024\ttotal: 10.5s\tremaining: 1.8s\n",
            "853:\tlearn: 0.0262786\ttotal: 10.5s\tremaining: 1.79s\n",
            "854:\tlearn: 0.0262445\ttotal: 10.5s\tremaining: 1.78s\n",
            "855:\tlearn: 0.0262062\ttotal: 10.5s\tremaining: 1.77s\n",
            "856:\tlearn: 0.0261606\ttotal: 10.5s\tremaining: 1.75s\n",
            "857:\tlearn: 0.0261469\ttotal: 10.5s\tremaining: 1.74s\n",
            "858:\tlearn: 0.0261082\ttotal: 10.5s\tremaining: 1.73s\n",
            "859:\tlearn: 0.0260635\ttotal: 10.5s\tremaining: 1.72s\n",
            "860:\tlearn: 0.0259977\ttotal: 10.6s\tremaining: 1.7s\n",
            "861:\tlearn: 0.0259873\ttotal: 10.6s\tremaining: 1.69s\n",
            "862:\tlearn: 0.0259514\ttotal: 10.6s\tremaining: 1.68s\n",
            "863:\tlearn: 0.0259198\ttotal: 10.6s\tremaining: 1.67s\n",
            "864:\tlearn: 0.0258792\ttotal: 10.6s\tremaining: 1.65s\n",
            "865:\tlearn: 0.0258471\ttotal: 10.6s\tremaining: 1.64s\n",
            "866:\tlearn: 0.0258245\ttotal: 10.6s\tremaining: 1.63s\n",
            "867:\tlearn: 0.0257710\ttotal: 10.6s\tremaining: 1.62s\n",
            "868:\tlearn: 0.0257075\ttotal: 10.7s\tremaining: 1.61s\n",
            "869:\tlearn: 0.0256775\ttotal: 10.7s\tremaining: 1.59s\n",
            "870:\tlearn: 0.0256480\ttotal: 10.7s\tremaining: 1.58s\n",
            "871:\tlearn: 0.0256218\ttotal: 10.7s\tremaining: 1.57s\n",
            "872:\tlearn: 0.0255653\ttotal: 10.7s\tremaining: 1.56s\n",
            "873:\tlearn: 0.0255207\ttotal: 10.7s\tremaining: 1.54s\n",
            "874:\tlearn: 0.0255065\ttotal: 10.7s\tremaining: 1.53s\n",
            "875:\tlearn: 0.0254646\ttotal: 10.7s\tremaining: 1.52s\n",
            "876:\tlearn: 0.0254037\ttotal: 10.7s\tremaining: 1.51s\n",
            "877:\tlearn: 0.0253731\ttotal: 10.8s\tremaining: 1.49s\n",
            "878:\tlearn: 0.0253048\ttotal: 10.8s\tremaining: 1.48s\n",
            "879:\tlearn: 0.0252269\ttotal: 10.8s\tremaining: 1.47s\n",
            "880:\tlearn: 0.0252014\ttotal: 10.8s\tremaining: 1.46s\n",
            "881:\tlearn: 0.0251706\ttotal: 10.8s\tremaining: 1.44s\n",
            "882:\tlearn: 0.0251447\ttotal: 10.8s\tremaining: 1.43s\n",
            "883:\tlearn: 0.0251133\ttotal: 10.8s\tremaining: 1.42s\n",
            "884:\tlearn: 0.0250686\ttotal: 10.8s\tremaining: 1.41s\n",
            "885:\tlearn: 0.0250206\ttotal: 10.8s\tremaining: 1.4s\n",
            "886:\tlearn: 0.0250076\ttotal: 10.9s\tremaining: 1.38s\n",
            "887:\tlearn: 0.0249893\ttotal: 10.9s\tremaining: 1.37s\n",
            "888:\tlearn: 0.0249373\ttotal: 10.9s\tremaining: 1.36s\n",
            "889:\tlearn: 0.0249041\ttotal: 10.9s\tremaining: 1.34s\n",
            "890:\tlearn: 0.0248491\ttotal: 10.9s\tremaining: 1.33s\n",
            "891:\tlearn: 0.0248200\ttotal: 10.9s\tremaining: 1.32s\n",
            "892:\tlearn: 0.0247823\ttotal: 10.9s\tremaining: 1.31s\n",
            "893:\tlearn: 0.0247268\ttotal: 10.9s\tremaining: 1.29s\n",
            "894:\tlearn: 0.0246948\ttotal: 10.9s\tremaining: 1.28s\n",
            "895:\tlearn: 0.0246662\ttotal: 10.9s\tremaining: 1.27s\n",
            "896:\tlearn: 0.0246550\ttotal: 11s\tremaining: 1.26s\n",
            "897:\tlearn: 0.0246076\ttotal: 11s\tremaining: 1.25s\n",
            "898:\tlearn: 0.0245820\ttotal: 11s\tremaining: 1.23s\n",
            "899:\tlearn: 0.0245271\ttotal: 11s\tremaining: 1.22s\n",
            "900:\tlearn: 0.0244621\ttotal: 11s\tremaining: 1.21s\n",
            "901:\tlearn: 0.0244376\ttotal: 11s\tremaining: 1.2s\n",
            "902:\tlearn: 0.0244078\ttotal: 11s\tremaining: 1.18s\n",
            "903:\tlearn: 0.0243845\ttotal: 11s\tremaining: 1.17s\n",
            "904:\tlearn: 0.0243370\ttotal: 11.1s\tremaining: 1.16s\n",
            "905:\tlearn: 0.0242935\ttotal: 11.1s\tremaining: 1.15s\n",
            "906:\tlearn: 0.0242650\ttotal: 11.1s\tremaining: 1.14s\n",
            "907:\tlearn: 0.0242092\ttotal: 11.1s\tremaining: 1.12s\n",
            "908:\tlearn: 0.0241613\ttotal: 11.1s\tremaining: 1.11s\n",
            "909:\tlearn: 0.0241265\ttotal: 11.1s\tremaining: 1.1s\n",
            "910:\tlearn: 0.0240842\ttotal: 11.1s\tremaining: 1.08s\n",
            "911:\tlearn: 0.0240476\ttotal: 11.1s\tremaining: 1.07s\n",
            "912:\tlearn: 0.0240023\ttotal: 11.1s\tremaining: 1.06s\n",
            "913:\tlearn: 0.0239649\ttotal: 11.1s\tremaining: 1.05s\n",
            "914:\tlearn: 0.0239305\ttotal: 11.2s\tremaining: 1.04s\n",
            "915:\tlearn: 0.0238944\ttotal: 11.2s\tremaining: 1.02s\n",
            "916:\tlearn: 0.0238589\ttotal: 11.2s\tremaining: 1.01s\n",
            "917:\tlearn: 0.0238356\ttotal: 11.2s\tremaining: 999ms\n",
            "918:\tlearn: 0.0237692\ttotal: 11.2s\tremaining: 987ms\n",
            "919:\tlearn: 0.0237523\ttotal: 11.2s\tremaining: 974ms\n",
            "920:\tlearn: 0.0237004\ttotal: 11.2s\tremaining: 962ms\n",
            "921:\tlearn: 0.0236425\ttotal: 11.2s\tremaining: 950ms\n",
            "922:\tlearn: 0.0235988\ttotal: 11.2s\tremaining: 938ms\n",
            "923:\tlearn: 0.0235644\ttotal: 11.3s\tremaining: 926ms\n",
            "924:\tlearn: 0.0235389\ttotal: 11.3s\tremaining: 913ms\n",
            "925:\tlearn: 0.0235232\ttotal: 11.3s\tremaining: 901ms\n",
            "926:\tlearn: 0.0234686\ttotal: 11.3s\tremaining: 889ms\n",
            "927:\tlearn: 0.0234249\ttotal: 11.3s\tremaining: 876ms\n",
            "928:\tlearn: 0.0233797\ttotal: 11.3s\tremaining: 864ms\n",
            "929:\tlearn: 0.0233465\ttotal: 11.3s\tremaining: 852ms\n",
            "930:\tlearn: 0.0233048\ttotal: 11.3s\tremaining: 840ms\n",
            "931:\tlearn: 0.0232460\ttotal: 11.3s\tremaining: 827ms\n",
            "932:\tlearn: 0.0232118\ttotal: 11.3s\tremaining: 815ms\n",
            "933:\tlearn: 0.0231703\ttotal: 11.4s\tremaining: 803ms\n",
            "934:\tlearn: 0.0231302\ttotal: 11.4s\tremaining: 790ms\n",
            "935:\tlearn: 0.0231052\ttotal: 11.4s\tremaining: 778ms\n",
            "936:\tlearn: 0.0230553\ttotal: 11.4s\tremaining: 766ms\n",
            "937:\tlearn: 0.0230050\ttotal: 11.4s\tremaining: 754ms\n",
            "938:\tlearn: 0.0229770\ttotal: 11.4s\tremaining: 741ms\n",
            "939:\tlearn: 0.0229466\ttotal: 11.4s\tremaining: 729ms\n",
            "940:\tlearn: 0.0229091\ttotal: 11.4s\tremaining: 717ms\n",
            "941:\tlearn: 0.0228745\ttotal: 11.4s\tremaining: 705ms\n",
            "942:\tlearn: 0.0228372\ttotal: 11.5s\tremaining: 693ms\n",
            "943:\tlearn: 0.0228096\ttotal: 11.5s\tremaining: 680ms\n",
            "944:\tlearn: 0.0227668\ttotal: 11.5s\tremaining: 668ms\n",
            "945:\tlearn: 0.0227354\ttotal: 11.5s\tremaining: 656ms\n",
            "946:\tlearn: 0.0226864\ttotal: 11.5s\tremaining: 644ms\n",
            "947:\tlearn: 0.0226544\ttotal: 11.5s\tremaining: 632ms\n",
            "948:\tlearn: 0.0225910\ttotal: 11.5s\tremaining: 619ms\n",
            "949:\tlearn: 0.0225638\ttotal: 11.5s\tremaining: 608ms\n",
            "950:\tlearn: 0.0225083\ttotal: 11.6s\tremaining: 596ms\n",
            "951:\tlearn: 0.0224849\ttotal: 11.6s\tremaining: 584ms\n",
            "952:\tlearn: 0.0224576\ttotal: 11.6s\tremaining: 572ms\n",
            "953:\tlearn: 0.0223963\ttotal: 11.6s\tremaining: 560ms\n",
            "954:\tlearn: 0.0223642\ttotal: 11.6s\tremaining: 548ms\n",
            "955:\tlearn: 0.0223141\ttotal: 11.7s\tremaining: 536ms\n",
            "956:\tlearn: 0.0222992\ttotal: 11.7s\tremaining: 525ms\n",
            "957:\tlearn: 0.0222653\ttotal: 11.7s\tremaining: 513ms\n",
            "958:\tlearn: 0.0222426\ttotal: 11.7s\tremaining: 501ms\n",
            "959:\tlearn: 0.0222163\ttotal: 11.7s\tremaining: 489ms\n",
            "960:\tlearn: 0.0221547\ttotal: 11.7s\tremaining: 477ms\n",
            "961:\tlearn: 0.0221164\ttotal: 11.8s\tremaining: 464ms\n",
            "962:\tlearn: 0.0220611\ttotal: 11.8s\tremaining: 452ms\n",
            "963:\tlearn: 0.0220078\ttotal: 11.8s\tremaining: 440ms\n",
            "964:\tlearn: 0.0219932\ttotal: 11.8s\tremaining: 429ms\n",
            "965:\tlearn: 0.0219490\ttotal: 11.8s\tremaining: 417ms\n",
            "966:\tlearn: 0.0219140\ttotal: 11.9s\tremaining: 405ms\n",
            "967:\tlearn: 0.0218690\ttotal: 11.9s\tremaining: 393ms\n",
            "968:\tlearn: 0.0218108\ttotal: 11.9s\tremaining: 381ms\n",
            "969:\tlearn: 0.0217840\ttotal: 11.9s\tremaining: 369ms\n",
            "970:\tlearn: 0.0217680\ttotal: 12s\tremaining: 357ms\n",
            "971:\tlearn: 0.0217373\ttotal: 12s\tremaining: 345ms\n",
            "972:\tlearn: 0.0216954\ttotal: 12s\tremaining: 333ms\n",
            "973:\tlearn: 0.0216580\ttotal: 12s\tremaining: 321ms\n",
            "974:\tlearn: 0.0216170\ttotal: 12s\tremaining: 309ms\n",
            "975:\tlearn: 0.0215900\ttotal: 12s\tremaining: 296ms\n",
            "976:\tlearn: 0.0215516\ttotal: 12.1s\tremaining: 284ms\n",
            "977:\tlearn: 0.0215056\ttotal: 12.1s\tremaining: 272ms\n",
            "978:\tlearn: 0.0214613\ttotal: 12.1s\tremaining: 260ms\n",
            "979:\tlearn: 0.0214390\ttotal: 12.1s\tremaining: 247ms\n",
            "980:\tlearn: 0.0214212\ttotal: 12.1s\tremaining: 235ms\n",
            "981:\tlearn: 0.0214131\ttotal: 12.2s\tremaining: 223ms\n",
            "982:\tlearn: 0.0213597\ttotal: 12.2s\tremaining: 210ms\n",
            "983:\tlearn: 0.0213379\ttotal: 12.2s\tremaining: 198ms\n",
            "984:\tlearn: 0.0213128\ttotal: 12.2s\tremaining: 186ms\n",
            "985:\tlearn: 0.0212619\ttotal: 12.2s\tremaining: 173ms\n",
            "986:\tlearn: 0.0212395\ttotal: 12.2s\tremaining: 161ms\n",
            "987:\tlearn: 0.0212298\ttotal: 12.2s\tremaining: 149ms\n",
            "988:\tlearn: 0.0211878\ttotal: 12.3s\tremaining: 136ms\n",
            "989:\tlearn: 0.0211584\ttotal: 12.3s\tremaining: 124ms\n",
            "990:\tlearn: 0.0211469\ttotal: 12.3s\tremaining: 112ms\n",
            "991:\tlearn: 0.0211002\ttotal: 12.3s\tremaining: 99.3ms\n",
            "992:\tlearn: 0.0210424\ttotal: 12.3s\tremaining: 86.9ms\n",
            "993:\tlearn: 0.0210138\ttotal: 12.3s\tremaining: 74.5ms\n",
            "994:\tlearn: 0.0209951\ttotal: 12.4s\tremaining: 62.1ms\n",
            "995:\tlearn: 0.0209610\ttotal: 12.4s\tremaining: 49.7ms\n",
            "996:\tlearn: 0.0209318\ttotal: 12.4s\tremaining: 37.3ms\n",
            "997:\tlearn: 0.0208694\ttotal: 12.4s\tremaining: 24.9ms\n",
            "998:\tlearn: 0.0208356\ttotal: 12.4s\tremaining: 12.5ms\n",
            "999:\tlearn: 0.0207930\ttotal: 12.5s\tremaining: 0us\n",
            "Learning rate set to 0.007862\n",
            "0:\tlearn: 0.6830620\ttotal: 22.1ms\tremaining: 22.1s\n",
            "1:\tlearn: 0.6733479\ttotal: 44.2ms\tremaining: 22s\n",
            "2:\tlearn: 0.6623329\ttotal: 60.4ms\tremaining: 20.1s\n",
            "3:\tlearn: 0.6519719\ttotal: 80.7ms\tremaining: 20.1s\n",
            "4:\tlearn: 0.6427934\ttotal: 101ms\tremaining: 20.2s\n",
            "5:\tlearn: 0.6342079\ttotal: 122ms\tremaining: 20.2s\n",
            "6:\tlearn: 0.6243545\ttotal: 143ms\tremaining: 20.2s\n",
            "7:\tlearn: 0.6156490\ttotal: 166ms\tremaining: 20.5s\n",
            "8:\tlearn: 0.6062512\ttotal: 185ms\tremaining: 20.4s\n",
            "9:\tlearn: 0.5975469\ttotal: 204ms\tremaining: 20.2s\n",
            "10:\tlearn: 0.5901612\ttotal: 225ms\tremaining: 20.2s\n",
            "11:\tlearn: 0.5824141\ttotal: 245ms\tremaining: 20.1s\n",
            "12:\tlearn: 0.5742915\ttotal: 259ms\tremaining: 19.7s\n",
            "13:\tlearn: 0.5666301\ttotal: 273ms\tremaining: 19.2s\n",
            "14:\tlearn: 0.5578558\ttotal: 285ms\tremaining: 18.7s\n",
            "15:\tlearn: 0.5494796\ttotal: 300ms\tremaining: 18.5s\n",
            "16:\tlearn: 0.5416837\ttotal: 321ms\tremaining: 18.5s\n",
            "17:\tlearn: 0.5351963\ttotal: 342ms\tremaining: 18.7s\n",
            "18:\tlearn: 0.5277478\ttotal: 364ms\tremaining: 18.8s\n",
            "19:\tlearn: 0.5204449\ttotal: 383ms\tremaining: 18.8s\n",
            "20:\tlearn: 0.5131620\ttotal: 406ms\tremaining: 18.9s\n",
            "21:\tlearn: 0.5065568\ttotal: 428ms\tremaining: 19s\n",
            "22:\tlearn: 0.4995984\ttotal: 448ms\tremaining: 19s\n",
            "23:\tlearn: 0.4920755\ttotal: 469ms\tremaining: 19.1s\n",
            "24:\tlearn: 0.4865212\ttotal: 491ms\tremaining: 19.2s\n",
            "25:\tlearn: 0.4812421\ttotal: 512ms\tremaining: 19.2s\n",
            "26:\tlearn: 0.4742398\ttotal: 532ms\tremaining: 19.2s\n",
            "27:\tlearn: 0.4676590\ttotal: 554ms\tremaining: 19.2s\n",
            "28:\tlearn: 0.4624197\ttotal: 572ms\tremaining: 19.2s\n",
            "29:\tlearn: 0.4573806\ttotal: 593ms\tremaining: 19.2s\n",
            "30:\tlearn: 0.4526692\ttotal: 615ms\tremaining: 19.2s\n",
            "31:\tlearn: 0.4471858\ttotal: 636ms\tremaining: 19.2s\n",
            "32:\tlearn: 0.4415304\ttotal: 656ms\tremaining: 19.2s\n",
            "33:\tlearn: 0.4366371\ttotal: 677ms\tremaining: 19.2s\n",
            "34:\tlearn: 0.4319526\ttotal: 697ms\tremaining: 19.2s\n",
            "35:\tlearn: 0.4263368\ttotal: 718ms\tremaining: 19.2s\n",
            "36:\tlearn: 0.4212782\ttotal: 738ms\tremaining: 19.2s\n",
            "37:\tlearn: 0.4168538\ttotal: 765ms\tremaining: 19.4s\n",
            "38:\tlearn: 0.4125186\ttotal: 782ms\tremaining: 19.3s\n",
            "39:\tlearn: 0.4075865\ttotal: 803ms\tremaining: 19.3s\n",
            "40:\tlearn: 0.4034484\ttotal: 823ms\tremaining: 19.2s\n",
            "41:\tlearn: 0.3983782\ttotal: 844ms\tremaining: 19.2s\n",
            "42:\tlearn: 0.3936705\ttotal: 858ms\tremaining: 19.1s\n",
            "43:\tlearn: 0.3889413\ttotal: 872ms\tremaining: 19s\n",
            "44:\tlearn: 0.3843974\ttotal: 893ms\tremaining: 18.9s\n",
            "45:\tlearn: 0.3794355\ttotal: 909ms\tremaining: 18.8s\n",
            "46:\tlearn: 0.3751056\ttotal: 930ms\tremaining: 18.8s\n",
            "47:\tlearn: 0.3704272\ttotal: 945ms\tremaining: 18.7s\n",
            "48:\tlearn: 0.3657879\ttotal: 965ms\tremaining: 18.7s\n",
            "49:\tlearn: 0.3617274\ttotal: 987ms\tremaining: 18.8s\n",
            "50:\tlearn: 0.3576824\ttotal: 1.01s\tremaining: 18.8s\n",
            "51:\tlearn: 0.3536705\ttotal: 1.03s\tremaining: 18.8s\n",
            "52:\tlearn: 0.3498289\ttotal: 1.05s\tremaining: 18.8s\n",
            "53:\tlearn: 0.3461199\ttotal: 1.07s\tremaining: 18.8s\n",
            "54:\tlearn: 0.3422338\ttotal: 1.09s\tremaining: 18.8s\n",
            "55:\tlearn: 0.3380653\ttotal: 1.13s\tremaining: 19.1s\n",
            "56:\tlearn: 0.3344815\ttotal: 1.17s\tremaining: 19.3s\n",
            "57:\tlearn: 0.3308534\ttotal: 1.18s\tremaining: 19.2s\n",
            "58:\tlearn: 0.3274159\ttotal: 1.2s\tremaining: 19.2s\n",
            "59:\tlearn: 0.3240257\ttotal: 1.22s\tremaining: 19.1s\n",
            "60:\tlearn: 0.3205140\ttotal: 1.25s\tremaining: 19.2s\n",
            "61:\tlearn: 0.3169098\ttotal: 1.27s\tremaining: 19.2s\n",
            "62:\tlearn: 0.3136537\ttotal: 1.3s\tremaining: 19.3s\n",
            "63:\tlearn: 0.3110490\ttotal: 1.32s\tremaining: 19.3s\n",
            "64:\tlearn: 0.3071535\ttotal: 1.35s\tremaining: 19.5s\n",
            "65:\tlearn: 0.3037934\ttotal: 1.38s\tremaining: 19.6s\n",
            "66:\tlearn: 0.3011480\ttotal: 1.4s\tremaining: 19.5s\n",
            "67:\tlearn: 0.2980242\ttotal: 1.41s\tremaining: 19.4s\n",
            "68:\tlearn: 0.2951481\ttotal: 1.44s\tremaining: 19.4s\n",
            "69:\tlearn: 0.2921192\ttotal: 1.47s\tremaining: 19.6s\n",
            "70:\tlearn: 0.2896193\ttotal: 1.5s\tremaining: 19.7s\n",
            "71:\tlearn: 0.2867310\ttotal: 1.53s\tremaining: 19.7s\n",
            "72:\tlearn: 0.2831814\ttotal: 1.55s\tremaining: 19.7s\n",
            "73:\tlearn: 0.2808230\ttotal: 1.59s\tremaining: 19.9s\n",
            "74:\tlearn: 0.2779150\ttotal: 1.63s\tremaining: 20.1s\n",
            "75:\tlearn: 0.2758748\ttotal: 1.65s\tremaining: 20.1s\n",
            "76:\tlearn: 0.2733595\ttotal: 1.69s\tremaining: 20.3s\n",
            "77:\tlearn: 0.2706285\ttotal: 1.72s\tremaining: 20.3s\n",
            "78:\tlearn: 0.2682052\ttotal: 1.77s\tremaining: 20.6s\n",
            "79:\tlearn: 0.2659485\ttotal: 1.8s\tremaining: 20.7s\n",
            "80:\tlearn: 0.2633627\ttotal: 1.83s\tremaining: 20.8s\n",
            "81:\tlearn: 0.2615563\ttotal: 1.85s\tremaining: 20.8s\n",
            "82:\tlearn: 0.2590668\ttotal: 1.9s\tremaining: 21s\n",
            "83:\tlearn: 0.2565378\ttotal: 1.94s\tremaining: 21.2s\n",
            "84:\tlearn: 0.2544253\ttotal: 1.98s\tremaining: 21.3s\n",
            "85:\tlearn: 0.2521039\ttotal: 2.02s\tremaining: 21.5s\n",
            "86:\tlearn: 0.2497961\ttotal: 2.05s\tremaining: 21.5s\n",
            "87:\tlearn: 0.2472880\ttotal: 2.08s\tremaining: 21.6s\n",
            "88:\tlearn: 0.2451303\ttotal: 2.13s\tremaining: 21.8s\n",
            "89:\tlearn: 0.2430727\ttotal: 2.17s\tremaining: 21.9s\n",
            "90:\tlearn: 0.2409675\ttotal: 2.21s\tremaining: 22.1s\n",
            "91:\tlearn: 0.2391120\ttotal: 2.26s\tremaining: 22.4s\n",
            "92:\tlearn: 0.2372195\ttotal: 2.31s\tremaining: 22.6s\n",
            "93:\tlearn: 0.2355117\ttotal: 2.36s\tremaining: 22.7s\n",
            "94:\tlearn: 0.2338331\ttotal: 2.4s\tremaining: 22.8s\n",
            "95:\tlearn: 0.2317283\ttotal: 2.43s\tremaining: 22.9s\n",
            "96:\tlearn: 0.2299987\ttotal: 2.5s\tremaining: 23.3s\n",
            "97:\tlearn: 0.2282652\ttotal: 2.56s\tremaining: 23.5s\n",
            "98:\tlearn: 0.2262969\ttotal: 2.6s\tremaining: 23.7s\n",
            "99:\tlearn: 0.2246495\ttotal: 2.64s\tremaining: 23.8s\n",
            "100:\tlearn: 0.2229976\ttotal: 2.68s\tremaining: 23.9s\n",
            "101:\tlearn: 0.2212096\ttotal: 2.73s\tremaining: 24s\n",
            "102:\tlearn: 0.2198927\ttotal: 2.77s\tremaining: 24.1s\n",
            "103:\tlearn: 0.2183180\ttotal: 2.8s\tremaining: 24.1s\n",
            "104:\tlearn: 0.2171161\ttotal: 2.86s\tremaining: 24.4s\n",
            "105:\tlearn: 0.2156011\ttotal: 2.9s\tremaining: 24.5s\n",
            "106:\tlearn: 0.2141326\ttotal: 2.94s\tremaining: 24.5s\n",
            "107:\tlearn: 0.2127532\ttotal: 2.98s\tremaining: 24.6s\n",
            "108:\tlearn: 0.2111307\ttotal: 3.01s\tremaining: 24.6s\n",
            "109:\tlearn: 0.2094441\ttotal: 3.04s\tremaining: 24.6s\n",
            "110:\tlearn: 0.2079415\ttotal: 3.07s\tremaining: 24.6s\n",
            "111:\tlearn: 0.2066476\ttotal: 3.12s\tremaining: 24.7s\n",
            "112:\tlearn: 0.2052654\ttotal: 3.19s\tremaining: 25s\n",
            "113:\tlearn: 0.2037799\ttotal: 3.25s\tremaining: 25.2s\n",
            "114:\tlearn: 0.2022555\ttotal: 3.28s\tremaining: 25.3s\n",
            "115:\tlearn: 0.2007566\ttotal: 3.32s\tremaining: 25.3s\n",
            "116:\tlearn: 0.1994612\ttotal: 3.37s\tremaining: 25.4s\n",
            "117:\tlearn: 0.1981879\ttotal: 3.43s\tremaining: 25.6s\n",
            "118:\tlearn: 0.1969159\ttotal: 3.47s\tremaining: 25.7s\n",
            "119:\tlearn: 0.1955586\ttotal: 3.51s\tremaining: 25.7s\n",
            "120:\tlearn: 0.1942111\ttotal: 3.55s\tremaining: 25.8s\n",
            "121:\tlearn: 0.1929705\ttotal: 3.58s\tremaining: 25.8s\n",
            "122:\tlearn: 0.1915757\ttotal: 3.63s\tremaining: 25.9s\n",
            "123:\tlearn: 0.1905269\ttotal: 3.66s\tremaining: 25.9s\n",
            "124:\tlearn: 0.1893878\ttotal: 3.7s\tremaining: 25.9s\n",
            "125:\tlearn: 0.1881606\ttotal: 3.75s\tremaining: 26s\n",
            "126:\tlearn: 0.1866899\ttotal: 3.78s\tremaining: 26s\n",
            "127:\tlearn: 0.1855377\ttotal: 3.81s\tremaining: 26s\n",
            "128:\tlearn: 0.1842711\ttotal: 3.86s\tremaining: 26.1s\n",
            "129:\tlearn: 0.1830084\ttotal: 3.89s\tremaining: 26s\n",
            "130:\tlearn: 0.1817805\ttotal: 3.92s\tremaining: 26s\n",
            "131:\tlearn: 0.1805643\ttotal: 3.94s\tremaining: 25.9s\n",
            "132:\tlearn: 0.1794003\ttotal: 3.97s\tremaining: 25.9s\n",
            "133:\tlearn: 0.1782365\ttotal: 4s\tremaining: 25.8s\n",
            "134:\tlearn: 0.1772676\ttotal: 4.03s\tremaining: 25.8s\n",
            "135:\tlearn: 0.1761413\ttotal: 4.05s\tremaining: 25.8s\n",
            "136:\tlearn: 0.1750565\ttotal: 4.09s\tremaining: 25.7s\n",
            "137:\tlearn: 0.1741465\ttotal: 4.1s\tremaining: 25.6s\n",
            "138:\tlearn: 0.1729423\ttotal: 4.12s\tremaining: 25.5s\n",
            "139:\tlearn: 0.1719460\ttotal: 4.13s\tremaining: 25.4s\n",
            "140:\tlearn: 0.1710630\ttotal: 4.15s\tremaining: 25.3s\n",
            "141:\tlearn: 0.1702029\ttotal: 4.16s\tremaining: 25.1s\n",
            "142:\tlearn: 0.1689688\ttotal: 4.17s\tremaining: 25s\n",
            "143:\tlearn: 0.1680922\ttotal: 4.19s\tremaining: 24.9s\n",
            "144:\tlearn: 0.1671579\ttotal: 4.2s\tremaining: 24.8s\n",
            "145:\tlearn: 0.1662346\ttotal: 4.21s\tremaining: 24.7s\n",
            "146:\tlearn: 0.1653983\ttotal: 4.23s\tremaining: 24.5s\n",
            "147:\tlearn: 0.1645731\ttotal: 4.24s\tremaining: 24.4s\n",
            "148:\tlearn: 0.1636172\ttotal: 4.26s\tremaining: 24.4s\n",
            "149:\tlearn: 0.1626911\ttotal: 4.28s\tremaining: 24.3s\n",
            "150:\tlearn: 0.1615927\ttotal: 4.29s\tremaining: 24.1s\n",
            "151:\tlearn: 0.1605225\ttotal: 4.3s\tremaining: 24s\n",
            "152:\tlearn: 0.1595408\ttotal: 4.32s\tremaining: 23.9s\n",
            "153:\tlearn: 0.1587864\ttotal: 4.33s\tremaining: 23.8s\n",
            "154:\tlearn: 0.1578657\ttotal: 4.34s\tremaining: 23.6s\n",
            "155:\tlearn: 0.1568950\ttotal: 4.35s\tremaining: 23.5s\n",
            "156:\tlearn: 0.1562479\ttotal: 4.37s\tremaining: 23.4s\n",
            "157:\tlearn: 0.1555496\ttotal: 4.39s\tremaining: 23.4s\n",
            "158:\tlearn: 0.1547224\ttotal: 4.4s\tremaining: 23.3s\n",
            "159:\tlearn: 0.1539426\ttotal: 4.41s\tremaining: 23.2s\n",
            "160:\tlearn: 0.1531199\ttotal: 4.42s\tremaining: 23.1s\n",
            "161:\tlearn: 0.1522740\ttotal: 4.44s\tremaining: 22.9s\n",
            "162:\tlearn: 0.1514588\ttotal: 4.45s\tremaining: 22.9s\n",
            "163:\tlearn: 0.1505262\ttotal: 4.47s\tremaining: 22.8s\n",
            "164:\tlearn: 0.1496295\ttotal: 4.49s\tremaining: 22.7s\n",
            "165:\tlearn: 0.1489205\ttotal: 4.5s\tremaining: 22.6s\n",
            "166:\tlearn: 0.1481702\ttotal: 4.52s\tremaining: 22.5s\n",
            "167:\tlearn: 0.1472240\ttotal: 4.53s\tremaining: 22.4s\n",
            "168:\tlearn: 0.1465557\ttotal: 4.54s\tremaining: 22.3s\n",
            "169:\tlearn: 0.1456593\ttotal: 4.55s\tremaining: 22.2s\n",
            "170:\tlearn: 0.1447933\ttotal: 4.57s\tremaining: 22.1s\n",
            "171:\tlearn: 0.1441310\ttotal: 4.58s\tremaining: 22s\n",
            "172:\tlearn: 0.1433763\ttotal: 4.59s\tremaining: 22s\n",
            "173:\tlearn: 0.1426712\ttotal: 4.61s\tremaining: 21.9s\n",
            "174:\tlearn: 0.1420644\ttotal: 4.62s\tremaining: 21.8s\n",
            "175:\tlearn: 0.1412179\ttotal: 4.63s\tremaining: 21.7s\n",
            "176:\tlearn: 0.1405074\ttotal: 4.64s\tremaining: 21.6s\n",
            "177:\tlearn: 0.1397648\ttotal: 4.66s\tremaining: 21.5s\n",
            "178:\tlearn: 0.1390330\ttotal: 4.68s\tremaining: 21.4s\n",
            "179:\tlearn: 0.1383358\ttotal: 4.69s\tremaining: 21.4s\n",
            "180:\tlearn: 0.1377045\ttotal: 4.71s\tremaining: 21.3s\n",
            "181:\tlearn: 0.1372065\ttotal: 4.72s\tremaining: 21.2s\n",
            "182:\tlearn: 0.1363695\ttotal: 4.73s\tremaining: 21.1s\n",
            "183:\tlearn: 0.1357138\ttotal: 4.75s\tremaining: 21.1s\n",
            "184:\tlearn: 0.1352027\ttotal: 4.77s\tremaining: 21s\n",
            "185:\tlearn: 0.1346450\ttotal: 4.79s\tremaining: 21s\n",
            "186:\tlearn: 0.1338286\ttotal: 4.8s\tremaining: 20.9s\n",
            "187:\tlearn: 0.1330689\ttotal: 4.82s\tremaining: 20.8s\n",
            "188:\tlearn: 0.1326172\ttotal: 4.83s\tremaining: 20.7s\n",
            "189:\tlearn: 0.1320614\ttotal: 4.84s\tremaining: 20.6s\n",
            "190:\tlearn: 0.1313950\ttotal: 4.85s\tremaining: 20.6s\n",
            "191:\tlearn: 0.1307616\ttotal: 4.87s\tremaining: 20.5s\n",
            "192:\tlearn: 0.1302542\ttotal: 4.89s\tremaining: 20.4s\n",
            "193:\tlearn: 0.1296732\ttotal: 4.9s\tremaining: 20.4s\n",
            "194:\tlearn: 0.1291462\ttotal: 4.92s\tremaining: 20.3s\n",
            "195:\tlearn: 0.1286389\ttotal: 4.93s\tremaining: 20.2s\n",
            "196:\tlearn: 0.1278691\ttotal: 4.95s\tremaining: 20.2s\n",
            "197:\tlearn: 0.1273312\ttotal: 4.96s\tremaining: 20.1s\n",
            "198:\tlearn: 0.1268734\ttotal: 4.97s\tremaining: 20s\n",
            "199:\tlearn: 0.1262470\ttotal: 4.99s\tremaining: 19.9s\n",
            "200:\tlearn: 0.1258568\ttotal: 5s\tremaining: 19.9s\n",
            "201:\tlearn: 0.1252936\ttotal: 5.01s\tremaining: 19.8s\n",
            "202:\tlearn: 0.1246902\ttotal: 5.02s\tremaining: 19.7s\n",
            "203:\tlearn: 0.1241589\ttotal: 5.03s\tremaining: 19.6s\n",
            "204:\tlearn: 0.1234850\ttotal: 5.04s\tremaining: 19.6s\n",
            "205:\tlearn: 0.1230118\ttotal: 5.05s\tremaining: 19.5s\n",
            "206:\tlearn: 0.1225244\ttotal: 5.07s\tremaining: 19.4s\n",
            "207:\tlearn: 0.1219487\ttotal: 5.08s\tremaining: 19.3s\n",
            "208:\tlearn: 0.1214423\ttotal: 5.09s\tremaining: 19.3s\n",
            "209:\tlearn: 0.1209577\ttotal: 5.1s\tremaining: 19.2s\n",
            "210:\tlearn: 0.1204102\ttotal: 5.11s\tremaining: 19.1s\n",
            "211:\tlearn: 0.1199408\ttotal: 5.12s\tremaining: 19s\n",
            "212:\tlearn: 0.1195068\ttotal: 5.14s\tremaining: 19s\n",
            "213:\tlearn: 0.1191085\ttotal: 5.15s\tremaining: 18.9s\n",
            "214:\tlearn: 0.1185346\ttotal: 5.16s\tremaining: 18.8s\n",
            "215:\tlearn: 0.1180079\ttotal: 5.17s\tremaining: 18.8s\n",
            "216:\tlearn: 0.1175355\ttotal: 5.18s\tremaining: 18.7s\n",
            "217:\tlearn: 0.1170949\ttotal: 5.19s\tremaining: 18.6s\n",
            "218:\tlearn: 0.1164922\ttotal: 5.2s\tremaining: 18.5s\n",
            "219:\tlearn: 0.1160509\ttotal: 5.21s\tremaining: 18.5s\n",
            "220:\tlearn: 0.1154986\ttotal: 5.22s\tremaining: 18.4s\n",
            "221:\tlearn: 0.1150142\ttotal: 5.23s\tremaining: 18.3s\n",
            "222:\tlearn: 0.1146590\ttotal: 5.24s\tremaining: 18.3s\n",
            "223:\tlearn: 0.1142613\ttotal: 5.25s\tremaining: 18.2s\n",
            "224:\tlearn: 0.1139226\ttotal: 5.26s\tremaining: 18.1s\n",
            "225:\tlearn: 0.1134754\ttotal: 5.27s\tremaining: 18.1s\n",
            "226:\tlearn: 0.1131022\ttotal: 5.28s\tremaining: 18s\n",
            "227:\tlearn: 0.1126378\ttotal: 5.3s\tremaining: 17.9s\n",
            "228:\tlearn: 0.1122576\ttotal: 5.31s\tremaining: 17.9s\n",
            "229:\tlearn: 0.1117665\ttotal: 5.32s\tremaining: 17.8s\n",
            "230:\tlearn: 0.1113175\ttotal: 5.33s\tremaining: 17.8s\n",
            "231:\tlearn: 0.1107901\ttotal: 5.34s\tremaining: 17.7s\n",
            "232:\tlearn: 0.1102302\ttotal: 5.35s\tremaining: 17.6s\n",
            "233:\tlearn: 0.1099628\ttotal: 5.36s\tremaining: 17.6s\n",
            "234:\tlearn: 0.1094460\ttotal: 5.38s\tremaining: 17.5s\n",
            "235:\tlearn: 0.1090555\ttotal: 5.4s\tremaining: 17.5s\n",
            "236:\tlearn: 0.1085840\ttotal: 5.41s\tremaining: 17.4s\n",
            "237:\tlearn: 0.1081614\ttotal: 5.42s\tremaining: 17.3s\n",
            "238:\tlearn: 0.1077784\ttotal: 5.43s\tremaining: 17.3s\n",
            "239:\tlearn: 0.1073740\ttotal: 5.44s\tremaining: 17.2s\n",
            "240:\tlearn: 0.1069377\ttotal: 5.45s\tremaining: 17.2s\n",
            "241:\tlearn: 0.1064465\ttotal: 5.46s\tremaining: 17.1s\n",
            "242:\tlearn: 0.1061264\ttotal: 5.47s\tremaining: 17s\n",
            "243:\tlearn: 0.1058101\ttotal: 5.48s\tremaining: 17s\n",
            "244:\tlearn: 0.1054393\ttotal: 5.49s\tremaining: 16.9s\n",
            "245:\tlearn: 0.1051122\ttotal: 5.52s\tremaining: 16.9s\n",
            "246:\tlearn: 0.1047164\ttotal: 5.53s\tremaining: 16.8s\n",
            "247:\tlearn: 0.1042215\ttotal: 5.54s\tremaining: 16.8s\n",
            "248:\tlearn: 0.1038692\ttotal: 5.55s\tremaining: 16.7s\n",
            "249:\tlearn: 0.1035259\ttotal: 5.56s\tremaining: 16.7s\n",
            "250:\tlearn: 0.1032023\ttotal: 5.57s\tremaining: 16.6s\n",
            "251:\tlearn: 0.1028764\ttotal: 5.58s\tremaining: 16.6s\n",
            "252:\tlearn: 0.1026122\ttotal: 5.59s\tremaining: 16.5s\n",
            "253:\tlearn: 0.1023161\ttotal: 5.6s\tremaining: 16.4s\n",
            "254:\tlearn: 0.1019604\ttotal: 5.61s\tremaining: 16.4s\n",
            "255:\tlearn: 0.1015358\ttotal: 5.62s\tremaining: 16.3s\n",
            "256:\tlearn: 0.1011967\ttotal: 5.63s\tremaining: 16.3s\n",
            "257:\tlearn: 0.1008992\ttotal: 5.64s\tremaining: 16.2s\n",
            "258:\tlearn: 0.1005728\ttotal: 5.65s\tremaining: 16.2s\n",
            "259:\tlearn: 0.1002440\ttotal: 5.66s\tremaining: 16.1s\n",
            "260:\tlearn: 0.0998906\ttotal: 5.67s\tremaining: 16s\n",
            "261:\tlearn: 0.0993954\ttotal: 5.68s\tremaining: 16s\n",
            "262:\tlearn: 0.0991144\ttotal: 5.69s\tremaining: 15.9s\n",
            "263:\tlearn: 0.0986410\ttotal: 5.7s\tremaining: 15.9s\n",
            "264:\tlearn: 0.0982757\ttotal: 5.71s\tremaining: 15.8s\n",
            "265:\tlearn: 0.0979484\ttotal: 5.73s\tremaining: 15.8s\n",
            "266:\tlearn: 0.0977338\ttotal: 5.74s\tremaining: 15.8s\n",
            "267:\tlearn: 0.0974013\ttotal: 5.75s\tremaining: 15.7s\n",
            "268:\tlearn: 0.0971406\ttotal: 5.76s\tremaining: 15.7s\n",
            "269:\tlearn: 0.0968336\ttotal: 5.78s\tremaining: 15.6s\n",
            "270:\tlearn: 0.0966234\ttotal: 5.79s\tremaining: 15.6s\n",
            "271:\tlearn: 0.0962461\ttotal: 5.8s\tremaining: 15.5s\n",
            "272:\tlearn: 0.0959169\ttotal: 5.81s\tremaining: 15.5s\n",
            "273:\tlearn: 0.0956773\ttotal: 5.82s\tremaining: 15.4s\n",
            "274:\tlearn: 0.0953509\ttotal: 5.83s\tremaining: 15.4s\n",
            "275:\tlearn: 0.0949741\ttotal: 5.84s\tremaining: 15.3s\n",
            "276:\tlearn: 0.0946665\ttotal: 5.85s\tremaining: 15.3s\n",
            "277:\tlearn: 0.0943301\ttotal: 5.86s\tremaining: 15.2s\n",
            "278:\tlearn: 0.0940370\ttotal: 5.87s\tremaining: 15.2s\n",
            "279:\tlearn: 0.0938088\ttotal: 5.88s\tremaining: 15.1s\n",
            "280:\tlearn: 0.0934715\ttotal: 5.89s\tremaining: 15.1s\n",
            "281:\tlearn: 0.0931519\ttotal: 5.9s\tremaining: 15s\n",
            "282:\tlearn: 0.0928532\ttotal: 5.91s\tremaining: 15s\n",
            "283:\tlearn: 0.0925583\ttotal: 5.92s\tremaining: 14.9s\n",
            "284:\tlearn: 0.0923386\ttotal: 5.94s\tremaining: 14.9s\n",
            "285:\tlearn: 0.0920822\ttotal: 5.95s\tremaining: 14.8s\n",
            "286:\tlearn: 0.0917942\ttotal: 5.96s\tremaining: 14.8s\n",
            "287:\tlearn: 0.0915625\ttotal: 5.97s\tremaining: 14.8s\n",
            "288:\tlearn: 0.0912083\ttotal: 5.98s\tremaining: 14.7s\n",
            "289:\tlearn: 0.0910304\ttotal: 5.99s\tremaining: 14.7s\n",
            "290:\tlearn: 0.0907766\ttotal: 6s\tremaining: 14.6s\n",
            "291:\tlearn: 0.0904878\ttotal: 6.01s\tremaining: 14.6s\n",
            "292:\tlearn: 0.0903001\ttotal: 6.03s\tremaining: 14.5s\n",
            "293:\tlearn: 0.0900115\ttotal: 6.04s\tremaining: 14.5s\n",
            "294:\tlearn: 0.0896795\ttotal: 6.04s\tremaining: 14.4s\n",
            "295:\tlearn: 0.0893492\ttotal: 6.06s\tremaining: 14.4s\n",
            "296:\tlearn: 0.0891357\ttotal: 6.07s\tremaining: 14.4s\n",
            "297:\tlearn: 0.0888891\ttotal: 6.08s\tremaining: 14.3s\n",
            "298:\tlearn: 0.0886436\ttotal: 6.09s\tremaining: 14.3s\n",
            "299:\tlearn: 0.0882478\ttotal: 6.1s\tremaining: 14.2s\n",
            "300:\tlearn: 0.0879717\ttotal: 6.11s\tremaining: 14.2s\n",
            "301:\tlearn: 0.0877437\ttotal: 6.12s\tremaining: 14.1s\n",
            "302:\tlearn: 0.0874561\ttotal: 6.13s\tremaining: 14.1s\n",
            "303:\tlearn: 0.0871666\ttotal: 6.15s\tremaining: 14.1s\n",
            "304:\tlearn: 0.0868562\ttotal: 6.16s\tremaining: 14s\n",
            "305:\tlearn: 0.0865365\ttotal: 6.17s\tremaining: 14s\n",
            "306:\tlearn: 0.0862550\ttotal: 6.18s\tremaining: 13.9s\n",
            "307:\tlearn: 0.0860467\ttotal: 6.19s\tremaining: 13.9s\n",
            "308:\tlearn: 0.0858037\ttotal: 6.2s\tremaining: 13.9s\n",
            "309:\tlearn: 0.0855947\ttotal: 6.21s\tremaining: 13.8s\n",
            "310:\tlearn: 0.0853511\ttotal: 6.22s\tremaining: 13.8s\n",
            "311:\tlearn: 0.0850702\ttotal: 6.23s\tremaining: 13.7s\n",
            "312:\tlearn: 0.0847872\ttotal: 6.24s\tremaining: 13.7s\n",
            "313:\tlearn: 0.0845804\ttotal: 6.25s\tremaining: 13.7s\n",
            "314:\tlearn: 0.0843495\ttotal: 6.26s\tremaining: 13.6s\n",
            "315:\tlearn: 0.0840636\ttotal: 6.27s\tremaining: 13.6s\n",
            "316:\tlearn: 0.0838006\ttotal: 6.28s\tremaining: 13.5s\n",
            "317:\tlearn: 0.0835650\ttotal: 6.29s\tremaining: 13.5s\n",
            "318:\tlearn: 0.0832602\ttotal: 6.3s\tremaining: 13.4s\n",
            "319:\tlearn: 0.0829946\ttotal: 6.31s\tremaining: 13.4s\n",
            "320:\tlearn: 0.0827320\ttotal: 6.32s\tremaining: 13.4s\n",
            "321:\tlearn: 0.0825605\ttotal: 6.33s\tremaining: 13.3s\n",
            "322:\tlearn: 0.0822796\ttotal: 6.34s\tremaining: 13.3s\n",
            "323:\tlearn: 0.0820282\ttotal: 6.36s\tremaining: 13.3s\n",
            "324:\tlearn: 0.0817807\ttotal: 6.37s\tremaining: 13.2s\n",
            "325:\tlearn: 0.0815600\ttotal: 6.39s\tremaining: 13.2s\n",
            "326:\tlearn: 0.0813530\ttotal: 6.4s\tremaining: 13.2s\n",
            "327:\tlearn: 0.0810983\ttotal: 6.42s\tremaining: 13.1s\n",
            "328:\tlearn: 0.0809117\ttotal: 6.42s\tremaining: 13.1s\n",
            "329:\tlearn: 0.0807678\ttotal: 6.43s\tremaining: 13.1s\n",
            "330:\tlearn: 0.0804541\ttotal: 6.45s\tremaining: 13s\n",
            "331:\tlearn: 0.0802441\ttotal: 6.46s\tremaining: 13s\n",
            "332:\tlearn: 0.0799499\ttotal: 6.47s\tremaining: 13s\n",
            "333:\tlearn: 0.0796840\ttotal: 6.48s\tremaining: 12.9s\n",
            "334:\tlearn: 0.0794463\ttotal: 6.49s\tremaining: 12.9s\n",
            "335:\tlearn: 0.0792038\ttotal: 6.5s\tremaining: 12.8s\n",
            "336:\tlearn: 0.0789310\ttotal: 6.51s\tremaining: 12.8s\n",
            "337:\tlearn: 0.0786700\ttotal: 6.52s\tremaining: 12.8s\n",
            "338:\tlearn: 0.0784821\ttotal: 6.53s\tremaining: 12.7s\n",
            "339:\tlearn: 0.0783887\ttotal: 6.54s\tremaining: 12.7s\n",
            "340:\tlearn: 0.0781235\ttotal: 6.55s\tremaining: 12.7s\n",
            "341:\tlearn: 0.0778827\ttotal: 6.56s\tremaining: 12.6s\n",
            "342:\tlearn: 0.0776404\ttotal: 6.58s\tremaining: 12.6s\n",
            "343:\tlearn: 0.0773947\ttotal: 6.59s\tremaining: 12.6s\n",
            "344:\tlearn: 0.0771831\ttotal: 6.6s\tremaining: 12.5s\n",
            "345:\tlearn: 0.0769630\ttotal: 6.61s\tremaining: 12.5s\n",
            "346:\tlearn: 0.0767248\ttotal: 6.62s\tremaining: 12.5s\n",
            "347:\tlearn: 0.0764655\ttotal: 6.63s\tremaining: 12.4s\n",
            "348:\tlearn: 0.0762367\ttotal: 6.64s\tremaining: 12.4s\n",
            "349:\tlearn: 0.0760163\ttotal: 6.65s\tremaining: 12.3s\n",
            "350:\tlearn: 0.0758033\ttotal: 6.66s\tremaining: 12.3s\n",
            "351:\tlearn: 0.0756052\ttotal: 6.67s\tremaining: 12.3s\n",
            "352:\tlearn: 0.0754095\ttotal: 6.68s\tremaining: 12.2s\n",
            "353:\tlearn: 0.0752718\ttotal: 6.69s\tremaining: 12.2s\n",
            "354:\tlearn: 0.0750242\ttotal: 6.7s\tremaining: 12.2s\n",
            "355:\tlearn: 0.0748046\ttotal: 6.71s\tremaining: 12.1s\n",
            "356:\tlearn: 0.0746416\ttotal: 6.73s\tremaining: 12.1s\n",
            "357:\tlearn: 0.0744885\ttotal: 6.74s\tremaining: 12.1s\n",
            "358:\tlearn: 0.0742231\ttotal: 6.75s\tremaining: 12s\n",
            "359:\tlearn: 0.0739913\ttotal: 6.76s\tremaining: 12s\n",
            "360:\tlearn: 0.0738245\ttotal: 6.78s\tremaining: 12s\n",
            "361:\tlearn: 0.0736046\ttotal: 6.79s\tremaining: 12s\n",
            "362:\tlearn: 0.0733971\ttotal: 6.8s\tremaining: 11.9s\n",
            "363:\tlearn: 0.0732169\ttotal: 6.81s\tremaining: 11.9s\n",
            "364:\tlearn: 0.0730213\ttotal: 6.82s\tremaining: 11.9s\n",
            "365:\tlearn: 0.0728134\ttotal: 6.83s\tremaining: 11.8s\n",
            "366:\tlearn: 0.0725923\ttotal: 6.84s\tremaining: 11.8s\n",
            "367:\tlearn: 0.0723574\ttotal: 6.85s\tremaining: 11.8s\n",
            "368:\tlearn: 0.0721580\ttotal: 6.86s\tremaining: 11.7s\n",
            "369:\tlearn: 0.0719018\ttotal: 6.87s\tremaining: 11.7s\n",
            "370:\tlearn: 0.0716681\ttotal: 6.88s\tremaining: 11.7s\n",
            "371:\tlearn: 0.0714037\ttotal: 6.89s\tremaining: 11.6s\n",
            "372:\tlearn: 0.0712508\ttotal: 6.9s\tremaining: 11.6s\n",
            "373:\tlearn: 0.0710258\ttotal: 6.91s\tremaining: 11.6s\n",
            "374:\tlearn: 0.0708449\ttotal: 6.92s\tremaining: 11.5s\n",
            "375:\tlearn: 0.0706034\ttotal: 6.93s\tremaining: 11.5s\n",
            "376:\tlearn: 0.0703808\ttotal: 6.94s\tremaining: 11.5s\n",
            "377:\tlearn: 0.0702218\ttotal: 6.95s\tremaining: 11.4s\n",
            "378:\tlearn: 0.0699834\ttotal: 6.96s\tremaining: 11.4s\n",
            "379:\tlearn: 0.0697987\ttotal: 6.97s\tremaining: 11.4s\n",
            "380:\tlearn: 0.0696447\ttotal: 6.99s\tremaining: 11.3s\n",
            "381:\tlearn: 0.0694435\ttotal: 7s\tremaining: 11.3s\n",
            "382:\tlearn: 0.0693159\ttotal: 7s\tremaining: 11.3s\n",
            "383:\tlearn: 0.0691221\ttotal: 7.02s\tremaining: 11.3s\n",
            "384:\tlearn: 0.0689864\ttotal: 7.03s\tremaining: 11.2s\n",
            "385:\tlearn: 0.0688116\ttotal: 7.04s\tremaining: 11.2s\n",
            "386:\tlearn: 0.0686634\ttotal: 7.04s\tremaining: 11.2s\n",
            "387:\tlearn: 0.0685198\ttotal: 7.05s\tremaining: 11.1s\n",
            "388:\tlearn: 0.0683920\ttotal: 7.07s\tremaining: 11.1s\n",
            "389:\tlearn: 0.0682207\ttotal: 7.08s\tremaining: 11.1s\n",
            "390:\tlearn: 0.0680240\ttotal: 7.09s\tremaining: 11s\n",
            "391:\tlearn: 0.0678479\ttotal: 7.11s\tremaining: 11s\n",
            "392:\tlearn: 0.0676356\ttotal: 7.12s\tremaining: 11s\n",
            "393:\tlearn: 0.0674870\ttotal: 7.13s\tremaining: 11s\n",
            "394:\tlearn: 0.0673707\ttotal: 7.14s\tremaining: 10.9s\n",
            "395:\tlearn: 0.0671909\ttotal: 7.15s\tremaining: 10.9s\n",
            "396:\tlearn: 0.0670359\ttotal: 7.16s\tremaining: 10.9s\n",
            "397:\tlearn: 0.0668646\ttotal: 7.17s\tremaining: 10.8s\n",
            "398:\tlearn: 0.0666971\ttotal: 7.18s\tremaining: 10.8s\n",
            "399:\tlearn: 0.0664815\ttotal: 7.2s\tremaining: 10.8s\n",
            "400:\tlearn: 0.0662982\ttotal: 7.21s\tremaining: 10.8s\n",
            "401:\tlearn: 0.0661429\ttotal: 7.22s\tremaining: 10.7s\n",
            "402:\tlearn: 0.0660017\ttotal: 7.23s\tremaining: 10.7s\n",
            "403:\tlearn: 0.0658463\ttotal: 7.24s\tremaining: 10.7s\n",
            "404:\tlearn: 0.0657340\ttotal: 7.25s\tremaining: 10.7s\n",
            "405:\tlearn: 0.0655699\ttotal: 7.26s\tremaining: 10.6s\n",
            "406:\tlearn: 0.0653834\ttotal: 7.27s\tremaining: 10.6s\n",
            "407:\tlearn: 0.0651844\ttotal: 7.28s\tremaining: 10.6s\n",
            "408:\tlearn: 0.0649607\ttotal: 7.29s\tremaining: 10.5s\n",
            "409:\tlearn: 0.0648820\ttotal: 7.3s\tremaining: 10.5s\n",
            "410:\tlearn: 0.0647523\ttotal: 7.31s\tremaining: 10.5s\n",
            "411:\tlearn: 0.0646037\ttotal: 7.32s\tremaining: 10.4s\n",
            "412:\tlearn: 0.0643931\ttotal: 7.33s\tremaining: 10.4s\n",
            "413:\tlearn: 0.0642529\ttotal: 7.35s\tremaining: 10.4s\n",
            "414:\tlearn: 0.0640963\ttotal: 7.36s\tremaining: 10.4s\n",
            "415:\tlearn: 0.0639812\ttotal: 7.37s\tremaining: 10.3s\n",
            "416:\tlearn: 0.0638273\ttotal: 7.38s\tremaining: 10.3s\n",
            "417:\tlearn: 0.0636339\ttotal: 7.4s\tremaining: 10.3s\n",
            "418:\tlearn: 0.0634833\ttotal: 7.42s\tremaining: 10.3s\n",
            "419:\tlearn: 0.0633054\ttotal: 7.43s\tremaining: 10.3s\n",
            "420:\tlearn: 0.0631384\ttotal: 7.44s\tremaining: 10.2s\n",
            "421:\tlearn: 0.0629521\ttotal: 7.45s\tremaining: 10.2s\n",
            "422:\tlearn: 0.0627628\ttotal: 7.46s\tremaining: 10.2s\n",
            "423:\tlearn: 0.0625896\ttotal: 7.47s\tremaining: 10.2s\n",
            "424:\tlearn: 0.0624681\ttotal: 7.48s\tremaining: 10.1s\n",
            "425:\tlearn: 0.0623332\ttotal: 7.49s\tremaining: 10.1s\n",
            "426:\tlearn: 0.0622031\ttotal: 7.5s\tremaining: 10.1s\n",
            "427:\tlearn: 0.0620378\ttotal: 7.51s\tremaining: 10s\n",
            "428:\tlearn: 0.0619120\ttotal: 7.52s\tremaining: 10s\n",
            "429:\tlearn: 0.0616680\ttotal: 7.54s\tremaining: 9.99s\n",
            "430:\tlearn: 0.0615905\ttotal: 7.54s\tremaining: 9.96s\n",
            "431:\tlearn: 0.0614688\ttotal: 7.55s\tremaining: 9.93s\n",
            "432:\tlearn: 0.0613483\ttotal: 7.57s\tremaining: 9.91s\n",
            "433:\tlearn: 0.0612613\ttotal: 7.58s\tremaining: 9.88s\n",
            "434:\tlearn: 0.0611195\ttotal: 7.58s\tremaining: 9.85s\n",
            "435:\tlearn: 0.0609911\ttotal: 7.59s\tremaining: 9.82s\n",
            "436:\tlearn: 0.0607767\ttotal: 7.62s\tremaining: 9.81s\n",
            "437:\tlearn: 0.0605556\ttotal: 7.63s\tremaining: 9.79s\n",
            "438:\tlearn: 0.0604682\ttotal: 7.64s\tremaining: 9.76s\n",
            "439:\tlearn: 0.0603490\ttotal: 7.65s\tremaining: 9.73s\n",
            "440:\tlearn: 0.0601786\ttotal: 7.66s\tremaining: 9.71s\n",
            "441:\tlearn: 0.0600309\ttotal: 7.67s\tremaining: 9.68s\n",
            "442:\tlearn: 0.0598904\ttotal: 7.68s\tremaining: 9.65s\n",
            "443:\tlearn: 0.0597045\ttotal: 7.69s\tremaining: 9.63s\n",
            "444:\tlearn: 0.0595776\ttotal: 7.71s\tremaining: 9.61s\n",
            "445:\tlearn: 0.0594252\ttotal: 7.72s\tremaining: 9.59s\n",
            "446:\tlearn: 0.0592529\ttotal: 7.73s\tremaining: 9.56s\n",
            "447:\tlearn: 0.0590420\ttotal: 7.74s\tremaining: 9.54s\n",
            "448:\tlearn: 0.0589467\ttotal: 7.75s\tremaining: 9.51s\n",
            "449:\tlearn: 0.0587813\ttotal: 7.76s\tremaining: 9.48s\n",
            "450:\tlearn: 0.0586359\ttotal: 7.77s\tremaining: 9.46s\n",
            "451:\tlearn: 0.0584512\ttotal: 7.78s\tremaining: 9.43s\n",
            "452:\tlearn: 0.0583477\ttotal: 7.79s\tremaining: 9.41s\n",
            "453:\tlearn: 0.0582113\ttotal: 7.8s\tremaining: 9.38s\n",
            "454:\tlearn: 0.0580461\ttotal: 7.81s\tremaining: 9.36s\n",
            "455:\tlearn: 0.0578972\ttotal: 7.83s\tremaining: 9.34s\n",
            "456:\tlearn: 0.0578171\ttotal: 7.84s\tremaining: 9.32s\n",
            "457:\tlearn: 0.0577072\ttotal: 7.85s\tremaining: 9.29s\n",
            "458:\tlearn: 0.0575880\ttotal: 7.86s\tremaining: 9.27s\n",
            "459:\tlearn: 0.0574399\ttotal: 7.87s\tremaining: 9.24s\n",
            "460:\tlearn: 0.0572903\ttotal: 7.88s\tremaining: 9.22s\n",
            "461:\tlearn: 0.0571485\ttotal: 7.89s\tremaining: 9.19s\n",
            "462:\tlearn: 0.0569277\ttotal: 7.9s\tremaining: 9.17s\n",
            "463:\tlearn: 0.0567614\ttotal: 7.91s\tremaining: 9.14s\n",
            "464:\tlearn: 0.0566653\ttotal: 7.92s\tremaining: 9.12s\n",
            "465:\tlearn: 0.0565377\ttotal: 7.93s\tremaining: 9.09s\n",
            "466:\tlearn: 0.0563784\ttotal: 7.94s\tremaining: 9.07s\n",
            "467:\tlearn: 0.0562303\ttotal: 7.95s\tremaining: 9.04s\n",
            "468:\tlearn: 0.0560823\ttotal: 7.96s\tremaining: 9.02s\n",
            "469:\tlearn: 0.0559210\ttotal: 7.97s\tremaining: 8.99s\n",
            "470:\tlearn: 0.0557706\ttotal: 7.98s\tremaining: 8.97s\n",
            "471:\tlearn: 0.0557001\ttotal: 8s\tremaining: 8.94s\n",
            "472:\tlearn: 0.0555678\ttotal: 8.01s\tremaining: 8.92s\n",
            "473:\tlearn: 0.0553715\ttotal: 8.02s\tremaining: 8.9s\n",
            "474:\tlearn: 0.0552572\ttotal: 8.03s\tremaining: 8.88s\n",
            "475:\tlearn: 0.0551177\ttotal: 8.04s\tremaining: 8.85s\n",
            "476:\tlearn: 0.0550008\ttotal: 8.05s\tremaining: 8.83s\n",
            "477:\tlearn: 0.0548690\ttotal: 8.06s\tremaining: 8.8s\n",
            "478:\tlearn: 0.0547502\ttotal: 8.07s\tremaining: 8.78s\n",
            "479:\tlearn: 0.0546292\ttotal: 8.08s\tremaining: 8.76s\n",
            "480:\tlearn: 0.0545050\ttotal: 8.1s\tremaining: 8.73s\n",
            "481:\tlearn: 0.0543036\ttotal: 8.11s\tremaining: 8.71s\n",
            "482:\tlearn: 0.0542290\ttotal: 8.12s\tremaining: 8.69s\n",
            "483:\tlearn: 0.0541255\ttotal: 8.13s\tremaining: 8.66s\n",
            "484:\tlearn: 0.0540213\ttotal: 8.13s\tremaining: 8.64s\n",
            "485:\tlearn: 0.0538616\ttotal: 8.14s\tremaining: 8.61s\n",
            "486:\tlearn: 0.0536878\ttotal: 8.16s\tremaining: 8.59s\n",
            "487:\tlearn: 0.0535857\ttotal: 8.17s\tremaining: 8.57s\n",
            "488:\tlearn: 0.0534542\ttotal: 8.18s\tremaining: 8.55s\n",
            "489:\tlearn: 0.0533300\ttotal: 8.19s\tremaining: 8.53s\n",
            "490:\tlearn: 0.0532333\ttotal: 8.2s\tremaining: 8.5s\n",
            "491:\tlearn: 0.0531054\ttotal: 8.21s\tremaining: 8.48s\n",
            "492:\tlearn: 0.0529668\ttotal: 8.23s\tremaining: 8.46s\n",
            "493:\tlearn: 0.0528345\ttotal: 8.24s\tremaining: 8.44s\n",
            "494:\tlearn: 0.0527363\ttotal: 8.25s\tremaining: 8.42s\n",
            "495:\tlearn: 0.0526481\ttotal: 8.26s\tremaining: 8.39s\n",
            "496:\tlearn: 0.0525705\ttotal: 8.27s\tremaining: 8.37s\n",
            "497:\tlearn: 0.0524465\ttotal: 8.28s\tremaining: 8.35s\n",
            "498:\tlearn: 0.0523558\ttotal: 8.29s\tremaining: 8.32s\n",
            "499:\tlearn: 0.0521921\ttotal: 8.3s\tremaining: 8.3s\n",
            "500:\tlearn: 0.0520793\ttotal: 8.31s\tremaining: 8.28s\n",
            "501:\tlearn: 0.0519284\ttotal: 8.32s\tremaining: 8.26s\n",
            "502:\tlearn: 0.0517820\ttotal: 8.33s\tremaining: 8.23s\n",
            "503:\tlearn: 0.0516720\ttotal: 8.34s\tremaining: 8.21s\n",
            "504:\tlearn: 0.0515684\ttotal: 8.36s\tremaining: 8.19s\n",
            "505:\tlearn: 0.0514664\ttotal: 8.37s\tremaining: 8.17s\n",
            "506:\tlearn: 0.0513284\ttotal: 8.38s\tremaining: 8.15s\n",
            "507:\tlearn: 0.0511501\ttotal: 8.39s\tremaining: 8.12s\n",
            "508:\tlearn: 0.0509938\ttotal: 8.4s\tremaining: 8.11s\n",
            "509:\tlearn: 0.0508643\ttotal: 8.43s\tremaining: 8.1s\n",
            "510:\tlearn: 0.0507604\ttotal: 8.45s\tremaining: 8.08s\n",
            "511:\tlearn: 0.0506485\ttotal: 8.46s\tremaining: 8.06s\n",
            "512:\tlearn: 0.0505567\ttotal: 8.47s\tremaining: 8.04s\n",
            "513:\tlearn: 0.0504118\ttotal: 8.48s\tremaining: 8.02s\n",
            "514:\tlearn: 0.0502073\ttotal: 8.49s\tremaining: 8s\n",
            "515:\tlearn: 0.0500949\ttotal: 8.5s\tremaining: 7.97s\n",
            "516:\tlearn: 0.0499728\ttotal: 8.51s\tremaining: 7.95s\n",
            "517:\tlearn: 0.0498931\ttotal: 8.52s\tremaining: 7.93s\n",
            "518:\tlearn: 0.0497691\ttotal: 8.53s\tremaining: 7.91s\n",
            "519:\tlearn: 0.0496105\ttotal: 8.54s\tremaining: 7.88s\n",
            "520:\tlearn: 0.0495531\ttotal: 8.55s\tremaining: 7.86s\n",
            "521:\tlearn: 0.0494491\ttotal: 8.56s\tremaining: 7.84s\n",
            "522:\tlearn: 0.0493738\ttotal: 8.57s\tremaining: 7.82s\n",
            "523:\tlearn: 0.0493092\ttotal: 8.58s\tremaining: 7.8s\n",
            "524:\tlearn: 0.0492161\ttotal: 8.59s\tremaining: 7.78s\n",
            "525:\tlearn: 0.0491495\ttotal: 8.6s\tremaining: 7.75s\n",
            "526:\tlearn: 0.0490841\ttotal: 8.62s\tremaining: 7.73s\n",
            "527:\tlearn: 0.0489251\ttotal: 8.63s\tremaining: 7.71s\n",
            "528:\tlearn: 0.0488539\ttotal: 8.64s\tremaining: 7.7s\n",
            "529:\tlearn: 0.0487247\ttotal: 8.66s\tremaining: 7.68s\n",
            "530:\tlearn: 0.0486227\ttotal: 8.67s\tremaining: 7.66s\n",
            "531:\tlearn: 0.0485352\ttotal: 8.68s\tremaining: 7.64s\n",
            "532:\tlearn: 0.0484841\ttotal: 8.69s\tremaining: 7.62s\n",
            "533:\tlearn: 0.0483857\ttotal: 8.7s\tremaining: 7.59s\n",
            "534:\tlearn: 0.0482795\ttotal: 8.71s\tremaining: 7.57s\n",
            "535:\tlearn: 0.0481849\ttotal: 8.72s\tremaining: 7.55s\n",
            "536:\tlearn: 0.0480872\ttotal: 8.73s\tremaining: 7.53s\n",
            "537:\tlearn: 0.0480214\ttotal: 8.74s\tremaining: 7.51s\n",
            "538:\tlearn: 0.0479566\ttotal: 8.76s\tremaining: 7.49s\n",
            "539:\tlearn: 0.0478384\ttotal: 8.77s\tremaining: 7.47s\n",
            "540:\tlearn: 0.0477449\ttotal: 8.78s\tremaining: 7.45s\n",
            "541:\tlearn: 0.0476524\ttotal: 8.79s\tremaining: 7.42s\n",
            "542:\tlearn: 0.0475509\ttotal: 8.8s\tremaining: 7.4s\n",
            "543:\tlearn: 0.0474700\ttotal: 8.81s\tremaining: 7.38s\n",
            "544:\tlearn: 0.0473888\ttotal: 8.82s\tremaining: 7.36s\n",
            "545:\tlearn: 0.0472955\ttotal: 8.83s\tremaining: 7.34s\n",
            "546:\tlearn: 0.0471819\ttotal: 8.84s\tremaining: 7.32s\n",
            "547:\tlearn: 0.0470877\ttotal: 8.86s\tremaining: 7.31s\n",
            "548:\tlearn: 0.0470285\ttotal: 8.87s\tremaining: 7.29s\n",
            "549:\tlearn: 0.0469457\ttotal: 8.88s\tremaining: 7.27s\n",
            "550:\tlearn: 0.0468672\ttotal: 8.89s\tremaining: 7.25s\n",
            "551:\tlearn: 0.0467742\ttotal: 8.9s\tremaining: 7.23s\n",
            "552:\tlearn: 0.0466807\ttotal: 8.91s\tremaining: 7.21s\n",
            "553:\tlearn: 0.0466038\ttotal: 8.93s\tremaining: 7.19s\n",
            "554:\tlearn: 0.0465303\ttotal: 8.94s\tremaining: 7.17s\n",
            "555:\tlearn: 0.0464252\ttotal: 8.95s\tremaining: 7.14s\n",
            "556:\tlearn: 0.0463031\ttotal: 8.96s\tremaining: 7.12s\n",
            "557:\tlearn: 0.0462243\ttotal: 8.97s\tremaining: 7.1s\n",
            "558:\tlearn: 0.0460754\ttotal: 8.98s\tremaining: 7.08s\n",
            "559:\tlearn: 0.0459012\ttotal: 8.99s\tremaining: 7.06s\n",
            "560:\tlearn: 0.0457620\ttotal: 9s\tremaining: 7.04s\n",
            "561:\tlearn: 0.0456801\ttotal: 9.01s\tremaining: 7.02s\n",
            "562:\tlearn: 0.0455616\ttotal: 9.02s\tremaining: 7s\n",
            "563:\tlearn: 0.0454742\ttotal: 9.03s\tremaining: 6.98s\n",
            "564:\tlearn: 0.0453907\ttotal: 9.05s\tremaining: 6.96s\n",
            "565:\tlearn: 0.0453459\ttotal: 9.06s\tremaining: 6.95s\n",
            "566:\tlearn: 0.0452086\ttotal: 9.07s\tremaining: 6.92s\n",
            "567:\tlearn: 0.0451285\ttotal: 9.08s\tremaining: 6.9s\n",
            "568:\tlearn: 0.0450049\ttotal: 9.09s\tremaining: 6.88s\n",
            "569:\tlearn: 0.0448970\ttotal: 9.1s\tremaining: 6.86s\n",
            "570:\tlearn: 0.0448075\ttotal: 9.11s\tremaining: 6.84s\n",
            "571:\tlearn: 0.0447366\ttotal: 9.12s\tremaining: 6.82s\n",
            "572:\tlearn: 0.0446345\ttotal: 9.13s\tremaining: 6.8s\n",
            "573:\tlearn: 0.0445094\ttotal: 9.14s\tremaining: 6.78s\n",
            "574:\tlearn: 0.0443984\ttotal: 9.15s\tremaining: 6.76s\n",
            "575:\tlearn: 0.0443564\ttotal: 9.16s\tremaining: 6.74s\n",
            "576:\tlearn: 0.0442354\ttotal: 9.17s\tremaining: 6.72s\n",
            "577:\tlearn: 0.0441453\ttotal: 9.18s\tremaining: 6.7s\n",
            "578:\tlearn: 0.0440591\ttotal: 9.19s\tremaining: 6.68s\n",
            "579:\tlearn: 0.0439465\ttotal: 9.2s\tremaining: 6.66s\n",
            "580:\tlearn: 0.0438438\ttotal: 9.21s\tremaining: 6.64s\n",
            "581:\tlearn: 0.0437700\ttotal: 9.22s\tremaining: 6.62s\n",
            "582:\tlearn: 0.0436722\ttotal: 9.23s\tremaining: 6.6s\n",
            "583:\tlearn: 0.0435835\ttotal: 9.25s\tremaining: 6.59s\n",
            "584:\tlearn: 0.0435103\ttotal: 9.26s\tremaining: 6.57s\n",
            "585:\tlearn: 0.0433917\ttotal: 9.28s\tremaining: 6.55s\n",
            "586:\tlearn: 0.0433088\ttotal: 9.29s\tremaining: 6.53s\n",
            "587:\tlearn: 0.0432144\ttotal: 9.3s\tremaining: 6.51s\n",
            "588:\tlearn: 0.0431131\ttotal: 9.31s\tremaining: 6.49s\n",
            "589:\tlearn: 0.0430150\ttotal: 9.32s\tremaining: 6.47s\n",
            "590:\tlearn: 0.0429085\ttotal: 9.33s\tremaining: 6.45s\n",
            "591:\tlearn: 0.0428127\ttotal: 9.34s\tremaining: 6.43s\n",
            "592:\tlearn: 0.0427102\ttotal: 9.35s\tremaining: 6.42s\n",
            "593:\tlearn: 0.0426002\ttotal: 9.36s\tremaining: 6.39s\n",
            "594:\tlearn: 0.0424932\ttotal: 9.37s\tremaining: 6.38s\n",
            "595:\tlearn: 0.0424261\ttotal: 9.38s\tremaining: 6.36s\n",
            "596:\tlearn: 0.0423373\ttotal: 9.39s\tremaining: 6.34s\n",
            "597:\tlearn: 0.0422238\ttotal: 9.4s\tremaining: 6.32s\n",
            "598:\tlearn: 0.0421212\ttotal: 9.42s\tremaining: 6.31s\n",
            "599:\tlearn: 0.0420085\ttotal: 9.44s\tremaining: 6.29s\n",
            "600:\tlearn: 0.0419492\ttotal: 9.45s\tremaining: 6.27s\n",
            "601:\tlearn: 0.0419027\ttotal: 9.46s\tremaining: 6.26s\n",
            "602:\tlearn: 0.0418224\ttotal: 9.48s\tremaining: 6.24s\n",
            "603:\tlearn: 0.0417404\ttotal: 9.49s\tremaining: 6.22s\n",
            "604:\tlearn: 0.0416727\ttotal: 9.5s\tremaining: 6.2s\n",
            "605:\tlearn: 0.0416024\ttotal: 9.51s\tremaining: 6.18s\n",
            "606:\tlearn: 0.0415322\ttotal: 9.52s\tremaining: 6.17s\n",
            "607:\tlearn: 0.0414586\ttotal: 9.53s\tremaining: 6.15s\n",
            "608:\tlearn: 0.0413994\ttotal: 9.54s\tremaining: 6.13s\n",
            "609:\tlearn: 0.0413543\ttotal: 9.55s\tremaining: 6.11s\n",
            "610:\tlearn: 0.0412627\ttotal: 9.56s\tremaining: 6.09s\n",
            "611:\tlearn: 0.0411553\ttotal: 9.57s\tremaining: 6.07s\n",
            "612:\tlearn: 0.0410658\ttotal: 9.59s\tremaining: 6.05s\n",
            "613:\tlearn: 0.0410215\ttotal: 9.6s\tremaining: 6.03s\n",
            "614:\tlearn: 0.0409388\ttotal: 9.61s\tremaining: 6.01s\n",
            "615:\tlearn: 0.0408855\ttotal: 9.62s\tremaining: 5.99s\n",
            "616:\tlearn: 0.0408456\ttotal: 9.63s\tremaining: 5.97s\n",
            "617:\tlearn: 0.0408006\ttotal: 9.64s\tremaining: 5.96s\n",
            "618:\tlearn: 0.0407206\ttotal: 9.65s\tremaining: 5.94s\n",
            "619:\tlearn: 0.0406385\ttotal: 9.66s\tremaining: 5.92s\n",
            "620:\tlearn: 0.0405756\ttotal: 9.68s\tremaining: 5.91s\n",
            "621:\tlearn: 0.0404734\ttotal: 9.69s\tremaining: 5.89s\n",
            "622:\tlearn: 0.0404088\ttotal: 9.7s\tremaining: 5.87s\n",
            "623:\tlearn: 0.0403096\ttotal: 9.71s\tremaining: 5.85s\n",
            "624:\tlearn: 0.0402361\ttotal: 9.72s\tremaining: 5.83s\n",
            "625:\tlearn: 0.0401509\ttotal: 9.73s\tremaining: 5.81s\n",
            "626:\tlearn: 0.0401181\ttotal: 9.74s\tremaining: 5.8s\n",
            "627:\tlearn: 0.0400810\ttotal: 9.75s\tremaining: 5.78s\n",
            "628:\tlearn: 0.0400112\ttotal: 9.76s\tremaining: 5.76s\n",
            "629:\tlearn: 0.0399177\ttotal: 9.77s\tremaining: 5.74s\n",
            "630:\tlearn: 0.0398176\ttotal: 9.78s\tremaining: 5.72s\n",
            "631:\tlearn: 0.0397196\ttotal: 9.79s\tremaining: 5.7s\n",
            "632:\tlearn: 0.0396497\ttotal: 9.8s\tremaining: 5.68s\n",
            "633:\tlearn: 0.0395629\ttotal: 9.82s\tremaining: 5.67s\n",
            "634:\tlearn: 0.0395084\ttotal: 9.83s\tremaining: 5.65s\n",
            "635:\tlearn: 0.0394367\ttotal: 9.84s\tremaining: 5.63s\n",
            "636:\tlearn: 0.0393850\ttotal: 9.86s\tremaining: 5.62s\n",
            "637:\tlearn: 0.0393120\ttotal: 9.88s\tremaining: 5.61s\n",
            "638:\tlearn: 0.0392436\ttotal: 9.9s\tremaining: 5.59s\n",
            "639:\tlearn: 0.0391868\ttotal: 9.91s\tremaining: 5.58s\n",
            "640:\tlearn: 0.0391059\ttotal: 9.93s\tremaining: 5.56s\n",
            "641:\tlearn: 0.0390268\ttotal: 9.95s\tremaining: 5.54s\n",
            "642:\tlearn: 0.0389150\ttotal: 9.96s\tremaining: 5.53s\n",
            "643:\tlearn: 0.0388368\ttotal: 9.97s\tremaining: 5.51s\n",
            "644:\tlearn: 0.0387758\ttotal: 9.98s\tremaining: 5.49s\n",
            "645:\tlearn: 0.0387197\ttotal: 9.99s\tremaining: 5.47s\n",
            "646:\tlearn: 0.0386231\ttotal: 10s\tremaining: 5.46s\n",
            "647:\tlearn: 0.0385406\ttotal: 10s\tremaining: 5.44s\n",
            "648:\tlearn: 0.0384782\ttotal: 10s\tremaining: 5.42s\n",
            "649:\tlearn: 0.0383833\ttotal: 10s\tremaining: 5.4s\n",
            "650:\tlearn: 0.0382948\ttotal: 10s\tremaining: 5.38s\n",
            "651:\tlearn: 0.0382314\ttotal: 10.1s\tremaining: 5.36s\n",
            "652:\tlearn: 0.0381381\ttotal: 10.1s\tremaining: 5.35s\n",
            "653:\tlearn: 0.0380896\ttotal: 10.1s\tremaining: 5.33s\n",
            "654:\tlearn: 0.0379979\ttotal: 10.1s\tremaining: 5.31s\n",
            "655:\tlearn: 0.0379396\ttotal: 10.1s\tremaining: 5.29s\n",
            "656:\tlearn: 0.0378875\ttotal: 10.1s\tremaining: 5.28s\n",
            "657:\tlearn: 0.0378000\ttotal: 10.1s\tremaining: 5.26s\n",
            "658:\tlearn: 0.0377361\ttotal: 10.1s\tremaining: 5.24s\n",
            "659:\tlearn: 0.0377018\ttotal: 10.1s\tremaining: 5.23s\n",
            "660:\tlearn: 0.0375842\ttotal: 10.2s\tremaining: 5.21s\n",
            "661:\tlearn: 0.0375161\ttotal: 10.2s\tremaining: 5.19s\n",
            "662:\tlearn: 0.0374599\ttotal: 10.2s\tremaining: 5.17s\n",
            "663:\tlearn: 0.0374273\ttotal: 10.2s\tremaining: 5.16s\n",
            "664:\tlearn: 0.0373708\ttotal: 10.2s\tremaining: 5.14s\n",
            "665:\tlearn: 0.0372840\ttotal: 10.2s\tremaining: 5.12s\n",
            "666:\tlearn: 0.0372179\ttotal: 10.2s\tremaining: 5.1s\n",
            "667:\tlearn: 0.0371365\ttotal: 10.2s\tremaining: 5.08s\n",
            "668:\tlearn: 0.0370840\ttotal: 10.2s\tremaining: 5.07s\n",
            "669:\tlearn: 0.0370129\ttotal: 10.2s\tremaining: 5.05s\n",
            "670:\tlearn: 0.0369359\ttotal: 10.3s\tremaining: 5.03s\n",
            "671:\tlearn: 0.0368766\ttotal: 10.3s\tremaining: 5.01s\n",
            "672:\tlearn: 0.0368107\ttotal: 10.3s\tremaining: 4.99s\n",
            "673:\tlearn: 0.0367622\ttotal: 10.3s\tremaining: 4.98s\n",
            "674:\tlearn: 0.0366892\ttotal: 10.3s\tremaining: 4.96s\n",
            "675:\tlearn: 0.0365702\ttotal: 10.3s\tremaining: 4.94s\n",
            "676:\tlearn: 0.0364912\ttotal: 10.3s\tremaining: 4.93s\n",
            "677:\tlearn: 0.0364521\ttotal: 10.3s\tremaining: 4.91s\n",
            "678:\tlearn: 0.0363793\ttotal: 10.3s\tremaining: 4.89s\n",
            "679:\tlearn: 0.0362916\ttotal: 10.4s\tremaining: 4.87s\n",
            "680:\tlearn: 0.0362389\ttotal: 10.4s\tremaining: 4.86s\n",
            "681:\tlearn: 0.0362022\ttotal: 10.4s\tremaining: 4.84s\n",
            "682:\tlearn: 0.0361161\ttotal: 10.4s\tremaining: 4.82s\n",
            "683:\tlearn: 0.0360775\ttotal: 10.4s\tremaining: 4.8s\n",
            "684:\tlearn: 0.0360066\ttotal: 10.4s\tremaining: 4.79s\n",
            "685:\tlearn: 0.0359422\ttotal: 10.4s\tremaining: 4.78s\n",
            "686:\tlearn: 0.0358998\ttotal: 10.4s\tremaining: 4.76s\n",
            "687:\tlearn: 0.0358169\ttotal: 10.5s\tremaining: 4.74s\n",
            "688:\tlearn: 0.0357275\ttotal: 10.5s\tremaining: 4.73s\n",
            "689:\tlearn: 0.0356702\ttotal: 10.5s\tremaining: 4.71s\n",
            "690:\tlearn: 0.0356083\ttotal: 10.5s\tremaining: 4.69s\n",
            "691:\tlearn: 0.0355060\ttotal: 10.5s\tremaining: 4.68s\n",
            "692:\tlearn: 0.0354375\ttotal: 10.5s\tremaining: 4.66s\n",
            "693:\tlearn: 0.0353742\ttotal: 10.5s\tremaining: 4.64s\n",
            "694:\tlearn: 0.0352944\ttotal: 10.5s\tremaining: 4.63s\n",
            "695:\tlearn: 0.0352403\ttotal: 10.6s\tremaining: 4.61s\n",
            "696:\tlearn: 0.0351720\ttotal: 10.6s\tremaining: 4.59s\n",
            "697:\tlearn: 0.0350611\ttotal: 10.6s\tremaining: 4.57s\n",
            "698:\tlearn: 0.0349941\ttotal: 10.6s\tremaining: 4.56s\n",
            "699:\tlearn: 0.0349533\ttotal: 10.6s\tremaining: 4.54s\n",
            "700:\tlearn: 0.0348768\ttotal: 10.6s\tremaining: 4.52s\n",
            "701:\tlearn: 0.0348268\ttotal: 10.6s\tremaining: 4.51s\n",
            "702:\tlearn: 0.0347641\ttotal: 10.6s\tremaining: 4.49s\n",
            "703:\tlearn: 0.0347053\ttotal: 10.6s\tremaining: 4.47s\n",
            "704:\tlearn: 0.0346329\ttotal: 10.7s\tremaining: 4.46s\n",
            "705:\tlearn: 0.0345520\ttotal: 10.7s\tremaining: 4.44s\n",
            "706:\tlearn: 0.0344895\ttotal: 10.7s\tremaining: 4.42s\n",
            "707:\tlearn: 0.0344467\ttotal: 10.7s\tremaining: 4.41s\n",
            "708:\tlearn: 0.0343782\ttotal: 10.7s\tremaining: 4.39s\n",
            "709:\tlearn: 0.0342819\ttotal: 10.7s\tremaining: 4.37s\n",
            "710:\tlearn: 0.0342206\ttotal: 10.7s\tremaining: 4.36s\n",
            "711:\tlearn: 0.0341528\ttotal: 10.7s\tremaining: 4.34s\n",
            "712:\tlearn: 0.0340557\ttotal: 10.7s\tremaining: 4.33s\n",
            "713:\tlearn: 0.0340207\ttotal: 10.8s\tremaining: 4.31s\n",
            "714:\tlearn: 0.0339435\ttotal: 10.8s\tremaining: 4.29s\n",
            "715:\tlearn: 0.0338998\ttotal: 10.8s\tremaining: 4.27s\n",
            "716:\tlearn: 0.0338526\ttotal: 10.8s\tremaining: 4.26s\n",
            "717:\tlearn: 0.0337529\ttotal: 10.8s\tremaining: 4.24s\n",
            "718:\tlearn: 0.0337028\ttotal: 10.8s\tremaining: 4.22s\n",
            "719:\tlearn: 0.0336276\ttotal: 10.8s\tremaining: 4.21s\n",
            "720:\tlearn: 0.0335823\ttotal: 10.8s\tremaining: 4.19s\n",
            "721:\tlearn: 0.0334882\ttotal: 10.8s\tremaining: 4.17s\n",
            "722:\tlearn: 0.0334092\ttotal: 10.8s\tremaining: 4.16s\n",
            "723:\tlearn: 0.0333190\ttotal: 10.9s\tremaining: 4.14s\n",
            "724:\tlearn: 0.0332618\ttotal: 10.9s\tremaining: 4.12s\n",
            "725:\tlearn: 0.0331800\ttotal: 10.9s\tremaining: 4.11s\n",
            "726:\tlearn: 0.0331153\ttotal: 10.9s\tremaining: 4.09s\n",
            "727:\tlearn: 0.0330237\ttotal: 10.9s\tremaining: 4.07s\n",
            "728:\tlearn: 0.0329716\ttotal: 10.9s\tremaining: 4.05s\n",
            "729:\tlearn: 0.0328666\ttotal: 10.9s\tremaining: 4.04s\n",
            "730:\tlearn: 0.0328031\ttotal: 10.9s\tremaining: 4.02s\n",
            "731:\tlearn: 0.0327480\ttotal: 10.9s\tremaining: 4.01s\n",
            "732:\tlearn: 0.0326584\ttotal: 11s\tremaining: 3.99s\n",
            "733:\tlearn: 0.0325965\ttotal: 11s\tremaining: 3.97s\n",
            "734:\tlearn: 0.0325480\ttotal: 11s\tremaining: 3.96s\n",
            "735:\tlearn: 0.0324806\ttotal: 11s\tremaining: 3.94s\n",
            "736:\tlearn: 0.0324235\ttotal: 11s\tremaining: 3.92s\n",
            "737:\tlearn: 0.0323659\ttotal: 11s\tremaining: 3.91s\n",
            "738:\tlearn: 0.0322830\ttotal: 11s\tremaining: 3.89s\n",
            "739:\tlearn: 0.0322007\ttotal: 11s\tremaining: 3.87s\n",
            "740:\tlearn: 0.0321386\ttotal: 11s\tremaining: 3.86s\n",
            "741:\tlearn: 0.0320882\ttotal: 11s\tremaining: 3.84s\n",
            "742:\tlearn: 0.0320355\ttotal: 11.1s\tremaining: 3.83s\n",
            "743:\tlearn: 0.0319594\ttotal: 11.1s\tremaining: 3.81s\n",
            "744:\tlearn: 0.0318898\ttotal: 11.1s\tremaining: 3.79s\n",
            "745:\tlearn: 0.0318000\ttotal: 11.1s\tremaining: 3.77s\n",
            "746:\tlearn: 0.0317176\ttotal: 11.1s\tremaining: 3.76s\n",
            "747:\tlearn: 0.0316545\ttotal: 11.1s\tremaining: 3.74s\n",
            "748:\tlearn: 0.0315649\ttotal: 11.1s\tremaining: 3.73s\n",
            "749:\tlearn: 0.0315178\ttotal: 11.1s\tremaining: 3.71s\n",
            "750:\tlearn: 0.0314407\ttotal: 11.1s\tremaining: 3.7s\n",
            "751:\tlearn: 0.0314237\ttotal: 11.2s\tremaining: 3.68s\n",
            "752:\tlearn: 0.0313820\ttotal: 11.2s\tremaining: 3.66s\n",
            "753:\tlearn: 0.0313050\ttotal: 11.2s\tremaining: 3.65s\n",
            "754:\tlearn: 0.0312196\ttotal: 11.2s\tremaining: 3.63s\n",
            "755:\tlearn: 0.0311690\ttotal: 11.2s\tremaining: 3.61s\n",
            "756:\tlearn: 0.0310921\ttotal: 11.2s\tremaining: 3.6s\n",
            "757:\tlearn: 0.0310784\ttotal: 11.2s\tremaining: 3.58s\n",
            "758:\tlearn: 0.0310093\ttotal: 11.2s\tremaining: 3.56s\n",
            "759:\tlearn: 0.0309442\ttotal: 11.2s\tremaining: 3.55s\n",
            "760:\tlearn: 0.0309069\ttotal: 11.2s\tremaining: 3.53s\n",
            "761:\tlearn: 0.0308278\ttotal: 11.3s\tremaining: 3.52s\n",
            "762:\tlearn: 0.0307785\ttotal: 11.3s\tremaining: 3.5s\n",
            "763:\tlearn: 0.0307553\ttotal: 11.3s\tremaining: 3.48s\n",
            "764:\tlearn: 0.0307066\ttotal: 11.3s\tremaining: 3.47s\n",
            "765:\tlearn: 0.0306445\ttotal: 11.3s\tremaining: 3.45s\n",
            "766:\tlearn: 0.0305622\ttotal: 11.3s\tremaining: 3.44s\n",
            "767:\tlearn: 0.0304973\ttotal: 11.3s\tremaining: 3.42s\n",
            "768:\tlearn: 0.0304116\ttotal: 11.3s\tremaining: 3.4s\n",
            "769:\tlearn: 0.0303565\ttotal: 11.3s\tremaining: 3.39s\n",
            "770:\tlearn: 0.0302893\ttotal: 11.4s\tremaining: 3.37s\n",
            "771:\tlearn: 0.0302534\ttotal: 11.4s\tremaining: 3.36s\n",
            "772:\tlearn: 0.0301896\ttotal: 11.4s\tremaining: 3.34s\n",
            "773:\tlearn: 0.0301252\ttotal: 11.4s\tremaining: 3.33s\n",
            "774:\tlearn: 0.0300925\ttotal: 11.4s\tremaining: 3.31s\n",
            "775:\tlearn: 0.0300718\ttotal: 11.4s\tremaining: 3.3s\n",
            "776:\tlearn: 0.0300197\ttotal: 11.4s\tremaining: 3.28s\n",
            "777:\tlearn: 0.0299730\ttotal: 11.5s\tremaining: 3.27s\n",
            "778:\tlearn: 0.0299244\ttotal: 11.5s\tremaining: 3.25s\n",
            "779:\tlearn: 0.0298453\ttotal: 11.5s\tremaining: 3.23s\n",
            "780:\tlearn: 0.0298069\ttotal: 11.5s\tremaining: 3.22s\n",
            "781:\tlearn: 0.0297393\ttotal: 11.5s\tremaining: 3.2s\n",
            "782:\tlearn: 0.0296438\ttotal: 11.5s\tremaining: 3.19s\n",
            "783:\tlearn: 0.0295926\ttotal: 11.5s\tremaining: 3.17s\n",
            "784:\tlearn: 0.0295425\ttotal: 11.5s\tremaining: 3.15s\n",
            "785:\tlearn: 0.0294624\ttotal: 11.5s\tremaining: 3.14s\n",
            "786:\tlearn: 0.0294386\ttotal: 11.5s\tremaining: 3.12s\n",
            "787:\tlearn: 0.0294143\ttotal: 11.6s\tremaining: 3.11s\n",
            "788:\tlearn: 0.0293465\ttotal: 11.6s\tremaining: 3.1s\n",
            "789:\tlearn: 0.0292901\ttotal: 11.6s\tremaining: 3.08s\n",
            "790:\tlearn: 0.0292288\ttotal: 11.6s\tremaining: 3.06s\n",
            "791:\tlearn: 0.0291920\ttotal: 11.6s\tremaining: 3.05s\n",
            "792:\tlearn: 0.0291605\ttotal: 11.6s\tremaining: 3.03s\n",
            "793:\tlearn: 0.0290895\ttotal: 11.6s\tremaining: 3.02s\n",
            "794:\tlearn: 0.0290306\ttotal: 11.6s\tremaining: 3s\n",
            "795:\tlearn: 0.0289969\ttotal: 11.7s\tremaining: 2.99s\n",
            "796:\tlearn: 0.0289667\ttotal: 11.7s\tremaining: 2.97s\n",
            "797:\tlearn: 0.0288819\ttotal: 11.7s\tremaining: 2.95s\n",
            "798:\tlearn: 0.0288160\ttotal: 11.7s\tremaining: 2.94s\n",
            "799:\tlearn: 0.0287903\ttotal: 11.7s\tremaining: 2.92s\n",
            "800:\tlearn: 0.0287384\ttotal: 11.7s\tremaining: 2.91s\n",
            "801:\tlearn: 0.0286744\ttotal: 11.7s\tremaining: 2.89s\n",
            "802:\tlearn: 0.0286081\ttotal: 11.7s\tremaining: 2.88s\n",
            "803:\tlearn: 0.0285410\ttotal: 11.7s\tremaining: 2.86s\n",
            "804:\tlearn: 0.0284853\ttotal: 11.7s\tremaining: 2.85s\n",
            "805:\tlearn: 0.0284325\ttotal: 11.8s\tremaining: 2.83s\n",
            "806:\tlearn: 0.0283704\ttotal: 11.8s\tremaining: 2.82s\n",
            "807:\tlearn: 0.0283168\ttotal: 11.8s\tremaining: 2.8s\n",
            "808:\tlearn: 0.0282518\ttotal: 11.8s\tremaining: 2.79s\n",
            "809:\tlearn: 0.0282091\ttotal: 11.8s\tremaining: 2.77s\n",
            "810:\tlearn: 0.0281485\ttotal: 11.8s\tremaining: 2.75s\n",
            "811:\tlearn: 0.0280819\ttotal: 11.8s\tremaining: 2.74s\n",
            "812:\tlearn: 0.0280465\ttotal: 11.8s\tremaining: 2.72s\n",
            "813:\tlearn: 0.0279891\ttotal: 11.8s\tremaining: 2.71s\n",
            "814:\tlearn: 0.0279410\ttotal: 11.9s\tremaining: 2.69s\n",
            "815:\tlearn: 0.0278973\ttotal: 11.9s\tremaining: 2.68s\n",
            "816:\tlearn: 0.0278410\ttotal: 11.9s\tremaining: 2.66s\n",
            "817:\tlearn: 0.0278060\ttotal: 11.9s\tremaining: 2.65s\n",
            "818:\tlearn: 0.0277710\ttotal: 11.9s\tremaining: 2.63s\n",
            "819:\tlearn: 0.0277131\ttotal: 11.9s\tremaining: 2.61s\n",
            "820:\tlearn: 0.0276646\ttotal: 11.9s\tremaining: 2.6s\n",
            "821:\tlearn: 0.0276356\ttotal: 11.9s\tremaining: 2.58s\n",
            "822:\tlearn: 0.0276136\ttotal: 11.9s\tremaining: 2.57s\n",
            "823:\tlearn: 0.0275506\ttotal: 12s\tremaining: 2.55s\n",
            "824:\tlearn: 0.0274952\ttotal: 12s\tremaining: 2.54s\n",
            "825:\tlearn: 0.0274538\ttotal: 12s\tremaining: 2.52s\n",
            "826:\tlearn: 0.0273965\ttotal: 12s\tremaining: 2.51s\n",
            "827:\tlearn: 0.0273794\ttotal: 12s\tremaining: 2.49s\n",
            "828:\tlearn: 0.0273359\ttotal: 12s\tremaining: 2.48s\n",
            "829:\tlearn: 0.0273149\ttotal: 12s\tremaining: 2.46s\n",
            "830:\tlearn: 0.0272672\ttotal: 12s\tremaining: 2.45s\n",
            "831:\tlearn: 0.0272056\ttotal: 12s\tremaining: 2.43s\n",
            "832:\tlearn: 0.0271750\ttotal: 12s\tremaining: 2.42s\n",
            "833:\tlearn: 0.0271407\ttotal: 12.1s\tremaining: 2.4s\n",
            "834:\tlearn: 0.0270951\ttotal: 12.1s\tremaining: 2.38s\n",
            "835:\tlearn: 0.0270213\ttotal: 12.1s\tremaining: 2.37s\n",
            "836:\tlearn: 0.0269792\ttotal: 12.1s\tremaining: 2.35s\n",
            "837:\tlearn: 0.0269237\ttotal: 12.1s\tremaining: 2.34s\n",
            "838:\tlearn: 0.0268829\ttotal: 12.1s\tremaining: 2.32s\n",
            "839:\tlearn: 0.0268530\ttotal: 12.1s\tremaining: 2.31s\n",
            "840:\tlearn: 0.0267745\ttotal: 12.1s\tremaining: 2.29s\n",
            "841:\tlearn: 0.0267275\ttotal: 12.1s\tremaining: 2.28s\n",
            "842:\tlearn: 0.0266868\ttotal: 12.2s\tremaining: 2.26s\n",
            "843:\tlearn: 0.0266218\ttotal: 12.2s\tremaining: 2.25s\n",
            "844:\tlearn: 0.0265929\ttotal: 12.2s\tremaining: 2.23s\n",
            "845:\tlearn: 0.0265722\ttotal: 12.2s\tremaining: 2.22s\n",
            "846:\tlearn: 0.0265539\ttotal: 12.2s\tremaining: 2.2s\n",
            "847:\tlearn: 0.0264983\ttotal: 12.2s\tremaining: 2.19s\n",
            "848:\tlearn: 0.0264374\ttotal: 12.2s\tremaining: 2.17s\n",
            "849:\tlearn: 0.0263983\ttotal: 12.2s\tremaining: 2.16s\n",
            "850:\tlearn: 0.0263374\ttotal: 12.2s\tremaining: 2.14s\n",
            "851:\tlearn: 0.0263085\ttotal: 12.3s\tremaining: 2.13s\n",
            "852:\tlearn: 0.0262910\ttotal: 12.3s\tremaining: 2.11s\n",
            "853:\tlearn: 0.0262522\ttotal: 12.3s\tremaining: 2.1s\n",
            "854:\tlearn: 0.0262165\ttotal: 12.3s\tremaining: 2.08s\n",
            "855:\tlearn: 0.0261701\ttotal: 12.3s\tremaining: 2.07s\n",
            "856:\tlearn: 0.0261327\ttotal: 12.3s\tremaining: 2.05s\n",
            "857:\tlearn: 0.0260731\ttotal: 12.3s\tremaining: 2.04s\n",
            "858:\tlearn: 0.0260368\ttotal: 12.3s\tremaining: 2.02s\n",
            "859:\tlearn: 0.0260074\ttotal: 12.3s\tremaining: 2.01s\n",
            "860:\tlearn: 0.0259605\ttotal: 12.4s\tremaining: 1.99s\n",
            "861:\tlearn: 0.0259018\ttotal: 12.4s\tremaining: 1.98s\n",
            "862:\tlearn: 0.0258248\ttotal: 12.4s\tremaining: 1.96s\n",
            "863:\tlearn: 0.0257787\ttotal: 12.4s\tremaining: 1.95s\n",
            "864:\tlearn: 0.0257433\ttotal: 12.4s\tremaining: 1.93s\n",
            "865:\tlearn: 0.0256902\ttotal: 12.4s\tremaining: 1.92s\n",
            "866:\tlearn: 0.0256686\ttotal: 12.4s\tremaining: 1.91s\n",
            "867:\tlearn: 0.0256355\ttotal: 12.4s\tremaining: 1.89s\n",
            "868:\tlearn: 0.0255654\ttotal: 12.5s\tremaining: 1.88s\n",
            "869:\tlearn: 0.0255137\ttotal: 12.5s\tremaining: 1.86s\n",
            "870:\tlearn: 0.0254567\ttotal: 12.5s\tremaining: 1.85s\n",
            "871:\tlearn: 0.0253957\ttotal: 12.5s\tremaining: 1.83s\n",
            "872:\tlearn: 0.0253435\ttotal: 12.5s\tremaining: 1.82s\n",
            "873:\tlearn: 0.0253045\ttotal: 12.5s\tremaining: 1.8s\n",
            "874:\tlearn: 0.0252614\ttotal: 12.5s\tremaining: 1.79s\n",
            "875:\tlearn: 0.0252190\ttotal: 12.5s\tremaining: 1.77s\n",
            "876:\tlearn: 0.0251709\ttotal: 12.5s\tremaining: 1.76s\n",
            "877:\tlearn: 0.0251040\ttotal: 12.5s\tremaining: 1.74s\n",
            "878:\tlearn: 0.0250715\ttotal: 12.6s\tremaining: 1.73s\n",
            "879:\tlearn: 0.0250359\ttotal: 12.6s\tremaining: 1.71s\n",
            "880:\tlearn: 0.0249686\ttotal: 12.6s\tremaining: 1.7s\n",
            "881:\tlearn: 0.0249243\ttotal: 12.6s\tremaining: 1.69s\n",
            "882:\tlearn: 0.0248970\ttotal: 12.6s\tremaining: 1.67s\n",
            "883:\tlearn: 0.0248513\ttotal: 12.6s\tremaining: 1.66s\n",
            "884:\tlearn: 0.0248058\ttotal: 12.6s\tremaining: 1.64s\n",
            "885:\tlearn: 0.0247685\ttotal: 12.6s\tremaining: 1.63s\n",
            "886:\tlearn: 0.0247215\ttotal: 12.7s\tremaining: 1.61s\n",
            "887:\tlearn: 0.0246827\ttotal: 12.7s\tremaining: 1.6s\n",
            "888:\tlearn: 0.0246180\ttotal: 12.7s\tremaining: 1.58s\n",
            "889:\tlearn: 0.0245567\ttotal: 12.7s\tremaining: 1.57s\n",
            "890:\tlearn: 0.0245211\ttotal: 12.7s\tremaining: 1.55s\n",
            "891:\tlearn: 0.0244913\ttotal: 12.7s\tremaining: 1.54s\n",
            "892:\tlearn: 0.0244567\ttotal: 12.7s\tremaining: 1.52s\n",
            "893:\tlearn: 0.0244007\ttotal: 12.7s\tremaining: 1.51s\n",
            "894:\tlearn: 0.0243671\ttotal: 12.7s\tremaining: 1.49s\n",
            "895:\tlearn: 0.0243282\ttotal: 12.7s\tremaining: 1.48s\n",
            "896:\tlearn: 0.0242729\ttotal: 12.8s\tremaining: 1.47s\n",
            "897:\tlearn: 0.0242251\ttotal: 12.8s\tremaining: 1.45s\n",
            "898:\tlearn: 0.0242046\ttotal: 12.8s\tremaining: 1.44s\n",
            "899:\tlearn: 0.0241408\ttotal: 12.8s\tremaining: 1.42s\n",
            "900:\tlearn: 0.0241000\ttotal: 12.8s\tremaining: 1.41s\n",
            "901:\tlearn: 0.0240757\ttotal: 12.8s\tremaining: 1.39s\n",
            "902:\tlearn: 0.0240347\ttotal: 12.8s\tremaining: 1.38s\n",
            "903:\tlearn: 0.0239847\ttotal: 12.8s\tremaining: 1.36s\n",
            "904:\tlearn: 0.0239072\ttotal: 12.8s\tremaining: 1.35s\n",
            "905:\tlearn: 0.0238451\ttotal: 12.9s\tremaining: 1.33s\n",
            "906:\tlearn: 0.0237849\ttotal: 12.9s\tremaining: 1.32s\n",
            "907:\tlearn: 0.0237443\ttotal: 12.9s\tremaining: 1.3s\n",
            "908:\tlearn: 0.0236981\ttotal: 12.9s\tremaining: 1.29s\n",
            "909:\tlearn: 0.0236659\ttotal: 12.9s\tremaining: 1.27s\n",
            "910:\tlearn: 0.0236421\ttotal: 12.9s\tremaining: 1.26s\n",
            "911:\tlearn: 0.0235756\ttotal: 12.9s\tremaining: 1.25s\n",
            "912:\tlearn: 0.0235353\ttotal: 12.9s\tremaining: 1.23s\n",
            "913:\tlearn: 0.0234955\ttotal: 12.9s\tremaining: 1.22s\n",
            "914:\tlearn: 0.0234488\ttotal: 13s\tremaining: 1.2s\n",
            "915:\tlearn: 0.0234129\ttotal: 13s\tremaining: 1.19s\n",
            "916:\tlearn: 0.0233783\ttotal: 13s\tremaining: 1.17s\n",
            "917:\tlearn: 0.0233420\ttotal: 13s\tremaining: 1.16s\n",
            "918:\tlearn: 0.0232983\ttotal: 13s\tremaining: 1.15s\n",
            "919:\tlearn: 0.0232555\ttotal: 13s\tremaining: 1.13s\n",
            "920:\tlearn: 0.0232256\ttotal: 13s\tremaining: 1.12s\n",
            "921:\tlearn: 0.0231991\ttotal: 13s\tremaining: 1.1s\n",
            "922:\tlearn: 0.0231593\ttotal: 13s\tremaining: 1.09s\n",
            "923:\tlearn: 0.0231117\ttotal: 13.1s\tremaining: 1.07s\n",
            "924:\tlearn: 0.0230707\ttotal: 13.1s\tremaining: 1.06s\n",
            "925:\tlearn: 0.0230543\ttotal: 13.1s\tremaining: 1.04s\n",
            "926:\tlearn: 0.0230110\ttotal: 13.1s\tremaining: 1.03s\n",
            "927:\tlearn: 0.0229668\ttotal: 13.1s\tremaining: 1.02s\n",
            "928:\tlearn: 0.0229415\ttotal: 13.1s\tremaining: 1s\n",
            "929:\tlearn: 0.0229206\ttotal: 13.1s\tremaining: 987ms\n",
            "930:\tlearn: 0.0229048\ttotal: 13.1s\tremaining: 973ms\n",
            "931:\tlearn: 0.0228766\ttotal: 13.1s\tremaining: 959ms\n",
            "932:\tlearn: 0.0228516\ttotal: 13.1s\tremaining: 944ms\n",
            "933:\tlearn: 0.0228144\ttotal: 13.2s\tremaining: 930ms\n",
            "934:\tlearn: 0.0227718\ttotal: 13.2s\tremaining: 915ms\n",
            "935:\tlearn: 0.0227186\ttotal: 13.2s\tremaining: 901ms\n",
            "936:\tlearn: 0.0226993\ttotal: 13.2s\tremaining: 887ms\n",
            "937:\tlearn: 0.0226616\ttotal: 13.2s\tremaining: 872ms\n",
            "938:\tlearn: 0.0226397\ttotal: 13.2s\tremaining: 858ms\n",
            "939:\tlearn: 0.0226365\ttotal: 13.2s\tremaining: 844ms\n",
            "940:\tlearn: 0.0225857\ttotal: 13.2s\tremaining: 829ms\n",
            "941:\tlearn: 0.0225567\ttotal: 13.2s\tremaining: 816ms\n",
            "942:\tlearn: 0.0225279\ttotal: 13.3s\tremaining: 802ms\n",
            "943:\tlearn: 0.0224973\ttotal: 13.3s\tremaining: 787ms\n",
            "944:\tlearn: 0.0224727\ttotal: 13.3s\tremaining: 773ms\n",
            "945:\tlearn: 0.0224129\ttotal: 13.3s\tremaining: 759ms\n",
            "946:\tlearn: 0.0223753\ttotal: 13.3s\tremaining: 745ms\n",
            "947:\tlearn: 0.0223473\ttotal: 13.3s\tremaining: 731ms\n",
            "948:\tlearn: 0.0222822\ttotal: 13.3s\tremaining: 717ms\n",
            "949:\tlearn: 0.0222449\ttotal: 13.3s\tremaining: 702ms\n",
            "950:\tlearn: 0.0222037\ttotal: 13.4s\tremaining: 688ms\n",
            "951:\tlearn: 0.0221791\ttotal: 13.4s\tremaining: 674ms\n",
            "952:\tlearn: 0.0221586\ttotal: 13.4s\tremaining: 660ms\n",
            "953:\tlearn: 0.0221381\ttotal: 13.4s\tremaining: 645ms\n",
            "954:\tlearn: 0.0221168\ttotal: 13.4s\tremaining: 631ms\n",
            "955:\tlearn: 0.0220776\ttotal: 13.4s\tremaining: 617ms\n",
            "956:\tlearn: 0.0220504\ttotal: 13.4s\tremaining: 603ms\n",
            "957:\tlearn: 0.0219949\ttotal: 13.4s\tremaining: 589ms\n",
            "958:\tlearn: 0.0219620\ttotal: 13.5s\tremaining: 575ms\n",
            "959:\tlearn: 0.0219318\ttotal: 13.5s\tremaining: 561ms\n",
            "960:\tlearn: 0.0219003\ttotal: 13.5s\tremaining: 547ms\n",
            "961:\tlearn: 0.0218622\ttotal: 13.5s\tremaining: 533ms\n",
            "962:\tlearn: 0.0218176\ttotal: 13.5s\tremaining: 519ms\n",
            "963:\tlearn: 0.0217795\ttotal: 13.5s\tremaining: 505ms\n",
            "964:\tlearn: 0.0217550\ttotal: 13.5s\tremaining: 491ms\n",
            "965:\tlearn: 0.0217188\ttotal: 13.5s\tremaining: 477ms\n",
            "966:\tlearn: 0.0216744\ttotal: 13.6s\tremaining: 463ms\n",
            "967:\tlearn: 0.0216520\ttotal: 13.6s\tremaining: 449ms\n",
            "968:\tlearn: 0.0216315\ttotal: 13.6s\tremaining: 434ms\n",
            "969:\tlearn: 0.0215998\ttotal: 13.6s\tremaining: 420ms\n",
            "970:\tlearn: 0.0215756\ttotal: 13.6s\tremaining: 406ms\n",
            "971:\tlearn: 0.0215566\ttotal: 13.6s\tremaining: 392ms\n",
            "972:\tlearn: 0.0215085\ttotal: 13.6s\tremaining: 378ms\n",
            "973:\tlearn: 0.0214865\ttotal: 13.6s\tremaining: 364ms\n",
            "974:\tlearn: 0.0214689\ttotal: 13.6s\tremaining: 350ms\n",
            "975:\tlearn: 0.0214328\ttotal: 13.7s\tremaining: 336ms\n",
            "976:\tlearn: 0.0214233\ttotal: 13.7s\tremaining: 322ms\n",
            "977:\tlearn: 0.0213926\ttotal: 13.7s\tremaining: 308ms\n",
            "978:\tlearn: 0.0213687\ttotal: 13.7s\tremaining: 294ms\n",
            "979:\tlearn: 0.0213199\ttotal: 13.7s\tremaining: 280ms\n",
            "980:\tlearn: 0.0212829\ttotal: 13.7s\tremaining: 266ms\n",
            "981:\tlearn: 0.0212455\ttotal: 13.7s\tremaining: 252ms\n",
            "982:\tlearn: 0.0212232\ttotal: 13.7s\tremaining: 238ms\n",
            "983:\tlearn: 0.0211999\ttotal: 13.7s\tremaining: 224ms\n",
            "984:\tlearn: 0.0211897\ttotal: 13.8s\tremaining: 209ms\n",
            "985:\tlearn: 0.0211444\ttotal: 13.8s\tremaining: 195ms\n",
            "986:\tlearn: 0.0211148\ttotal: 13.8s\tremaining: 181ms\n",
            "987:\tlearn: 0.0210684\ttotal: 13.8s\tremaining: 167ms\n",
            "988:\tlearn: 0.0210563\ttotal: 13.8s\tremaining: 153ms\n",
            "989:\tlearn: 0.0210056\ttotal: 13.8s\tremaining: 139ms\n",
            "990:\tlearn: 0.0209699\ttotal: 13.8s\tremaining: 125ms\n",
            "991:\tlearn: 0.0209408\ttotal: 13.8s\tremaining: 112ms\n",
            "992:\tlearn: 0.0208876\ttotal: 13.8s\tremaining: 97.5ms\n",
            "993:\tlearn: 0.0208620\ttotal: 13.8s\tremaining: 83.6ms\n",
            "994:\tlearn: 0.0208084\ttotal: 13.9s\tremaining: 69.8ms\n",
            "995:\tlearn: 0.0207590\ttotal: 13.9s\tremaining: 55.8ms\n",
            "996:\tlearn: 0.0207099\ttotal: 13.9s\tremaining: 41.9ms\n",
            "997:\tlearn: 0.0206908\ttotal: 13.9s\tremaining: 27.9ms\n",
            "998:\tlearn: 0.0206719\ttotal: 14s\tremaining: 14ms\n",
            "999:\tlearn: 0.0206454\ttotal: 14s\tremaining: 0us\n",
            "Training and predicting with xgboost...\n",
            "Training and predicting with lightgbm...\n",
            "[LightGBM] [Info] Number of positive: 255, number of negative: 275\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002497 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3904\n",
            "[LightGBM] [Info] Number of data points in the train set: 530, number of used features: 42\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.481132 -> initscore=-0.075508\n",
            "[LightGBM] [Info] Start training from score -0.075508\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 254, number of negative: 276\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000114 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3898\n",
            "[LightGBM] [Info] Number of data points in the train set: 530, number of used features: 42\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.479245 -> initscore=-0.083067\n",
            "[LightGBM] [Info] Start training from score -0.083067\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 253, number of negative: 277\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000137 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3916\n",
            "[LightGBM] [Info] Number of data points in the train set: 530, number of used features: 42\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.477358 -> initscore=-0.090628\n",
            "[LightGBM] [Info] Start training from score -0.090628\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 266, number of negative: 265\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000175 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3891\n",
            "[LightGBM] [Info] Number of data points in the train set: 531, number of used features: 42\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500942 -> initscore=0.003766\n",
            "[LightGBM] [Info] Start training from score 0.003766\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 260, number of negative: 271\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000111 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3874\n",
            "[LightGBM] [Info] Number of data points in the train set: 531, number of used features: 42\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.489642 -> initscore=-0.041437\n",
            "[LightGBM] [Info] Start training from score -0.041437\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Learning rate set to 0.008644\n",
            "0:\tlearn: 0.6930829\ttotal: 698us\tremaining: 698ms\n",
            "1:\tlearn: 0.6930034\ttotal: 1.53ms\tremaining: 764ms\n",
            "2:\tlearn: 0.6929481\ttotal: 2.54ms\tremaining: 844ms\n",
            "3:\tlearn: 0.6928600\ttotal: 3.38ms\tremaining: 842ms\n",
            "4:\tlearn: 0.6927939\ttotal: 4.21ms\tremaining: 838ms\n",
            "5:\tlearn: 0.6927225\ttotal: 5.06ms\tremaining: 839ms\n",
            "6:\tlearn: 0.6926391\ttotal: 5.87ms\tremaining: 833ms\n",
            "7:\tlearn: 0.6925799\ttotal: 6.63ms\tremaining: 822ms\n",
            "8:\tlearn: 0.6925001\ttotal: 7.43ms\tremaining: 818ms\n",
            "9:\tlearn: 0.6924426\ttotal: 8.17ms\tremaining: 809ms\n",
            "10:\tlearn: 0.6923684\ttotal: 8.91ms\tremaining: 801ms\n",
            "11:\tlearn: 0.6922901\ttotal: 9.68ms\tremaining: 797ms\n",
            "12:\tlearn: 0.6922229\ttotal: 10.4ms\tremaining: 792ms\n",
            "13:\tlearn: 0.6921524\ttotal: 11.2ms\tremaining: 790ms\n",
            "14:\tlearn: 0.6920795\ttotal: 12ms\tremaining: 787ms\n",
            "15:\tlearn: 0.6920602\ttotal: 12.7ms\tremaining: 781ms\n",
            "16:\tlearn: 0.6919913\ttotal: 13.5ms\tremaining: 778ms\n",
            "17:\tlearn: 0.6919185\ttotal: 14.2ms\tremaining: 774ms\n",
            "18:\tlearn: 0.6918606\ttotal: 14.9ms\tremaining: 770ms\n",
            "19:\tlearn: 0.6918352\ttotal: 15.6ms\tremaining: 763ms\n",
            "20:\tlearn: 0.6918139\ttotal: 16.2ms\tremaining: 757ms\n",
            "21:\tlearn: 0.6917447\ttotal: 17ms\tremaining: 755ms\n",
            "22:\tlearn: 0.6916841\ttotal: 17.7ms\tremaining: 751ms\n",
            "23:\tlearn: 0.6916298\ttotal: 18.4ms\tremaining: 750ms\n",
            "24:\tlearn: 0.6915733\ttotal: 19.2ms\tremaining: 749ms\n",
            "25:\tlearn: 0.6915543\ttotal: 20.1ms\tremaining: 753ms\n",
            "26:\tlearn: 0.6915306\ttotal: 20.6ms\tremaining: 742ms\n",
            "27:\tlearn: 0.6915146\ttotal: 21ms\tremaining: 730ms\n",
            "28:\tlearn: 0.6914538\ttotal: 22.4ms\tremaining: 749ms\n",
            "29:\tlearn: 0.6913969\ttotal: 23.3ms\tremaining: 752ms\n",
            "30:\tlearn: 0.6913383\ttotal: 24.2ms\tremaining: 758ms\n",
            "31:\tlearn: 0.6912753\ttotal: 25.2ms\tremaining: 762ms\n",
            "32:\tlearn: 0.6912278\ttotal: 25.8ms\tremaining: 757ms\n",
            "33:\tlearn: 0.6911694\ttotal: 26.5ms\tremaining: 752ms\n",
            "34:\tlearn: 0.6911502\ttotal: 28.1ms\tremaining: 774ms\n",
            "35:\tlearn: 0.6910927\ttotal: 29ms\tremaining: 777ms\n",
            "36:\tlearn: 0.6910555\ttotal: 29.9ms\tremaining: 779ms\n",
            "37:\tlearn: 0.6910359\ttotal: 30.4ms\tremaining: 769ms\n",
            "38:\tlearn: 0.6910028\ttotal: 31ms\tremaining: 764ms\n",
            "39:\tlearn: 0.6909634\ttotal: 31.8ms\tremaining: 763ms\n",
            "40:\tlearn: 0.6909126\ttotal: 32.4ms\tremaining: 757ms\n",
            "41:\tlearn: 0.6908655\ttotal: 33.1ms\tremaining: 755ms\n",
            "42:\tlearn: 0.6908224\ttotal: 33.6ms\tremaining: 748ms\n",
            "43:\tlearn: 0.6907917\ttotal: 34.2ms\tremaining: 743ms\n",
            "44:\tlearn: 0.6907746\ttotal: 35.3ms\tremaining: 749ms\n",
            "45:\tlearn: 0.6907268\ttotal: 35.9ms\tremaining: 744ms\n",
            "46:\tlearn: 0.6906807\ttotal: 36.5ms\tremaining: 740ms\n",
            "47:\tlearn: 0.6906683\ttotal: 37ms\tremaining: 734ms\n",
            "48:\tlearn: 0.6906486\ttotal: 37.6ms\tremaining: 729ms\n",
            "49:\tlearn: 0.6906210\ttotal: 39.2ms\tremaining: 744ms\n",
            "50:\tlearn: 0.6906104\ttotal: 39.8ms\tremaining: 741ms\n",
            "51:\tlearn: 0.6905923\ttotal: 40.6ms\tremaining: 740ms\n",
            "52:\tlearn: 0.6905782\ttotal: 41.7ms\tremaining: 746ms\n",
            "53:\tlearn: 0.6905423\ttotal: 42.3ms\tremaining: 741ms\n",
            "54:\tlearn: 0.6904997\ttotal: 43.2ms\tremaining: 742ms\n",
            "55:\tlearn: 0.6904860\ttotal: 43.9ms\tremaining: 740ms\n",
            "56:\tlearn: 0.6904372\ttotal: 44.9ms\tremaining: 743ms\n",
            "57:\tlearn: 0.6903947\ttotal: 45.9ms\tremaining: 745ms\n",
            "58:\tlearn: 0.6903579\ttotal: 46.7ms\tremaining: 745ms\n",
            "59:\tlearn: 0.6903473\ttotal: 47.5ms\tremaining: 744ms\n",
            "60:\tlearn: 0.6903321\ttotal: 48.2ms\tremaining: 741ms\n",
            "61:\tlearn: 0.6902906\ttotal: 48.9ms\tremaining: 740ms\n",
            "62:\tlearn: 0.6902510\ttotal: 49.6ms\tremaining: 738ms\n",
            "63:\tlearn: 0.6902123\ttotal: 50.4ms\tremaining: 737ms\n",
            "64:\tlearn: 0.6902000\ttotal: 51.3ms\tremaining: 738ms\n",
            "65:\tlearn: 0.6901857\ttotal: 52.1ms\tremaining: 737ms\n",
            "66:\tlearn: 0.6901565\ttotal: 52.8ms\tremaining: 736ms\n",
            "67:\tlearn: 0.6901185\ttotal: 53.4ms\tremaining: 732ms\n",
            "68:\tlearn: 0.6900810\ttotal: 53.9ms\tremaining: 728ms\n",
            "69:\tlearn: 0.6900595\ttotal: 54.5ms\tremaining: 724ms\n",
            "70:\tlearn: 0.6900316\ttotal: 55ms\tremaining: 719ms\n",
            "71:\tlearn: 0.6899958\ttotal: 55.5ms\tremaining: 716ms\n",
            "72:\tlearn: 0.6899599\ttotal: 56.1ms\tremaining: 712ms\n",
            "73:\tlearn: 0.6899262\ttotal: 56.6ms\tremaining: 708ms\n",
            "74:\tlearn: 0.6898874\ttotal: 57.2ms\tremaining: 705ms\n",
            "75:\tlearn: 0.6898571\ttotal: 58ms\tremaining: 705ms\n",
            "76:\tlearn: 0.6898468\ttotal: 58.7ms\tremaining: 703ms\n",
            "77:\tlearn: 0.6898102\ttotal: 59.5ms\tremaining: 703ms\n",
            "78:\tlearn: 0.6897830\ttotal: 60.5ms\tremaining: 705ms\n",
            "79:\tlearn: 0.6897487\ttotal: 61.4ms\tremaining: 706ms\n",
            "80:\tlearn: 0.6897212\ttotal: 62.2ms\tremaining: 706ms\n",
            "81:\tlearn: 0.6897057\ttotal: 63.1ms\tremaining: 706ms\n",
            "82:\tlearn: 0.6896912\ttotal: 63.9ms\tremaining: 705ms\n",
            "83:\tlearn: 0.6896586\ttotal: 64.6ms\tremaining: 705ms\n",
            "84:\tlearn: 0.6896267\ttotal: 65.4ms\tremaining: 704ms\n",
            "85:\tlearn: 0.6895983\ttotal: 66.2ms\tremaining: 703ms\n",
            "86:\tlearn: 0.6895761\ttotal: 66.9ms\tremaining: 702ms\n",
            "87:\tlearn: 0.6895557\ttotal: 67.7ms\tremaining: 702ms\n",
            "88:\tlearn: 0.6895271\ttotal: 68.5ms\tremaining: 701ms\n",
            "89:\tlearn: 0.6895086\ttotal: 69.2ms\tremaining: 700ms\n",
            "90:\tlearn: 0.6894948\ttotal: 70ms\tremaining: 699ms\n",
            "91:\tlearn: 0.6894786\ttotal: 70.7ms\tremaining: 698ms\n",
            "92:\tlearn: 0.6894542\ttotal: 71.4ms\tremaining: 697ms\n",
            "93:\tlearn: 0.6894390\ttotal: 72.2ms\tremaining: 696ms\n",
            "94:\tlearn: 0.6894241\ttotal: 73.9ms\tremaining: 704ms\n",
            "95:\tlearn: 0.6894093\ttotal: 74.5ms\tremaining: 701ms\n",
            "96:\tlearn: 0.6893905\ttotal: 75ms\tremaining: 698ms\n",
            "97:\tlearn: 0.6893688\ttotal: 78.8ms\tremaining: 726ms\n",
            "98:\tlearn: 0.6893596\ttotal: 81.2ms\tremaining: 739ms\n",
            "99:\tlearn: 0.6893399\ttotal: 81.9ms\tremaining: 737ms\n",
            "100:\tlearn: 0.6893257\ttotal: 84.2ms\tremaining: 750ms\n",
            "101:\tlearn: 0.6893139\ttotal: 85.4ms\tremaining: 751ms\n",
            "102:\tlearn: 0.6892863\ttotal: 86.7ms\tremaining: 755ms\n",
            "103:\tlearn: 0.6892618\ttotal: 88ms\tremaining: 758ms\n",
            "104:\tlearn: 0.6892445\ttotal: 89.2ms\tremaining: 761ms\n",
            "105:\tlearn: 0.6892248\ttotal: 90.3ms\tremaining: 762ms\n",
            "106:\tlearn: 0.6892202\ttotal: 91.7ms\tremaining: 766ms\n",
            "107:\tlearn: 0.6892086\ttotal: 93ms\tremaining: 768ms\n",
            "108:\tlearn: 0.6891841\ttotal: 94ms\tremaining: 768ms\n",
            "109:\tlearn: 0.6891628\ttotal: 95.8ms\tremaining: 775ms\n",
            "110:\tlearn: 0.6891444\ttotal: 96.7ms\tremaining: 775ms\n",
            "111:\tlearn: 0.6891317\ttotal: 97.6ms\tremaining: 774ms\n",
            "112:\tlearn: 0.6891077\ttotal: 99.1ms\tremaining: 778ms\n",
            "113:\tlearn: 0.6890883\ttotal: 100ms\tremaining: 777ms\n",
            "114:\tlearn: 0.6890648\ttotal: 101ms\tremaining: 777ms\n",
            "115:\tlearn: 0.6890423\ttotal: 103ms\tremaining: 786ms\n",
            "116:\tlearn: 0.6890207\ttotal: 104ms\tremaining: 785ms\n",
            "117:\tlearn: 0.6890005\ttotal: 105ms\tremaining: 783ms\n",
            "118:\tlearn: 0.6889998\ttotal: 107ms\tremaining: 789ms\n",
            "119:\tlearn: 0.6889806\ttotal: 107ms\tremaining: 787ms\n",
            "120:\tlearn: 0.6889627\ttotal: 108ms\tremaining: 786ms\n",
            "121:\tlearn: 0.6889405\ttotal: 109ms\tremaining: 787ms\n",
            "122:\tlearn: 0.6889212\ttotal: 110ms\tremaining: 784ms\n",
            "123:\tlearn: 0.6889068\ttotal: 111ms\tremaining: 781ms\n",
            "124:\tlearn: 0.6888856\ttotal: 112ms\tremaining: 781ms\n",
            "125:\tlearn: 0.6888674\ttotal: 113ms\tremaining: 783ms\n",
            "126:\tlearn: 0.6888597\ttotal: 114ms\tremaining: 781ms\n",
            "127:\tlearn: 0.6888489\ttotal: 114ms\tremaining: 778ms\n",
            "128:\tlearn: 0.6888309\ttotal: 115ms\tremaining: 777ms\n",
            "129:\tlearn: 0.6888202\ttotal: 116ms\tremaining: 776ms\n",
            "130:\tlearn: 0.6888043\ttotal: 117ms\tremaining: 774ms\n",
            "131:\tlearn: 0.6888046\ttotal: 117ms\tremaining: 773ms\n",
            "132:\tlearn: 0.6887886\ttotal: 118ms\tremaining: 771ms\n",
            "133:\tlearn: 0.6887763\ttotal: 119ms\tremaining: 769ms\n",
            "134:\tlearn: 0.6887570\ttotal: 120ms\tremaining: 767ms\n",
            "135:\tlearn: 0.6887409\ttotal: 121ms\tremaining: 766ms\n",
            "136:\tlearn: 0.6887315\ttotal: 121ms\tremaining: 764ms\n",
            "137:\tlearn: 0.6887135\ttotal: 122ms\tremaining: 762ms\n",
            "138:\tlearn: 0.6887021\ttotal: 123ms\tremaining: 760ms\n",
            "139:\tlearn: 0.6886898\ttotal: 123ms\tremaining: 759ms\n",
            "140:\tlearn: 0.6886798\ttotal: 124ms\tremaining: 757ms\n",
            "141:\tlearn: 0.6886697\ttotal: 125ms\tremaining: 755ms\n",
            "142:\tlearn: 0.6886595\ttotal: 126ms\tremaining: 754ms\n",
            "143:\tlearn: 0.6886428\ttotal: 127ms\tremaining: 752ms\n",
            "144:\tlearn: 0.6886388\ttotal: 127ms\tremaining: 750ms\n",
            "145:\tlearn: 0.6886273\ttotal: 128ms\tremaining: 748ms\n",
            "146:\tlearn: 0.6886156\ttotal: 129ms\tremaining: 747ms\n",
            "147:\tlearn: 0.6886142\ttotal: 129ms\tremaining: 745ms\n",
            "148:\tlearn: 0.6886113\ttotal: 130ms\tremaining: 743ms\n",
            "149:\tlearn: 0.6886109\ttotal: 131ms\tremaining: 741ms\n",
            "150:\tlearn: 0.6886025\ttotal: 132ms\tremaining: 740ms\n",
            "151:\tlearn: 0.6885947\ttotal: 132ms\tremaining: 738ms\n",
            "152:\tlearn: 0.6885752\ttotal: 133ms\tremaining: 737ms\n",
            "153:\tlearn: 0.6885729\ttotal: 134ms\tremaining: 735ms\n",
            "154:\tlearn: 0.6885600\ttotal: 135ms\tremaining: 734ms\n",
            "155:\tlearn: 0.6885591\ttotal: 135ms\tremaining: 732ms\n",
            "156:\tlearn: 0.6885465\ttotal: 136ms\tremaining: 731ms\n",
            "157:\tlearn: 0.6885306\ttotal: 137ms\tremaining: 729ms\n",
            "158:\tlearn: 0.6885225\ttotal: 138ms\tremaining: 728ms\n",
            "159:\tlearn: 0.6885075\ttotal: 138ms\tremaining: 727ms\n",
            "160:\tlearn: 0.6885017\ttotal: 139ms\tremaining: 725ms\n",
            "161:\tlearn: 0.6885004\ttotal: 140ms\tremaining: 724ms\n",
            "162:\tlearn: 0.6884923\ttotal: 141ms\tremaining: 722ms\n",
            "163:\tlearn: 0.6884818\ttotal: 141ms\tremaining: 721ms\n",
            "164:\tlearn: 0.6884667\ttotal: 142ms\tremaining: 719ms\n",
            "165:\tlearn: 0.6884593\ttotal: 143ms\tremaining: 718ms\n",
            "166:\tlearn: 0.6884528\ttotal: 144ms\tremaining: 717ms\n",
            "167:\tlearn: 0.6884381\ttotal: 144ms\tremaining: 715ms\n",
            "168:\tlearn: 0.6884303\ttotal: 145ms\tremaining: 714ms\n",
            "169:\tlearn: 0.6884218\ttotal: 146ms\tremaining: 713ms\n",
            "170:\tlearn: 0.6884135\ttotal: 147ms\tremaining: 711ms\n",
            "171:\tlearn: 0.6883997\ttotal: 148ms\tremaining: 710ms\n",
            "172:\tlearn: 0.6883929\ttotal: 148ms\tremaining: 708ms\n",
            "173:\tlearn: 0.6883879\ttotal: 149ms\tremaining: 707ms\n",
            "174:\tlearn: 0.6883800\ttotal: 150ms\tremaining: 706ms\n",
            "175:\tlearn: 0.6883738\ttotal: 150ms\tremaining: 705ms\n",
            "176:\tlearn: 0.6883619\ttotal: 151ms\tremaining: 703ms\n",
            "177:\tlearn: 0.6883513\ttotal: 152ms\tremaining: 702ms\n",
            "178:\tlearn: 0.6883434\ttotal: 153ms\tremaining: 701ms\n",
            "179:\tlearn: 0.6883310\ttotal: 154ms\tremaining: 699ms\n",
            "180:\tlearn: 0.6883245\ttotal: 154ms\tremaining: 698ms\n",
            "181:\tlearn: 0.6883125\ttotal: 155ms\tremaining: 697ms\n",
            "182:\tlearn: 0.6883071\ttotal: 156ms\tremaining: 695ms\n",
            "183:\tlearn: 0.6883013\ttotal: 156ms\tremaining: 694ms\n",
            "184:\tlearn: 0.6882904\ttotal: 157ms\tremaining: 693ms\n",
            "185:\tlearn: 0.6882841\ttotal: 158ms\tremaining: 692ms\n",
            "186:\tlearn: 0.6882758\ttotal: 159ms\tremaining: 690ms\n",
            "187:\tlearn: 0.6882733\ttotal: 160ms\tremaining: 689ms\n",
            "188:\tlearn: 0.6882625\ttotal: 160ms\tremaining: 688ms\n",
            "189:\tlearn: 0.6882567\ttotal: 161ms\tremaining: 686ms\n",
            "190:\tlearn: 0.6882486\ttotal: 162ms\tremaining: 684ms\n",
            "191:\tlearn: 0.6882463\ttotal: 162ms\tremaining: 683ms\n",
            "192:\tlearn: 0.6882463\ttotal: 163ms\tremaining: 681ms\n",
            "193:\tlearn: 0.6882366\ttotal: 164ms\tremaining: 680ms\n",
            "194:\tlearn: 0.6882280\ttotal: 164ms\tremaining: 678ms\n",
            "195:\tlearn: 0.6882231\ttotal: 165ms\tremaining: 677ms\n",
            "196:\tlearn: 0.6882230\ttotal: 166ms\tremaining: 676ms\n",
            "197:\tlearn: 0.6882147\ttotal: 167ms\tremaining: 675ms\n",
            "198:\tlearn: 0.6882062\ttotal: 167ms\tremaining: 673ms\n",
            "199:\tlearn: 0.6882049\ttotal: 168ms\tremaining: 672ms\n",
            "200:\tlearn: 0.6881956\ttotal: 169ms\tremaining: 671ms\n",
            "201:\tlearn: 0.6881986\ttotal: 169ms\tremaining: 669ms\n",
            "202:\tlearn: 0.6881911\ttotal: 170ms\tremaining: 668ms\n",
            "203:\tlearn: 0.6881846\ttotal: 171ms\tremaining: 667ms\n",
            "204:\tlearn: 0.6881744\ttotal: 172ms\tremaining: 666ms\n",
            "205:\tlearn: 0.6881674\ttotal: 172ms\tremaining: 665ms\n",
            "206:\tlearn: 0.6881595\ttotal: 173ms\tremaining: 664ms\n",
            "207:\tlearn: 0.6881537\ttotal: 174ms\tremaining: 663ms\n",
            "208:\tlearn: 0.6881434\ttotal: 175ms\tremaining: 661ms\n",
            "209:\tlearn: 0.6881452\ttotal: 175ms\tremaining: 660ms\n",
            "210:\tlearn: 0.6881372\ttotal: 176ms\tremaining: 659ms\n",
            "211:\tlearn: 0.6881298\ttotal: 177ms\tremaining: 658ms\n",
            "212:\tlearn: 0.6881274\ttotal: 178ms\tremaining: 657ms\n",
            "213:\tlearn: 0.6881317\ttotal: 178ms\tremaining: 655ms\n",
            "214:\tlearn: 0.6881231\ttotal: 179ms\tremaining: 654ms\n",
            "215:\tlearn: 0.6881206\ttotal: 180ms\tremaining: 653ms\n",
            "216:\tlearn: 0.6881170\ttotal: 181ms\tremaining: 652ms\n",
            "217:\tlearn: 0.6881129\ttotal: 181ms\tremaining: 650ms\n",
            "218:\tlearn: 0.6881142\ttotal: 182ms\tremaining: 649ms\n",
            "219:\tlearn: 0.6881068\ttotal: 183ms\tremaining: 648ms\n",
            "220:\tlearn: 0.6880964\ttotal: 183ms\tremaining: 647ms\n",
            "221:\tlearn: 0.6880908\ttotal: 184ms\tremaining: 646ms\n",
            "222:\tlearn: 0.6880855\ttotal: 185ms\tremaining: 644ms\n",
            "223:\tlearn: 0.6880802\ttotal: 186ms\tremaining: 643ms\n",
            "224:\tlearn: 0.6880742\ttotal: 186ms\tremaining: 642ms\n",
            "225:\tlearn: 0.6880703\ttotal: 187ms\tremaining: 641ms\n",
            "226:\tlearn: 0.6880644\ttotal: 188ms\tremaining: 640ms\n",
            "227:\tlearn: 0.6880661\ttotal: 189ms\tremaining: 639ms\n",
            "228:\tlearn: 0.6880617\ttotal: 189ms\tremaining: 638ms\n",
            "229:\tlearn: 0.6880514\ttotal: 190ms\tremaining: 637ms\n",
            "230:\tlearn: 0.6880478\ttotal: 191ms\tremaining: 635ms\n",
            "231:\tlearn: 0.6880479\ttotal: 192ms\tremaining: 634ms\n",
            "232:\tlearn: 0.6880432\ttotal: 192ms\tremaining: 633ms\n",
            "233:\tlearn: 0.6880365\ttotal: 193ms\tremaining: 632ms\n",
            "234:\tlearn: 0.6880305\ttotal: 194ms\tremaining: 631ms\n",
            "235:\tlearn: 0.6880340\ttotal: 195ms\tremaining: 630ms\n",
            "236:\tlearn: 0.6880321\ttotal: 195ms\tremaining: 628ms\n",
            "237:\tlearn: 0.6880274\ttotal: 196ms\tremaining: 626ms\n",
            "238:\tlearn: 0.6880244\ttotal: 196ms\tremaining: 625ms\n",
            "239:\tlearn: 0.6880161\ttotal: 197ms\tremaining: 624ms\n",
            "240:\tlearn: 0.6880177\ttotal: 198ms\tremaining: 623ms\n",
            "241:\tlearn: 0.6880059\ttotal: 199ms\tremaining: 622ms\n",
            "242:\tlearn: 0.6880065\ttotal: 199ms\tremaining: 621ms\n",
            "243:\tlearn: 0.6880050\ttotal: 200ms\tremaining: 620ms\n",
            "244:\tlearn: 0.6880038\ttotal: 201ms\tremaining: 619ms\n",
            "245:\tlearn: 0.6879933\ttotal: 202ms\tremaining: 618ms\n",
            "246:\tlearn: 0.6879879\ttotal: 202ms\tremaining: 617ms\n",
            "247:\tlearn: 0.6879896\ttotal: 203ms\tremaining: 616ms\n",
            "248:\tlearn: 0.6879795\ttotal: 204ms\tremaining: 615ms\n",
            "249:\tlearn: 0.6879774\ttotal: 205ms\tremaining: 614ms\n",
            "250:\tlearn: 0.6879740\ttotal: 205ms\tremaining: 613ms\n",
            "251:\tlearn: 0.6879727\ttotal: 206ms\tremaining: 612ms\n",
            "252:\tlearn: 0.6879712\ttotal: 207ms\tremaining: 611ms\n",
            "253:\tlearn: 0.6879741\ttotal: 208ms\tremaining: 610ms\n",
            "254:\tlearn: 0.6879690\ttotal: 208ms\tremaining: 609ms\n",
            "255:\tlearn: 0.6879645\ttotal: 209ms\tremaining: 608ms\n",
            "256:\tlearn: 0.6879581\ttotal: 210ms\tremaining: 607ms\n",
            "257:\tlearn: 0.6879592\ttotal: 210ms\tremaining: 605ms\n",
            "258:\tlearn: 0.6879586\ttotal: 211ms\tremaining: 604ms\n",
            "259:\tlearn: 0.6879514\ttotal: 212ms\tremaining: 603ms\n",
            "260:\tlearn: 0.6879557\ttotal: 213ms\tremaining: 602ms\n",
            "261:\tlearn: 0.6879486\ttotal: 213ms\tremaining: 601ms\n",
            "262:\tlearn: 0.6879549\ttotal: 214ms\tremaining: 600ms\n",
            "263:\tlearn: 0.6879447\ttotal: 215ms\tremaining: 599ms\n",
            "264:\tlearn: 0.6879435\ttotal: 216ms\tremaining: 598ms\n",
            "265:\tlearn: 0.6879400\ttotal: 216ms\tremaining: 597ms\n",
            "266:\tlearn: 0.6879322\ttotal: 217ms\tremaining: 596ms\n",
            "267:\tlearn: 0.6879280\ttotal: 218ms\tremaining: 595ms\n",
            "268:\tlearn: 0.6879236\ttotal: 219ms\tremaining: 594ms\n",
            "269:\tlearn: 0.6879229\ttotal: 219ms\tremaining: 593ms\n",
            "270:\tlearn: 0.6879135\ttotal: 220ms\tremaining: 593ms\n",
            "271:\tlearn: 0.6879144\ttotal: 221ms\tremaining: 592ms\n",
            "272:\tlearn: 0.6879061\ttotal: 222ms\tremaining: 591ms\n",
            "273:\tlearn: 0.6879072\ttotal: 223ms\tremaining: 590ms\n",
            "274:\tlearn: 0.6879065\ttotal: 223ms\tremaining: 589ms\n",
            "275:\tlearn: 0.6879046\ttotal: 224ms\tremaining: 587ms\n",
            "276:\tlearn: 0.6878997\ttotal: 225ms\tremaining: 586ms\n",
            "277:\tlearn: 0.6878987\ttotal: 225ms\tremaining: 585ms\n",
            "278:\tlearn: 0.6878976\ttotal: 226ms\tremaining: 584ms\n",
            "279:\tlearn: 0.6878983\ttotal: 227ms\tremaining: 583ms\n",
            "280:\tlearn: 0.6878904\ttotal: 228ms\tremaining: 582ms\n",
            "281:\tlearn: 0.6878878\ttotal: 228ms\tremaining: 582ms\n",
            "282:\tlearn: 0.6878856\ttotal: 229ms\tremaining: 581ms\n",
            "283:\tlearn: 0.6878801\ttotal: 230ms\tremaining: 580ms\n",
            "284:\tlearn: 0.6878783\ttotal: 231ms\tremaining: 579ms\n",
            "285:\tlearn: 0.6878707\ttotal: 231ms\tremaining: 578ms\n",
            "286:\tlearn: 0.6878700\ttotal: 232ms\tremaining: 577ms\n",
            "287:\tlearn: 0.6878669\ttotal: 233ms\tremaining: 576ms\n",
            "288:\tlearn: 0.6878618\ttotal: 234ms\tremaining: 575ms\n",
            "289:\tlearn: 0.6878621\ttotal: 235ms\tremaining: 574ms\n",
            "290:\tlearn: 0.6878568\ttotal: 235ms\tremaining: 573ms\n",
            "291:\tlearn: 0.6878571\ttotal: 236ms\tremaining: 572ms\n",
            "292:\tlearn: 0.6878577\ttotal: 237ms\tremaining: 571ms\n",
            "293:\tlearn: 0.6878506\ttotal: 237ms\tremaining: 570ms\n",
            "294:\tlearn: 0.6878476\ttotal: 238ms\tremaining: 569ms\n",
            "295:\tlearn: 0.6878513\ttotal: 239ms\tremaining: 568ms\n",
            "296:\tlearn: 0.6878464\ttotal: 240ms\tremaining: 567ms\n",
            "297:\tlearn: 0.6878494\ttotal: 241ms\tremaining: 567ms\n",
            "298:\tlearn: 0.6878447\ttotal: 241ms\tremaining: 565ms\n",
            "299:\tlearn: 0.6878433\ttotal: 242ms\tremaining: 564ms\n",
            "300:\tlearn: 0.6878396\ttotal: 243ms\tremaining: 564ms\n",
            "301:\tlearn: 0.6878375\ttotal: 243ms\tremaining: 563ms\n",
            "302:\tlearn: 0.6878355\ttotal: 244ms\tremaining: 562ms\n",
            "303:\tlearn: 0.6878355\ttotal: 245ms\tremaining: 560ms\n",
            "304:\tlearn: 0.6878293\ttotal: 246ms\tremaining: 560ms\n",
            "305:\tlearn: 0.6878291\ttotal: 246ms\tremaining: 559ms\n",
            "306:\tlearn: 0.6878242\ttotal: 247ms\tremaining: 558ms\n",
            "307:\tlearn: 0.6878225\ttotal: 248ms\tremaining: 557ms\n",
            "308:\tlearn: 0.6878164\ttotal: 249ms\tremaining: 556ms\n",
            "309:\tlearn: 0.6878165\ttotal: 249ms\tremaining: 555ms\n",
            "310:\tlearn: 0.6878125\ttotal: 250ms\tremaining: 554ms\n",
            "311:\tlearn: 0.6878116\ttotal: 251ms\tremaining: 553ms\n",
            "312:\tlearn: 0.6878111\ttotal: 252ms\tremaining: 552ms\n",
            "313:\tlearn: 0.6878099\ttotal: 252ms\tremaining: 551ms\n",
            "314:\tlearn: 0.6878078\ttotal: 254ms\tremaining: 552ms\n",
            "315:\tlearn: 0.6878066\ttotal: 255ms\tremaining: 551ms\n",
            "316:\tlearn: 0.6878036\ttotal: 255ms\tremaining: 550ms\n",
            "317:\tlearn: 0.6878015\ttotal: 256ms\tremaining: 549ms\n",
            "318:\tlearn: 0.6877951\ttotal: 257ms\tremaining: 548ms\n",
            "319:\tlearn: 0.6877924\ttotal: 257ms\tremaining: 547ms\n",
            "320:\tlearn: 0.6877952\ttotal: 258ms\tremaining: 546ms\n",
            "321:\tlearn: 0.6877906\ttotal: 259ms\tremaining: 545ms\n",
            "322:\tlearn: 0.6877918\ttotal: 259ms\tremaining: 543ms\n",
            "323:\tlearn: 0.6877836\ttotal: 260ms\tremaining: 543ms\n",
            "324:\tlearn: 0.6877851\ttotal: 261ms\tremaining: 542ms\n",
            "325:\tlearn: 0.6877780\ttotal: 262ms\tremaining: 541ms\n",
            "326:\tlearn: 0.6877827\ttotal: 262ms\tremaining: 540ms\n",
            "327:\tlearn: 0.6877781\ttotal: 263ms\tremaining: 538ms\n",
            "328:\tlearn: 0.6877754\ttotal: 263ms\tremaining: 537ms\n",
            "329:\tlearn: 0.6877753\ttotal: 264ms\tremaining: 535ms\n",
            "330:\tlearn: 0.6877727\ttotal: 264ms\tremaining: 534ms\n",
            "331:\tlearn: 0.6877715\ttotal: 265ms\tremaining: 533ms\n",
            "332:\tlearn: 0.6877713\ttotal: 265ms\tremaining: 531ms\n",
            "333:\tlearn: 0.6877706\ttotal: 266ms\tremaining: 530ms\n",
            "334:\tlearn: 0.6877671\ttotal: 266ms\tremaining: 528ms\n",
            "335:\tlearn: 0.6877631\ttotal: 267ms\tremaining: 527ms\n",
            "336:\tlearn: 0.6877634\ttotal: 268ms\tremaining: 526ms\n",
            "337:\tlearn: 0.6877620\ttotal: 268ms\tremaining: 525ms\n",
            "338:\tlearn: 0.6877569\ttotal: 269ms\tremaining: 525ms\n",
            "339:\tlearn: 0.6877575\ttotal: 270ms\tremaining: 524ms\n",
            "340:\tlearn: 0.6877573\ttotal: 271ms\tremaining: 523ms\n",
            "341:\tlearn: 0.6877576\ttotal: 271ms\tremaining: 522ms\n",
            "342:\tlearn: 0.6877511\ttotal: 272ms\tremaining: 521ms\n",
            "343:\tlearn: 0.6877516\ttotal: 273ms\tremaining: 521ms\n",
            "344:\tlearn: 0.6877445\ttotal: 274ms\tremaining: 520ms\n",
            "345:\tlearn: 0.6877432\ttotal: 274ms\tremaining: 519ms\n",
            "346:\tlearn: 0.6877424\ttotal: 275ms\tremaining: 518ms\n",
            "347:\tlearn: 0.6877463\ttotal: 276ms\tremaining: 517ms\n",
            "348:\tlearn: 0.6877428\ttotal: 276ms\tremaining: 516ms\n",
            "349:\tlearn: 0.6877429\ttotal: 277ms\tremaining: 515ms\n",
            "350:\tlearn: 0.6877405\ttotal: 278ms\tremaining: 514ms\n",
            "351:\tlearn: 0.6877396\ttotal: 278ms\tremaining: 512ms\n",
            "352:\tlearn: 0.6877366\ttotal: 279ms\tremaining: 512ms\n",
            "353:\tlearn: 0.6877348\ttotal: 280ms\tremaining: 511ms\n",
            "354:\tlearn: 0.6877340\ttotal: 281ms\tremaining: 510ms\n",
            "355:\tlearn: 0.6877309\ttotal: 281ms\tremaining: 509ms\n",
            "356:\tlearn: 0.6877267\ttotal: 282ms\tremaining: 508ms\n",
            "357:\tlearn: 0.6877285\ttotal: 283ms\tremaining: 507ms\n",
            "358:\tlearn: 0.6877275\ttotal: 284ms\tremaining: 506ms\n",
            "359:\tlearn: 0.6877244\ttotal: 284ms\tremaining: 505ms\n",
            "360:\tlearn: 0.6877265\ttotal: 285ms\tremaining: 504ms\n",
            "361:\tlearn: 0.6877243\ttotal: 286ms\tremaining: 504ms\n",
            "362:\tlearn: 0.6877193\ttotal: 287ms\tremaining: 503ms\n",
            "363:\tlearn: 0.6877193\ttotal: 287ms\tremaining: 502ms\n",
            "364:\tlearn: 0.6877187\ttotal: 288ms\tremaining: 502ms\n",
            "365:\tlearn: 0.6877163\ttotal: 289ms\tremaining: 501ms\n",
            "366:\tlearn: 0.6877156\ttotal: 290ms\tremaining: 500ms\n",
            "367:\tlearn: 0.6877106\ttotal: 291ms\tremaining: 499ms\n",
            "368:\tlearn: 0.6877090\ttotal: 291ms\tremaining: 498ms\n",
            "369:\tlearn: 0.6877092\ttotal: 292ms\tremaining: 497ms\n",
            "370:\tlearn: 0.6877072\ttotal: 293ms\tremaining: 496ms\n",
            "371:\tlearn: 0.6877072\ttotal: 293ms\tremaining: 495ms\n",
            "372:\tlearn: 0.6877058\ttotal: 294ms\tremaining: 494ms\n",
            "373:\tlearn: 0.6877066\ttotal: 295ms\tremaining: 493ms\n",
            "374:\tlearn: 0.6877062\ttotal: 295ms\tremaining: 492ms\n",
            "375:\tlearn: 0.6877062\ttotal: 296ms\tremaining: 492ms\n",
            "376:\tlearn: 0.6877012\ttotal: 297ms\tremaining: 491ms\n",
            "377:\tlearn: 0.6877013\ttotal: 298ms\tremaining: 490ms\n",
            "378:\tlearn: 0.6876991\ttotal: 298ms\tremaining: 489ms\n",
            "379:\tlearn: 0.6876999\ttotal: 299ms\tremaining: 488ms\n",
            "380:\tlearn: 0.6876943\ttotal: 300ms\tremaining: 488ms\n",
            "381:\tlearn: 0.6876957\ttotal: 301ms\tremaining: 487ms\n",
            "382:\tlearn: 0.6876983\ttotal: 302ms\tremaining: 486ms\n",
            "383:\tlearn: 0.6876925\ttotal: 302ms\tremaining: 485ms\n",
            "384:\tlearn: 0.6876939\ttotal: 303ms\tremaining: 484ms\n",
            "385:\tlearn: 0.6876938\ttotal: 304ms\tremaining: 483ms\n",
            "386:\tlearn: 0.6876913\ttotal: 304ms\tremaining: 482ms\n",
            "387:\tlearn: 0.6876892\ttotal: 305ms\tremaining: 481ms\n",
            "388:\tlearn: 0.6876885\ttotal: 306ms\tremaining: 480ms\n",
            "389:\tlearn: 0.6876887\ttotal: 307ms\tremaining: 480ms\n",
            "390:\tlearn: 0.6876854\ttotal: 307ms\tremaining: 479ms\n",
            "391:\tlearn: 0.6876860\ttotal: 308ms\tremaining: 478ms\n",
            "392:\tlearn: 0.6876886\ttotal: 309ms\tremaining: 477ms\n",
            "393:\tlearn: 0.6876881\ttotal: 310ms\tremaining: 476ms\n",
            "394:\tlearn: 0.6876871\ttotal: 310ms\tremaining: 475ms\n",
            "395:\tlearn: 0.6876818\ttotal: 311ms\tremaining: 475ms\n",
            "396:\tlearn: 0.6876818\ttotal: 312ms\tremaining: 474ms\n",
            "397:\tlearn: 0.6876821\ttotal: 313ms\tremaining: 473ms\n",
            "398:\tlearn: 0.6876793\ttotal: 313ms\tremaining: 472ms\n",
            "399:\tlearn: 0.6876806\ttotal: 314ms\tremaining: 471ms\n",
            "400:\tlearn: 0.6876786\ttotal: 315ms\tremaining: 470ms\n",
            "401:\tlearn: 0.6876792\ttotal: 315ms\tremaining: 469ms\n",
            "402:\tlearn: 0.6876780\ttotal: 316ms\tremaining: 469ms\n",
            "403:\tlearn: 0.6876775\ttotal: 317ms\tremaining: 468ms\n",
            "404:\tlearn: 0.6876757\ttotal: 318ms\tremaining: 467ms\n",
            "405:\tlearn: 0.6876743\ttotal: 319ms\tremaining: 466ms\n",
            "406:\tlearn: 0.6876737\ttotal: 319ms\tremaining: 465ms\n",
            "407:\tlearn: 0.6876752\ttotal: 320ms\tremaining: 465ms\n",
            "408:\tlearn: 0.6876713\ttotal: 321ms\tremaining: 464ms\n",
            "409:\tlearn: 0.6876725\ttotal: 322ms\tremaining: 463ms\n",
            "410:\tlearn: 0.6876700\ttotal: 322ms\tremaining: 462ms\n",
            "411:\tlearn: 0.6876659\ttotal: 323ms\tremaining: 461ms\n",
            "412:\tlearn: 0.6876660\ttotal: 324ms\tremaining: 460ms\n",
            "413:\tlearn: 0.6876646\ttotal: 325ms\tremaining: 460ms\n",
            "414:\tlearn: 0.6876654\ttotal: 325ms\tremaining: 459ms\n",
            "415:\tlearn: 0.6876656\ttotal: 326ms\tremaining: 458ms\n",
            "416:\tlearn: 0.6876664\ttotal: 327ms\tremaining: 457ms\n",
            "417:\tlearn: 0.6876643\ttotal: 328ms\tremaining: 456ms\n",
            "418:\tlearn: 0.6876622\ttotal: 328ms\tremaining: 455ms\n",
            "419:\tlearn: 0.6876618\ttotal: 329ms\tremaining: 454ms\n",
            "420:\tlearn: 0.6876624\ttotal: 330ms\tremaining: 454ms\n",
            "421:\tlearn: 0.6876623\ttotal: 331ms\tremaining: 453ms\n",
            "422:\tlearn: 0.6876611\ttotal: 331ms\tremaining: 452ms\n",
            "423:\tlearn: 0.6876627\ttotal: 332ms\tremaining: 451ms\n",
            "424:\tlearn: 0.6876610\ttotal: 333ms\tremaining: 450ms\n",
            "425:\tlearn: 0.6876587\ttotal: 333ms\tremaining: 449ms\n",
            "426:\tlearn: 0.6876572\ttotal: 334ms\tremaining: 448ms\n",
            "427:\tlearn: 0.6876575\ttotal: 335ms\tremaining: 448ms\n",
            "428:\tlearn: 0.6876564\ttotal: 336ms\tremaining: 447ms\n",
            "429:\tlearn: 0.6876574\ttotal: 336ms\tremaining: 446ms\n",
            "430:\tlearn: 0.6876571\ttotal: 337ms\tremaining: 445ms\n",
            "431:\tlearn: 0.6876516\ttotal: 338ms\tremaining: 444ms\n",
            "432:\tlearn: 0.6876542\ttotal: 339ms\tremaining: 443ms\n",
            "433:\tlearn: 0.6876552\ttotal: 339ms\tremaining: 442ms\n",
            "434:\tlearn: 0.6876541\ttotal: 340ms\tremaining: 442ms\n",
            "435:\tlearn: 0.6876545\ttotal: 341ms\tremaining: 441ms\n",
            "436:\tlearn: 0.6876488\ttotal: 341ms\tremaining: 440ms\n",
            "437:\tlearn: 0.6876488\ttotal: 342ms\tremaining: 439ms\n",
            "438:\tlearn: 0.6876489\ttotal: 343ms\tremaining: 438ms\n",
            "439:\tlearn: 0.6876505\ttotal: 344ms\tremaining: 438ms\n",
            "440:\tlearn: 0.6876500\ttotal: 345ms\tremaining: 437ms\n",
            "441:\tlearn: 0.6876516\ttotal: 345ms\tremaining: 436ms\n",
            "442:\tlearn: 0.6876497\ttotal: 346ms\tremaining: 435ms\n",
            "443:\tlearn: 0.6876458\ttotal: 347ms\tremaining: 434ms\n",
            "444:\tlearn: 0.6876450\ttotal: 348ms\tremaining: 434ms\n",
            "445:\tlearn: 0.6876449\ttotal: 348ms\tremaining: 433ms\n",
            "446:\tlearn: 0.6876455\ttotal: 349ms\tremaining: 432ms\n",
            "447:\tlearn: 0.6876421\ttotal: 350ms\tremaining: 431ms\n",
            "448:\tlearn: 0.6876408\ttotal: 351ms\tremaining: 430ms\n",
            "449:\tlearn: 0.6876415\ttotal: 352ms\tremaining: 430ms\n",
            "450:\tlearn: 0.6876359\ttotal: 353ms\tremaining: 429ms\n",
            "451:\tlearn: 0.6876383\ttotal: 354ms\tremaining: 429ms\n",
            "452:\tlearn: 0.6876374\ttotal: 354ms\tremaining: 428ms\n",
            "453:\tlearn: 0.6876382\ttotal: 355ms\tremaining: 427ms\n",
            "454:\tlearn: 0.6876341\ttotal: 356ms\tremaining: 427ms\n",
            "455:\tlearn: 0.6876341\ttotal: 357ms\tremaining: 426ms\n",
            "456:\tlearn: 0.6876340\ttotal: 358ms\tremaining: 425ms\n",
            "457:\tlearn: 0.6876355\ttotal: 358ms\tremaining: 424ms\n",
            "458:\tlearn: 0.6876302\ttotal: 359ms\tremaining: 423ms\n",
            "459:\tlearn: 0.6876287\ttotal: 360ms\tremaining: 423ms\n",
            "460:\tlearn: 0.6876273\ttotal: 361ms\tremaining: 422ms\n",
            "461:\tlearn: 0.6876273\ttotal: 361ms\tremaining: 421ms\n",
            "462:\tlearn: 0.6876287\ttotal: 362ms\tremaining: 420ms\n",
            "463:\tlearn: 0.6876324\ttotal: 363ms\tremaining: 419ms\n",
            "464:\tlearn: 0.6876323\ttotal: 364ms\tremaining: 418ms\n",
            "465:\tlearn: 0.6876301\ttotal: 364ms\tremaining: 417ms\n",
            "466:\tlearn: 0.6876255\ttotal: 365ms\tremaining: 417ms\n",
            "467:\tlearn: 0.6876250\ttotal: 366ms\tremaining: 416ms\n",
            "468:\tlearn: 0.6876258\ttotal: 367ms\tremaining: 415ms\n",
            "469:\tlearn: 0.6876212\ttotal: 367ms\tremaining: 414ms\n",
            "470:\tlearn: 0.6876196\ttotal: 368ms\tremaining: 414ms\n",
            "471:\tlearn: 0.6876208\ttotal: 369ms\tremaining: 413ms\n",
            "472:\tlearn: 0.6876209\ttotal: 370ms\tremaining: 412ms\n",
            "473:\tlearn: 0.6876224\ttotal: 371ms\tremaining: 411ms\n",
            "474:\tlearn: 0.6876197\ttotal: 371ms\tremaining: 410ms\n",
            "475:\tlearn: 0.6876189\ttotal: 372ms\tremaining: 410ms\n",
            "476:\tlearn: 0.6876203\ttotal: 373ms\tremaining: 409ms\n",
            "477:\tlearn: 0.6876203\ttotal: 374ms\tremaining: 408ms\n",
            "478:\tlearn: 0.6876227\ttotal: 374ms\tremaining: 407ms\n",
            "479:\tlearn: 0.6876199\ttotal: 375ms\tremaining: 406ms\n",
            "480:\tlearn: 0.6876194\ttotal: 376ms\tremaining: 405ms\n",
            "481:\tlearn: 0.6876219\ttotal: 377ms\tremaining: 405ms\n",
            "482:\tlearn: 0.6876211\ttotal: 378ms\tremaining: 404ms\n",
            "483:\tlearn: 0.6876156\ttotal: 379ms\tremaining: 404ms\n",
            "484:\tlearn: 0.6876150\ttotal: 380ms\tremaining: 403ms\n",
            "485:\tlearn: 0.6876175\ttotal: 380ms\tremaining: 402ms\n",
            "486:\tlearn: 0.6876151\ttotal: 381ms\tremaining: 401ms\n",
            "487:\tlearn: 0.6876151\ttotal: 382ms\tremaining: 401ms\n",
            "488:\tlearn: 0.6876134\ttotal: 383ms\tremaining: 400ms\n",
            "489:\tlearn: 0.6876123\ttotal: 383ms\tremaining: 399ms\n",
            "490:\tlearn: 0.6876118\ttotal: 384ms\tremaining: 398ms\n",
            "491:\tlearn: 0.6876116\ttotal: 385ms\tremaining: 398ms\n",
            "492:\tlearn: 0.6876097\ttotal: 386ms\tremaining: 397ms\n",
            "493:\tlearn: 0.6876112\ttotal: 387ms\tremaining: 396ms\n",
            "494:\tlearn: 0.6876097\ttotal: 388ms\tremaining: 396ms\n",
            "495:\tlearn: 0.6876126\ttotal: 389ms\tremaining: 395ms\n",
            "496:\tlearn: 0.6876066\ttotal: 390ms\tremaining: 394ms\n",
            "497:\tlearn: 0.6876079\ttotal: 390ms\tremaining: 394ms\n",
            "498:\tlearn: 0.6876078\ttotal: 391ms\tremaining: 393ms\n",
            "499:\tlearn: 0.6876078\ttotal: 392ms\tremaining: 392ms\n",
            "500:\tlearn: 0.6876081\ttotal: 393ms\tremaining: 391ms\n",
            "501:\tlearn: 0.6876064\ttotal: 394ms\tremaining: 390ms\n",
            "502:\tlearn: 0.6876020\ttotal: 394ms\tremaining: 390ms\n",
            "503:\tlearn: 0.6876020\ttotal: 395ms\tremaining: 389ms\n",
            "504:\tlearn: 0.6876059\ttotal: 396ms\tremaining: 388ms\n",
            "505:\tlearn: 0.6876012\ttotal: 397ms\tremaining: 387ms\n",
            "506:\tlearn: 0.6876010\ttotal: 397ms\tremaining: 386ms\n",
            "507:\tlearn: 0.6876038\ttotal: 398ms\tremaining: 386ms\n",
            "508:\tlearn: 0.6876015\ttotal: 399ms\tremaining: 385ms\n",
            "509:\tlearn: 0.6876023\ttotal: 400ms\tremaining: 384ms\n",
            "510:\tlearn: 0.6875987\ttotal: 401ms\tremaining: 383ms\n",
            "511:\tlearn: 0.6875962\ttotal: 401ms\tremaining: 383ms\n",
            "512:\tlearn: 0.6875983\ttotal: 403ms\tremaining: 382ms\n",
            "513:\tlearn: 0.6875965\ttotal: 403ms\tremaining: 381ms\n",
            "514:\tlearn: 0.6875967\ttotal: 404ms\tremaining: 380ms\n",
            "515:\tlearn: 0.6875966\ttotal: 405ms\tremaining: 380ms\n",
            "516:\tlearn: 0.6875975\ttotal: 405ms\tremaining: 379ms\n",
            "517:\tlearn: 0.6875941\ttotal: 406ms\tremaining: 378ms\n",
            "518:\tlearn: 0.6875924\ttotal: 407ms\tremaining: 377ms\n",
            "519:\tlearn: 0.6875966\ttotal: 408ms\tremaining: 376ms\n",
            "520:\tlearn: 0.6875960\ttotal: 409ms\tremaining: 376ms\n",
            "521:\tlearn: 0.6875971\ttotal: 410ms\tremaining: 375ms\n",
            "522:\tlearn: 0.6875917\ttotal: 410ms\tremaining: 374ms\n",
            "523:\tlearn: 0.6875923\ttotal: 411ms\tremaining: 373ms\n",
            "524:\tlearn: 0.6875921\ttotal: 412ms\tremaining: 372ms\n",
            "525:\tlearn: 0.6875913\ttotal: 412ms\tremaining: 372ms\n",
            "526:\tlearn: 0.6875937\ttotal: 413ms\tremaining: 371ms\n",
            "527:\tlearn: 0.6875928\ttotal: 414ms\tremaining: 370ms\n",
            "528:\tlearn: 0.6875907\ttotal: 415ms\tremaining: 369ms\n",
            "529:\tlearn: 0.6875915\ttotal: 415ms\tremaining: 368ms\n",
            "530:\tlearn: 0.6875905\ttotal: 416ms\tremaining: 368ms\n",
            "531:\tlearn: 0.6875915\ttotal: 417ms\tremaining: 367ms\n",
            "532:\tlearn: 0.6875863\ttotal: 418ms\tremaining: 366ms\n",
            "533:\tlearn: 0.6875856\ttotal: 418ms\tremaining: 365ms\n",
            "534:\tlearn: 0.6875869\ttotal: 419ms\tremaining: 364ms\n",
            "535:\tlearn: 0.6875859\ttotal: 420ms\tremaining: 364ms\n",
            "536:\tlearn: 0.6875852\ttotal: 421ms\tremaining: 363ms\n",
            "537:\tlearn: 0.6875872\ttotal: 421ms\tremaining: 362ms\n",
            "538:\tlearn: 0.6875887\ttotal: 422ms\tremaining: 361ms\n",
            "539:\tlearn: 0.6875836\ttotal: 424ms\tremaining: 361ms\n",
            "540:\tlearn: 0.6875836\ttotal: 427ms\tremaining: 362ms\n",
            "541:\tlearn: 0.6875838\ttotal: 427ms\tremaining: 361ms\n",
            "542:\tlearn: 0.6875846\ttotal: 427ms\tremaining: 360ms\n",
            "543:\tlearn: 0.6875845\ttotal: 428ms\tremaining: 359ms\n",
            "544:\tlearn: 0.6875847\ttotal: 429ms\tremaining: 358ms\n",
            "545:\tlearn: 0.6875846\ttotal: 429ms\tremaining: 357ms\n",
            "546:\tlearn: 0.6875836\ttotal: 430ms\tremaining: 356ms\n",
            "547:\tlearn: 0.6875808\ttotal: 430ms\tremaining: 355ms\n",
            "548:\tlearn: 0.6875808\ttotal: 431ms\tremaining: 354ms\n",
            "549:\tlearn: 0.6875808\ttotal: 431ms\tremaining: 353ms\n",
            "550:\tlearn: 0.6875807\ttotal: 432ms\tremaining: 352ms\n",
            "551:\tlearn: 0.6875810\ttotal: 432ms\tremaining: 351ms\n",
            "552:\tlearn: 0.6875810\ttotal: 433ms\tremaining: 350ms\n",
            "553:\tlearn: 0.6875810\ttotal: 434ms\tremaining: 350ms\n",
            "554:\tlearn: 0.6875808\ttotal: 435ms\tremaining: 349ms\n",
            "555:\tlearn: 0.6875810\ttotal: 436ms\tremaining: 348ms\n",
            "556:\tlearn: 0.6875801\ttotal: 436ms\tremaining: 347ms\n",
            "557:\tlearn: 0.6875804\ttotal: 437ms\tremaining: 346ms\n",
            "558:\tlearn: 0.6875823\ttotal: 438ms\tremaining: 345ms\n",
            "559:\tlearn: 0.6875762\ttotal: 439ms\tremaining: 345ms\n",
            "560:\tlearn: 0.6875778\ttotal: 439ms\tremaining: 344ms\n",
            "561:\tlearn: 0.6875763\ttotal: 440ms\tremaining: 343ms\n",
            "562:\tlearn: 0.6875779\ttotal: 441ms\tremaining: 342ms\n",
            "563:\tlearn: 0.6875777\ttotal: 442ms\tremaining: 341ms\n",
            "564:\tlearn: 0.6875777\ttotal: 442ms\tremaining: 340ms\n",
            "565:\tlearn: 0.6875756\ttotal: 443ms\tremaining: 340ms\n",
            "566:\tlearn: 0.6875771\ttotal: 444ms\tremaining: 339ms\n",
            "567:\tlearn: 0.6875796\ttotal: 444ms\tremaining: 338ms\n",
            "568:\tlearn: 0.6875779\ttotal: 445ms\tremaining: 337ms\n",
            "569:\tlearn: 0.6875779\ttotal: 446ms\tremaining: 336ms\n",
            "570:\tlearn: 0.6875727\ttotal: 447ms\tremaining: 335ms\n",
            "571:\tlearn: 0.6875722\ttotal: 447ms\tremaining: 335ms\n",
            "572:\tlearn: 0.6875727\ttotal: 448ms\tremaining: 334ms\n",
            "573:\tlearn: 0.6875741\ttotal: 449ms\tremaining: 333ms\n",
            "574:\tlearn: 0.6875741\ttotal: 449ms\tremaining: 332ms\n",
            "575:\tlearn: 0.6875745\ttotal: 450ms\tremaining: 331ms\n",
            "576:\tlearn: 0.6875751\ttotal: 451ms\tremaining: 331ms\n",
            "577:\tlearn: 0.6875700\ttotal: 452ms\tremaining: 330ms\n",
            "578:\tlearn: 0.6875700\ttotal: 452ms\tremaining: 329ms\n",
            "579:\tlearn: 0.6875716\ttotal: 453ms\tremaining: 328ms\n",
            "580:\tlearn: 0.6875722\ttotal: 454ms\tremaining: 327ms\n",
            "581:\tlearn: 0.6875724\ttotal: 455ms\tremaining: 327ms\n",
            "582:\tlearn: 0.6875697\ttotal: 455ms\tremaining: 326ms\n",
            "583:\tlearn: 0.6875648\ttotal: 456ms\tremaining: 325ms\n",
            "584:\tlearn: 0.6875648\ttotal: 457ms\tremaining: 324ms\n",
            "585:\tlearn: 0.6875651\ttotal: 458ms\tremaining: 323ms\n",
            "586:\tlearn: 0.6875651\ttotal: 458ms\tremaining: 322ms\n",
            "587:\tlearn: 0.6875675\ttotal: 459ms\tremaining: 322ms\n",
            "588:\tlearn: 0.6875688\ttotal: 460ms\tremaining: 321ms\n",
            "589:\tlearn: 0.6875668\ttotal: 461ms\tremaining: 320ms\n",
            "590:\tlearn: 0.6875668\ttotal: 461ms\tremaining: 319ms\n",
            "591:\tlearn: 0.6875667\ttotal: 462ms\tremaining: 318ms\n",
            "592:\tlearn: 0.6875669\ttotal: 463ms\tremaining: 318ms\n",
            "593:\tlearn: 0.6875687\ttotal: 463ms\tremaining: 317ms\n",
            "594:\tlearn: 0.6875672\ttotal: 464ms\tremaining: 316ms\n",
            "595:\tlearn: 0.6875617\ttotal: 465ms\tremaining: 315ms\n",
            "596:\tlearn: 0.6875639\ttotal: 466ms\tremaining: 314ms\n",
            "597:\tlearn: 0.6875637\ttotal: 467ms\tremaining: 314ms\n",
            "598:\tlearn: 0.6875646\ttotal: 467ms\tremaining: 313ms\n",
            "599:\tlearn: 0.6875605\ttotal: 468ms\tremaining: 312ms\n",
            "600:\tlearn: 0.6875631\ttotal: 469ms\tremaining: 311ms\n",
            "601:\tlearn: 0.6875647\ttotal: 470ms\tremaining: 310ms\n",
            "602:\tlearn: 0.6875647\ttotal: 470ms\tremaining: 310ms\n",
            "603:\tlearn: 0.6875672\ttotal: 471ms\tremaining: 309ms\n",
            "604:\tlearn: 0.6875614\ttotal: 472ms\tremaining: 308ms\n",
            "605:\tlearn: 0.6875608\ttotal: 473ms\tremaining: 307ms\n",
            "606:\tlearn: 0.6875620\ttotal: 473ms\tremaining: 306ms\n",
            "607:\tlearn: 0.6875620\ttotal: 474ms\tremaining: 306ms\n",
            "608:\tlearn: 0.6875639\ttotal: 475ms\tremaining: 305ms\n",
            "609:\tlearn: 0.6875633\ttotal: 475ms\tremaining: 304ms\n",
            "610:\tlearn: 0.6875626\ttotal: 476ms\tremaining: 303ms\n",
            "611:\tlearn: 0.6875572\ttotal: 477ms\tremaining: 302ms\n",
            "612:\tlearn: 0.6875583\ttotal: 478ms\tremaining: 302ms\n",
            "613:\tlearn: 0.6875583\ttotal: 478ms\tremaining: 301ms\n",
            "614:\tlearn: 0.6875605\ttotal: 479ms\tremaining: 300ms\n",
            "615:\tlearn: 0.6875583\ttotal: 480ms\tremaining: 299ms\n",
            "616:\tlearn: 0.6875570\ttotal: 481ms\tremaining: 298ms\n",
            "617:\tlearn: 0.6875614\ttotal: 481ms\tremaining: 297ms\n",
            "618:\tlearn: 0.6875536\ttotal: 482ms\tremaining: 297ms\n",
            "619:\tlearn: 0.6875551\ttotal: 483ms\tremaining: 296ms\n",
            "620:\tlearn: 0.6875551\ttotal: 483ms\tremaining: 295ms\n",
            "621:\tlearn: 0.6875530\ttotal: 484ms\tremaining: 294ms\n",
            "622:\tlearn: 0.6875572\ttotal: 485ms\tremaining: 293ms\n",
            "623:\tlearn: 0.6875573\ttotal: 486ms\tremaining: 293ms\n",
            "624:\tlearn: 0.6875574\ttotal: 486ms\tremaining: 292ms\n",
            "625:\tlearn: 0.6875573\ttotal: 487ms\tremaining: 291ms\n",
            "626:\tlearn: 0.6875507\ttotal: 488ms\tremaining: 290ms\n",
            "627:\tlearn: 0.6875510\ttotal: 489ms\tremaining: 290ms\n",
            "628:\tlearn: 0.6875534\ttotal: 490ms\tremaining: 289ms\n",
            "629:\tlearn: 0.6875513\ttotal: 490ms\tremaining: 288ms\n",
            "630:\tlearn: 0.6875514\ttotal: 491ms\tremaining: 287ms\n",
            "631:\tlearn: 0.6875537\ttotal: 492ms\tremaining: 286ms\n",
            "632:\tlearn: 0.6875544\ttotal: 492ms\tremaining: 285ms\n",
            "633:\tlearn: 0.6875518\ttotal: 493ms\tremaining: 285ms\n",
            "634:\tlearn: 0.6875526\ttotal: 494ms\tremaining: 284ms\n",
            "635:\tlearn: 0.6875534\ttotal: 494ms\tremaining: 283ms\n",
            "636:\tlearn: 0.6875481\ttotal: 495ms\tremaining: 282ms\n",
            "637:\tlearn: 0.6875481\ttotal: 496ms\tremaining: 281ms\n",
            "638:\tlearn: 0.6875487\ttotal: 497ms\tremaining: 281ms\n",
            "639:\tlearn: 0.6875496\ttotal: 497ms\tremaining: 280ms\n",
            "640:\tlearn: 0.6875496\ttotal: 498ms\tremaining: 279ms\n",
            "641:\tlearn: 0.6875523\ttotal: 499ms\tremaining: 278ms\n",
            "642:\tlearn: 0.6875474\ttotal: 500ms\tremaining: 277ms\n",
            "643:\tlearn: 0.6875483\ttotal: 500ms\tremaining: 277ms\n",
            "644:\tlearn: 0.6875505\ttotal: 501ms\tremaining: 276ms\n",
            "645:\tlearn: 0.6875490\ttotal: 502ms\tremaining: 275ms\n",
            "646:\tlearn: 0.6875489\ttotal: 503ms\tremaining: 274ms\n",
            "647:\tlearn: 0.6875490\ttotal: 503ms\tremaining: 273ms\n",
            "648:\tlearn: 0.6875477\ttotal: 504ms\tremaining: 273ms\n",
            "649:\tlearn: 0.6875505\ttotal: 505ms\tremaining: 272ms\n",
            "650:\tlearn: 0.6875430\ttotal: 506ms\tremaining: 271ms\n",
            "651:\tlearn: 0.6875430\ttotal: 506ms\tremaining: 270ms\n",
            "652:\tlearn: 0.6875455\ttotal: 507ms\tremaining: 269ms\n",
            "653:\tlearn: 0.6875461\ttotal: 508ms\tremaining: 269ms\n",
            "654:\tlearn: 0.6875461\ttotal: 509ms\tremaining: 268ms\n",
            "655:\tlearn: 0.6875457\ttotal: 509ms\tremaining: 267ms\n",
            "656:\tlearn: 0.6875457\ttotal: 510ms\tremaining: 266ms\n",
            "657:\tlearn: 0.6875452\ttotal: 511ms\tremaining: 265ms\n",
            "658:\tlearn: 0.6875446\ttotal: 512ms\tremaining: 265ms\n",
            "659:\tlearn: 0.6875465\ttotal: 512ms\tremaining: 264ms\n",
            "660:\tlearn: 0.6875464\ttotal: 513ms\tremaining: 263ms\n",
            "661:\tlearn: 0.6875423\ttotal: 514ms\tremaining: 262ms\n",
            "662:\tlearn: 0.6875423\ttotal: 514ms\tremaining: 261ms\n",
            "663:\tlearn: 0.6875415\ttotal: 515ms\tremaining: 261ms\n",
            "664:\tlearn: 0.6875402\ttotal: 516ms\tremaining: 260ms\n",
            "665:\tlearn: 0.6875430\ttotal: 517ms\tremaining: 259ms\n",
            "666:\tlearn: 0.6875430\ttotal: 517ms\tremaining: 258ms\n",
            "667:\tlearn: 0.6875424\ttotal: 518ms\tremaining: 257ms\n",
            "668:\tlearn: 0.6875418\ttotal: 519ms\tremaining: 257ms\n",
            "669:\tlearn: 0.6875441\ttotal: 519ms\tremaining: 256ms\n",
            "670:\tlearn: 0.6875443\ttotal: 520ms\tremaining: 255ms\n",
            "671:\tlearn: 0.6875417\ttotal: 521ms\tremaining: 254ms\n",
            "672:\tlearn: 0.6875425\ttotal: 522ms\tremaining: 253ms\n",
            "673:\tlearn: 0.6875412\ttotal: 522ms\tremaining: 253ms\n",
            "674:\tlearn: 0.6875430\ttotal: 523ms\tremaining: 252ms\n",
            "675:\tlearn: 0.6875427\ttotal: 524ms\tremaining: 251ms\n",
            "676:\tlearn: 0.6875432\ttotal: 525ms\tremaining: 250ms\n",
            "677:\tlearn: 0.6875415\ttotal: 526ms\tremaining: 250ms\n",
            "678:\tlearn: 0.6875422\ttotal: 526ms\tremaining: 249ms\n",
            "679:\tlearn: 0.6875426\ttotal: 527ms\tremaining: 248ms\n",
            "680:\tlearn: 0.6875392\ttotal: 528ms\tremaining: 247ms\n",
            "681:\tlearn: 0.6875399\ttotal: 529ms\tremaining: 247ms\n",
            "682:\tlearn: 0.6875430\ttotal: 530ms\tremaining: 246ms\n",
            "683:\tlearn: 0.6875401\ttotal: 531ms\tremaining: 245ms\n",
            "684:\tlearn: 0.6875437\ttotal: 531ms\tremaining: 244ms\n",
            "685:\tlearn: 0.6875378\ttotal: 532ms\tremaining: 244ms\n",
            "686:\tlearn: 0.6875390\ttotal: 533ms\tremaining: 243ms\n",
            "687:\tlearn: 0.6875374\ttotal: 534ms\tremaining: 242ms\n",
            "688:\tlearn: 0.6875373\ttotal: 535ms\tremaining: 241ms\n",
            "689:\tlearn: 0.6875400\ttotal: 535ms\tremaining: 241ms\n",
            "690:\tlearn: 0.6875387\ttotal: 536ms\tremaining: 240ms\n",
            "691:\tlearn: 0.6875388\ttotal: 537ms\tremaining: 239ms\n",
            "692:\tlearn: 0.6875386\ttotal: 538ms\tremaining: 238ms\n",
            "693:\tlearn: 0.6875398\ttotal: 539ms\tremaining: 238ms\n",
            "694:\tlearn: 0.6875380\ttotal: 539ms\tremaining: 237ms\n",
            "695:\tlearn: 0.6875373\ttotal: 540ms\tremaining: 236ms\n",
            "696:\tlearn: 0.6875392\ttotal: 541ms\tremaining: 235ms\n",
            "697:\tlearn: 0.6875329\ttotal: 542ms\tremaining: 234ms\n",
            "698:\tlearn: 0.6875329\ttotal: 543ms\tremaining: 234ms\n",
            "699:\tlearn: 0.6875337\ttotal: 544ms\tremaining: 233ms\n",
            "700:\tlearn: 0.6875337\ttotal: 544ms\tremaining: 232ms\n",
            "701:\tlearn: 0.6875343\ttotal: 545ms\tremaining: 231ms\n",
            "702:\tlearn: 0.6875328\ttotal: 546ms\tremaining: 231ms\n",
            "703:\tlearn: 0.6875346\ttotal: 546ms\tremaining: 230ms\n",
            "704:\tlearn: 0.6875343\ttotal: 547ms\tremaining: 229ms\n",
            "705:\tlearn: 0.6875351\ttotal: 548ms\tremaining: 228ms\n",
            "706:\tlearn: 0.6875345\ttotal: 548ms\tremaining: 227ms\n",
            "707:\tlearn: 0.6875359\ttotal: 549ms\tremaining: 226ms\n",
            "708:\tlearn: 0.6875308\ttotal: 550ms\tremaining: 226ms\n",
            "709:\tlearn: 0.6875319\ttotal: 550ms\tremaining: 225ms\n",
            "710:\tlearn: 0.6875307\ttotal: 551ms\tremaining: 224ms\n",
            "711:\tlearn: 0.6875336\ttotal: 552ms\tremaining: 223ms\n",
            "712:\tlearn: 0.6875331\ttotal: 552ms\tremaining: 222ms\n",
            "713:\tlearn: 0.6875316\ttotal: 553ms\tremaining: 221ms\n",
            "714:\tlearn: 0.6875315\ttotal: 553ms\tremaining: 220ms\n",
            "715:\tlearn: 0.6875310\ttotal: 554ms\tremaining: 220ms\n",
            "716:\tlearn: 0.6875311\ttotal: 554ms\tremaining: 219ms\n",
            "717:\tlearn: 0.6875291\ttotal: 555ms\tremaining: 218ms\n",
            "718:\tlearn: 0.6875328\ttotal: 556ms\tremaining: 217ms\n",
            "719:\tlearn: 0.6875315\ttotal: 557ms\tremaining: 216ms\n",
            "720:\tlearn: 0.6875319\ttotal: 557ms\tremaining: 216ms\n",
            "721:\tlearn: 0.6875253\ttotal: 558ms\tremaining: 215ms\n",
            "722:\tlearn: 0.6875253\ttotal: 559ms\tremaining: 214ms\n",
            "723:\tlearn: 0.6875257\ttotal: 559ms\tremaining: 213ms\n",
            "724:\tlearn: 0.6875273\ttotal: 560ms\tremaining: 212ms\n",
            "725:\tlearn: 0.6875251\ttotal: 561ms\tremaining: 212ms\n",
            "726:\tlearn: 0.6875290\ttotal: 562ms\tremaining: 211ms\n",
            "727:\tlearn: 0.6875270\ttotal: 564ms\tremaining: 211ms\n",
            "728:\tlearn: 0.6875284\ttotal: 565ms\tremaining: 210ms\n",
            "729:\tlearn: 0.6875280\ttotal: 566ms\tremaining: 209ms\n",
            "730:\tlearn: 0.6875250\ttotal: 567ms\tremaining: 209ms\n",
            "731:\tlearn: 0.6875242\ttotal: 567ms\tremaining: 208ms\n",
            "732:\tlearn: 0.6875229\ttotal: 568ms\tremaining: 207ms\n",
            "733:\tlearn: 0.6875253\ttotal: 569ms\tremaining: 206ms\n",
            "734:\tlearn: 0.6875255\ttotal: 570ms\tremaining: 205ms\n",
            "735:\tlearn: 0.6875237\ttotal: 570ms\tremaining: 205ms\n",
            "736:\tlearn: 0.6875267\ttotal: 571ms\tremaining: 204ms\n",
            "737:\tlearn: 0.6875253\ttotal: 571ms\tremaining: 203ms\n",
            "738:\tlearn: 0.6875274\ttotal: 572ms\tremaining: 202ms\n",
            "739:\tlearn: 0.6875200\ttotal: 573ms\tremaining: 201ms\n",
            "740:\tlearn: 0.6875200\ttotal: 574ms\tremaining: 201ms\n",
            "741:\tlearn: 0.6875216\ttotal: 574ms\tremaining: 200ms\n",
            "742:\tlearn: 0.6875214\ttotal: 575ms\tremaining: 199ms\n",
            "743:\tlearn: 0.6875213\ttotal: 576ms\tremaining: 198ms\n",
            "744:\tlearn: 0.6875214\ttotal: 576ms\tremaining: 197ms\n",
            "745:\tlearn: 0.6875224\ttotal: 577ms\tremaining: 196ms\n",
            "746:\tlearn: 0.6875232\ttotal: 578ms\tremaining: 196ms\n",
            "747:\tlearn: 0.6875220\ttotal: 579ms\tremaining: 195ms\n",
            "748:\tlearn: 0.6875234\ttotal: 579ms\tremaining: 194ms\n",
            "749:\tlearn: 0.6875213\ttotal: 581ms\tremaining: 194ms\n",
            "750:\tlearn: 0.6875217\ttotal: 582ms\tremaining: 193ms\n",
            "751:\tlearn: 0.6875254\ttotal: 582ms\tremaining: 192ms\n",
            "752:\tlearn: 0.6875252\ttotal: 583ms\tremaining: 191ms\n",
            "753:\tlearn: 0.6875178\ttotal: 584ms\tremaining: 191ms\n",
            "754:\tlearn: 0.6875185\ttotal: 585ms\tremaining: 190ms\n",
            "755:\tlearn: 0.6875178\ttotal: 586ms\tremaining: 189ms\n",
            "756:\tlearn: 0.6875182\ttotal: 587ms\tremaining: 188ms\n",
            "757:\tlearn: 0.6875174\ttotal: 588ms\tremaining: 188ms\n",
            "758:\tlearn: 0.6875202\ttotal: 589ms\tremaining: 187ms\n",
            "759:\tlearn: 0.6875191\ttotal: 590ms\tremaining: 186ms\n",
            "760:\tlearn: 0.6875192\ttotal: 590ms\tremaining: 185ms\n",
            "761:\tlearn: 0.6875183\ttotal: 591ms\tremaining: 185ms\n",
            "762:\tlearn: 0.6875205\ttotal: 592ms\tremaining: 184ms\n",
            "763:\tlearn: 0.6875196\ttotal: 594ms\tremaining: 184ms\n",
            "764:\tlearn: 0.6875226\ttotal: 595ms\tremaining: 183ms\n",
            "765:\tlearn: 0.6875211\ttotal: 598ms\tremaining: 183ms\n",
            "766:\tlearn: 0.6875153\ttotal: 599ms\tremaining: 182ms\n",
            "767:\tlearn: 0.6875172\ttotal: 600ms\tremaining: 181ms\n",
            "768:\tlearn: 0.6875155\ttotal: 604ms\tremaining: 181ms\n",
            "769:\tlearn: 0.6875169\ttotal: 605ms\tremaining: 181ms\n",
            "770:\tlearn: 0.6875183\ttotal: 606ms\tremaining: 180ms\n",
            "771:\tlearn: 0.6875165\ttotal: 607ms\tremaining: 179ms\n",
            "772:\tlearn: 0.6875167\ttotal: 608ms\tremaining: 178ms\n",
            "773:\tlearn: 0.6875171\ttotal: 608ms\tremaining: 178ms\n",
            "774:\tlearn: 0.6875172\ttotal: 609ms\tremaining: 177ms\n",
            "775:\tlearn: 0.6875177\ttotal: 609ms\tremaining: 176ms\n",
            "776:\tlearn: 0.6875186\ttotal: 610ms\tremaining: 175ms\n",
            "777:\tlearn: 0.6875101\ttotal: 611ms\tremaining: 174ms\n",
            "778:\tlearn: 0.6875127\ttotal: 612ms\tremaining: 174ms\n",
            "779:\tlearn: 0.6875127\ttotal: 612ms\tremaining: 173ms\n",
            "780:\tlearn: 0.6875111\ttotal: 613ms\tremaining: 172ms\n",
            "781:\tlearn: 0.6875111\ttotal: 613ms\tremaining: 171ms\n",
            "782:\tlearn: 0.6875154\ttotal: 614ms\tremaining: 170ms\n",
            "783:\tlearn: 0.6875142\ttotal: 615ms\tremaining: 169ms\n",
            "784:\tlearn: 0.6875138\ttotal: 616ms\tremaining: 169ms\n",
            "785:\tlearn: 0.6875150\ttotal: 617ms\tremaining: 168ms\n",
            "786:\tlearn: 0.6875139\ttotal: 618ms\tremaining: 167ms\n",
            "787:\tlearn: 0.6875123\ttotal: 619ms\tremaining: 166ms\n",
            "788:\tlearn: 0.6875143\ttotal: 619ms\tremaining: 166ms\n",
            "789:\tlearn: 0.6875127\ttotal: 620ms\tremaining: 165ms\n",
            "790:\tlearn: 0.6875141\ttotal: 621ms\tremaining: 164ms\n",
            "791:\tlearn: 0.6875146\ttotal: 621ms\tremaining: 163ms\n",
            "792:\tlearn: 0.6875127\ttotal: 622ms\tremaining: 162ms\n",
            "793:\tlearn: 0.6875140\ttotal: 623ms\tremaining: 162ms\n",
            "794:\tlearn: 0.6875162\ttotal: 623ms\tremaining: 161ms\n",
            "795:\tlearn: 0.6875078\ttotal: 624ms\tremaining: 160ms\n",
            "796:\tlearn: 0.6875088\ttotal: 625ms\tremaining: 159ms\n",
            "797:\tlearn: 0.6875097\ttotal: 625ms\tremaining: 158ms\n",
            "798:\tlearn: 0.6875102\ttotal: 626ms\tremaining: 157ms\n",
            "799:\tlearn: 0.6875085\ttotal: 627ms\tremaining: 157ms\n",
            "800:\tlearn: 0.6875086\ttotal: 627ms\tremaining: 156ms\n",
            "801:\tlearn: 0.6875092\ttotal: 628ms\tremaining: 155ms\n",
            "802:\tlearn: 0.6875082\ttotal: 629ms\tremaining: 154ms\n",
            "803:\tlearn: 0.6875107\ttotal: 630ms\tremaining: 154ms\n",
            "804:\tlearn: 0.6875115\ttotal: 631ms\tremaining: 153ms\n",
            "805:\tlearn: 0.6875098\ttotal: 632ms\tremaining: 152ms\n",
            "806:\tlearn: 0.6875116\ttotal: 633ms\tremaining: 151ms\n",
            "807:\tlearn: 0.6875108\ttotal: 633ms\tremaining: 151ms\n",
            "808:\tlearn: 0.6875049\ttotal: 634ms\tremaining: 150ms\n",
            "809:\tlearn: 0.6875041\ttotal: 636ms\tremaining: 149ms\n",
            "810:\tlearn: 0.6875062\ttotal: 637ms\tremaining: 148ms\n",
            "811:\tlearn: 0.6875054\ttotal: 637ms\tremaining: 148ms\n",
            "812:\tlearn: 0.6875051\ttotal: 638ms\tremaining: 147ms\n",
            "813:\tlearn: 0.6875051\ttotal: 639ms\tremaining: 146ms\n",
            "814:\tlearn: 0.6875114\ttotal: 639ms\tremaining: 145ms\n",
            "815:\tlearn: 0.6875033\ttotal: 640ms\tremaining: 144ms\n",
            "816:\tlearn: 0.6875033\ttotal: 640ms\tremaining: 143ms\n",
            "817:\tlearn: 0.6875033\ttotal: 641ms\tremaining: 143ms\n",
            "818:\tlearn: 0.6875033\ttotal: 642ms\tremaining: 142ms\n",
            "819:\tlearn: 0.6875033\ttotal: 643ms\tremaining: 141ms\n",
            "820:\tlearn: 0.6875033\ttotal: 643ms\tremaining: 140ms\n",
            "821:\tlearn: 0.6875040\ttotal: 645ms\tremaining: 140ms\n",
            "822:\tlearn: 0.6875052\ttotal: 645ms\tremaining: 139ms\n",
            "823:\tlearn: 0.6875052\ttotal: 646ms\tremaining: 138ms\n",
            "824:\tlearn: 0.6875034\ttotal: 647ms\tremaining: 137ms\n",
            "825:\tlearn: 0.6875034\ttotal: 648ms\tremaining: 136ms\n",
            "826:\tlearn: 0.6875034\ttotal: 649ms\tremaining: 136ms\n",
            "827:\tlearn: 0.6875034\ttotal: 650ms\tremaining: 135ms\n",
            "828:\tlearn: 0.6875059\ttotal: 651ms\tremaining: 134ms\n",
            "829:\tlearn: 0.6875045\ttotal: 652ms\tremaining: 133ms\n",
            "830:\tlearn: 0.6875058\ttotal: 653ms\tremaining: 133ms\n",
            "831:\tlearn: 0.6875072\ttotal: 653ms\tremaining: 132ms\n",
            "832:\tlearn: 0.6875068\ttotal: 654ms\tremaining: 131ms\n",
            "833:\tlearn: 0.6875064\ttotal: 655ms\tremaining: 130ms\n",
            "834:\tlearn: 0.6875064\ttotal: 656ms\tremaining: 130ms\n",
            "835:\tlearn: 0.6875062\ttotal: 657ms\tremaining: 129ms\n",
            "836:\tlearn: 0.6875062\ttotal: 657ms\tremaining: 128ms\n",
            "837:\tlearn: 0.6875077\ttotal: 658ms\tremaining: 127ms\n",
            "838:\tlearn: 0.6875005\ttotal: 659ms\tremaining: 126ms\n",
            "839:\tlearn: 0.6875005\ttotal: 660ms\tremaining: 126ms\n",
            "840:\tlearn: 0.6875005\ttotal: 660ms\tremaining: 125ms\n",
            "841:\tlearn: 0.6875005\ttotal: 661ms\tremaining: 124ms\n",
            "842:\tlearn: 0.6875006\ttotal: 661ms\tremaining: 123ms\n",
            "843:\tlearn: 0.6875006\ttotal: 662ms\tremaining: 122ms\n",
            "844:\tlearn: 0.6875058\ttotal: 663ms\tremaining: 122ms\n",
            "845:\tlearn: 0.6874999\ttotal: 664ms\tremaining: 121ms\n",
            "846:\tlearn: 0.6875004\ttotal: 664ms\tremaining: 120ms\n",
            "847:\tlearn: 0.6875031\ttotal: 665ms\tremaining: 119ms\n",
            "848:\tlearn: 0.6875005\ttotal: 666ms\tremaining: 118ms\n",
            "849:\tlearn: 0.6875017\ttotal: 666ms\tremaining: 118ms\n",
            "850:\tlearn: 0.6875027\ttotal: 667ms\tremaining: 117ms\n",
            "851:\tlearn: 0.6875027\ttotal: 668ms\tremaining: 116ms\n",
            "852:\tlearn: 0.6875032\ttotal: 668ms\tremaining: 115ms\n",
            "853:\tlearn: 0.6875017\ttotal: 669ms\tremaining: 114ms\n",
            "854:\tlearn: 0.6875019\ttotal: 670ms\tremaining: 114ms\n",
            "855:\tlearn: 0.6875036\ttotal: 671ms\tremaining: 113ms\n",
            "856:\tlearn: 0.6875027\ttotal: 672ms\tremaining: 112ms\n",
            "857:\tlearn: 0.6875023\ttotal: 673ms\tremaining: 111ms\n",
            "858:\tlearn: 0.6875033\ttotal: 673ms\tremaining: 111ms\n",
            "859:\tlearn: 0.6875028\ttotal: 674ms\tremaining: 110ms\n",
            "860:\tlearn: 0.6875033\ttotal: 675ms\tremaining: 109ms\n",
            "861:\tlearn: 0.6874957\ttotal: 675ms\tremaining: 108ms\n",
            "862:\tlearn: 0.6874957\ttotal: 676ms\tremaining: 107ms\n",
            "863:\tlearn: 0.6874957\ttotal: 677ms\tremaining: 107ms\n",
            "864:\tlearn: 0.6874957\ttotal: 678ms\tremaining: 106ms\n",
            "865:\tlearn: 0.6874957\ttotal: 679ms\tremaining: 105ms\n",
            "866:\tlearn: 0.6874957\ttotal: 680ms\tremaining: 104ms\n",
            "867:\tlearn: 0.6874957\ttotal: 681ms\tremaining: 104ms\n",
            "868:\tlearn: 0.6874957\ttotal: 682ms\tremaining: 103ms\n",
            "869:\tlearn: 0.6874957\ttotal: 682ms\tremaining: 102ms\n",
            "870:\tlearn: 0.6874957\ttotal: 683ms\tremaining: 101ms\n",
            "871:\tlearn: 0.6874957\ttotal: 684ms\tremaining: 100ms\n",
            "872:\tlearn: 0.6874957\ttotal: 684ms\tremaining: 99.6ms\n",
            "873:\tlearn: 0.6874957\ttotal: 685ms\tremaining: 98.8ms\n",
            "874:\tlearn: 0.6874957\ttotal: 686ms\tremaining: 97.9ms\n",
            "875:\tlearn: 0.6874957\ttotal: 686ms\tremaining: 97.1ms\n",
            "876:\tlearn: 0.6874957\ttotal: 687ms\tremaining: 96.3ms\n",
            "877:\tlearn: 0.6874957\ttotal: 688ms\tremaining: 95.5ms\n",
            "878:\tlearn: 0.6874957\ttotal: 688ms\tremaining: 94.8ms\n",
            "879:\tlearn: 0.6874957\ttotal: 690ms\tremaining: 94ms\n",
            "880:\tlearn: 0.6874957\ttotal: 691ms\tremaining: 93.3ms\n",
            "881:\tlearn: 0.6874957\ttotal: 691ms\tremaining: 92.5ms\n",
            "882:\tlearn: 0.6874957\ttotal: 692ms\tremaining: 91.7ms\n",
            "883:\tlearn: 0.6874957\ttotal: 693ms\tremaining: 90.9ms\n",
            "884:\tlearn: 0.6874957\ttotal: 694ms\tremaining: 90.1ms\n",
            "885:\tlearn: 0.6874957\ttotal: 694ms\tremaining: 89.3ms\n",
            "886:\tlearn: 0.6874957\ttotal: 695ms\tremaining: 88.5ms\n",
            "887:\tlearn: 0.6874957\ttotal: 695ms\tremaining: 87.7ms\n",
            "888:\tlearn: 0.6874957\ttotal: 696ms\tremaining: 86.9ms\n",
            "889:\tlearn: 0.6874957\ttotal: 697ms\tremaining: 86.1ms\n",
            "890:\tlearn: 0.6874957\ttotal: 697ms\tremaining: 85.3ms\n",
            "891:\tlearn: 0.6874957\ttotal: 698ms\tremaining: 84.5ms\n",
            "892:\tlearn: 0.6874957\ttotal: 698ms\tremaining: 83.7ms\n",
            "893:\tlearn: 0.6874957\ttotal: 700ms\tremaining: 83ms\n",
            "894:\tlearn: 0.6874957\ttotal: 701ms\tremaining: 82.2ms\n",
            "895:\tlearn: 0.6874957\ttotal: 702ms\tremaining: 81.4ms\n",
            "896:\tlearn: 0.6874957\ttotal: 702ms\tremaining: 80.6ms\n",
            "897:\tlearn: 0.6874957\ttotal: 703ms\tremaining: 79.8ms\n",
            "898:\tlearn: 0.6874957\ttotal: 703ms\tremaining: 79ms\n",
            "899:\tlearn: 0.6874957\ttotal: 704ms\tremaining: 78.2ms\n",
            "900:\tlearn: 0.6874957\ttotal: 704ms\tremaining: 77.4ms\n",
            "901:\tlearn: 0.6874957\ttotal: 705ms\tremaining: 76.6ms\n",
            "902:\tlearn: 0.6874957\ttotal: 705ms\tremaining: 75.7ms\n",
            "903:\tlearn: 0.6874957\ttotal: 706ms\tremaining: 74.9ms\n",
            "904:\tlearn: 0.6874957\ttotal: 706ms\tremaining: 74.2ms\n",
            "905:\tlearn: 0.6874957\ttotal: 707ms\tremaining: 73.4ms\n",
            "906:\tlearn: 0.6874957\ttotal: 708ms\tremaining: 72.6ms\n",
            "907:\tlearn: 0.6874957\ttotal: 709ms\tremaining: 71.8ms\n",
            "908:\tlearn: 0.6874957\ttotal: 710ms\tremaining: 71ms\n",
            "909:\tlearn: 0.6874957\ttotal: 710ms\tremaining: 70.2ms\n",
            "910:\tlearn: 0.6874957\ttotal: 711ms\tremaining: 69.5ms\n",
            "911:\tlearn: 0.6874957\ttotal: 712ms\tremaining: 68.7ms\n",
            "912:\tlearn: 0.6874957\ttotal: 713ms\tremaining: 67.9ms\n",
            "913:\tlearn: 0.6874957\ttotal: 713ms\tremaining: 67.1ms\n",
            "914:\tlearn: 0.6874957\ttotal: 714ms\tremaining: 66.3ms\n",
            "915:\tlearn: 0.6874957\ttotal: 715ms\tremaining: 65.6ms\n",
            "916:\tlearn: 0.6874957\ttotal: 716ms\tremaining: 64.8ms\n",
            "917:\tlearn: 0.6874957\ttotal: 716ms\tremaining: 64ms\n",
            "918:\tlearn: 0.6874957\ttotal: 717ms\tremaining: 63.2ms\n",
            "919:\tlearn: 0.6874957\ttotal: 717ms\tremaining: 62.4ms\n",
            "920:\tlearn: 0.6874957\ttotal: 719ms\tremaining: 61.7ms\n",
            "921:\tlearn: 0.6874957\ttotal: 719ms\tremaining: 60.9ms\n",
            "922:\tlearn: 0.6874957\ttotal: 720ms\tremaining: 60.1ms\n",
            "923:\tlearn: 0.6874957\ttotal: 721ms\tremaining: 59.3ms\n",
            "924:\tlearn: 0.6874957\ttotal: 721ms\tremaining: 58.5ms\n",
            "925:\tlearn: 0.6874957\ttotal: 722ms\tremaining: 57.7ms\n",
            "926:\tlearn: 0.6874957\ttotal: 723ms\tremaining: 56.9ms\n",
            "927:\tlearn: 0.6874957\ttotal: 724ms\tremaining: 56.2ms\n",
            "928:\tlearn: 0.6874957\ttotal: 725ms\tremaining: 55.4ms\n",
            "929:\tlearn: 0.6874957\ttotal: 726ms\tremaining: 54.6ms\n",
            "930:\tlearn: 0.6874957\ttotal: 726ms\tremaining: 53.8ms\n",
            "931:\tlearn: 0.6874957\ttotal: 727ms\tremaining: 53.1ms\n",
            "932:\tlearn: 0.6874957\ttotal: 728ms\tremaining: 52.3ms\n",
            "933:\tlearn: 0.6874957\ttotal: 729ms\tremaining: 51.5ms\n",
            "934:\tlearn: 0.6874957\ttotal: 729ms\tremaining: 50.7ms\n",
            "935:\tlearn: 0.6874957\ttotal: 730ms\tremaining: 49.9ms\n",
            "936:\tlearn: 0.6874957\ttotal: 731ms\tremaining: 49.2ms\n",
            "937:\tlearn: 0.6874957\ttotal: 732ms\tremaining: 48.4ms\n",
            "938:\tlearn: 0.6874957\ttotal: 733ms\tremaining: 47.6ms\n",
            "939:\tlearn: 0.6874957\ttotal: 734ms\tremaining: 46.8ms\n",
            "940:\tlearn: 0.6874957\ttotal: 734ms\tremaining: 46ms\n",
            "941:\tlearn: 0.6874957\ttotal: 735ms\tremaining: 45.3ms\n",
            "942:\tlearn: 0.6874957\ttotal: 736ms\tremaining: 44.5ms\n",
            "943:\tlearn: 0.6874957\ttotal: 736ms\tremaining: 43.7ms\n",
            "944:\tlearn: 0.6874957\ttotal: 737ms\tremaining: 42.9ms\n",
            "945:\tlearn: 0.6874957\ttotal: 738ms\tremaining: 42.1ms\n",
            "946:\tlearn: 0.6874957\ttotal: 739ms\tremaining: 41.4ms\n",
            "947:\tlearn: 0.6874957\ttotal: 740ms\tremaining: 40.6ms\n",
            "948:\tlearn: 0.6874957\ttotal: 740ms\tremaining: 39.8ms\n",
            "949:\tlearn: 0.6874957\ttotal: 741ms\tremaining: 39ms\n",
            "950:\tlearn: 0.6874957\ttotal: 742ms\tremaining: 38.2ms\n",
            "951:\tlearn: 0.6874957\ttotal: 743ms\tremaining: 37.5ms\n",
            "952:\tlearn: 0.6874957\ttotal: 744ms\tremaining: 36.7ms\n",
            "953:\tlearn: 0.6874957\ttotal: 744ms\tremaining: 35.9ms\n",
            "954:\tlearn: 0.6874957\ttotal: 745ms\tremaining: 35.1ms\n",
            "955:\tlearn: 0.6874957\ttotal: 746ms\tremaining: 34.3ms\n",
            "956:\tlearn: 0.6874957\ttotal: 746ms\tremaining: 33.5ms\n",
            "957:\tlearn: 0.6874957\ttotal: 747ms\tremaining: 32.8ms\n",
            "958:\tlearn: 0.6874957\ttotal: 748ms\tremaining: 32ms\n",
            "959:\tlearn: 0.6874957\ttotal: 749ms\tremaining: 31.2ms\n",
            "960:\tlearn: 0.6874957\ttotal: 749ms\tremaining: 30.4ms\n",
            "961:\tlearn: 0.6874957\ttotal: 750ms\tremaining: 29.6ms\n",
            "962:\tlearn: 0.6874957\ttotal: 751ms\tremaining: 28.8ms\n",
            "963:\tlearn: 0.6874957\ttotal: 752ms\tremaining: 28.1ms\n",
            "964:\tlearn: 0.6874957\ttotal: 752ms\tremaining: 27.3ms\n",
            "965:\tlearn: 0.6874957\ttotal: 753ms\tremaining: 26.5ms\n",
            "966:\tlearn: 0.6874957\ttotal: 754ms\tremaining: 25.7ms\n",
            "967:\tlearn: 0.6874957\ttotal: 754ms\tremaining: 24.9ms\n",
            "968:\tlearn: 0.6874957\ttotal: 755ms\tremaining: 24.2ms\n",
            "969:\tlearn: 0.6874957\ttotal: 756ms\tremaining: 23.4ms\n",
            "970:\tlearn: 0.6874972\ttotal: 757ms\tremaining: 22.6ms\n",
            "971:\tlearn: 0.6874995\ttotal: 758ms\tremaining: 21.8ms\n",
            "972:\tlearn: 0.6874968\ttotal: 759ms\tremaining: 21ms\n",
            "973:\tlearn: 0.6874968\ttotal: 759ms\tremaining: 20.3ms\n",
            "974:\tlearn: 0.6874968\ttotal: 760ms\tremaining: 19.5ms\n",
            "975:\tlearn: 0.6874968\ttotal: 761ms\tremaining: 18.7ms\n",
            "976:\tlearn: 0.6874968\ttotal: 761ms\tremaining: 17.9ms\n",
            "977:\tlearn: 0.6874968\ttotal: 762ms\tremaining: 17.1ms\n",
            "978:\tlearn: 0.6874968\ttotal: 763ms\tremaining: 16.4ms\n",
            "979:\tlearn: 0.6874968\ttotal: 764ms\tremaining: 15.6ms\n",
            "980:\tlearn: 0.6874983\ttotal: 764ms\tremaining: 14.8ms\n",
            "981:\tlearn: 0.6874963\ttotal: 765ms\tremaining: 14ms\n",
            "982:\tlearn: 0.6874983\ttotal: 766ms\tremaining: 13.2ms\n",
            "983:\tlearn: 0.6874979\ttotal: 767ms\tremaining: 12.5ms\n",
            "984:\tlearn: 0.6874968\ttotal: 767ms\tremaining: 11.7ms\n",
            "985:\tlearn: 0.6874977\ttotal: 768ms\tremaining: 10.9ms\n",
            "986:\tlearn: 0.6874974\ttotal: 769ms\tremaining: 10.1ms\n",
            "987:\tlearn: 0.6874985\ttotal: 769ms\tremaining: 9.34ms\n",
            "988:\tlearn: 0.6874968\ttotal: 770ms\tremaining: 8.57ms\n",
            "989:\tlearn: 0.6874977\ttotal: 771ms\tremaining: 7.79ms\n",
            "990:\tlearn: 0.6874961\ttotal: 772ms\tremaining: 7.01ms\n",
            "991:\tlearn: 0.6874974\ttotal: 773ms\tremaining: 6.24ms\n",
            "992:\tlearn: 0.6874982\ttotal: 774ms\tremaining: 5.46ms\n",
            "993:\tlearn: 0.6874991\ttotal: 775ms\tremaining: 4.67ms\n",
            "994:\tlearn: 0.6874972\ttotal: 775ms\tremaining: 3.9ms\n",
            "995:\tlearn: 0.6874924\ttotal: 776ms\tremaining: 3.12ms\n",
            "996:\tlearn: 0.6874924\ttotal: 776ms\tremaining: 2.33ms\n",
            "997:\tlearn: 0.6874936\ttotal: 777ms\tremaining: 1.56ms\n",
            "998:\tlearn: 0.6874932\ttotal: 777ms\tremaining: 778us\n",
            "999:\tlearn: 0.6874931\ttotal: 778ms\tremaining: 0us\n",
            "Test Accuracy with blending classifier:  0.16842105263157894\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from catboost import CatBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming you have your embeddings already defined as train_embeddings and test_embeddings\n",
        "# and your target labels as y_train and y_test\n",
        "\n",
        "# Example data (replace with your actual data)\n",
        "# train_embeddings = ...\n",
        "# test_embeddings = ...\n",
        "# y_train = ...\n",
        "# y_test = ...\n",
        "\n",
        "# Convert embeddings to DataFrames\n",
        "train_embeddings_df = pd.DataFrame(train_embeddings, columns=[f\"emb_{i}\" for i in range(train_embeddings.shape[1])])\n",
        "test_embeddings_df = pd.DataFrame(test_embeddings, columns=[f\"emb_{i}\" for i in range(test_embeddings.shape[1])])\n",
        "\n",
        "# Define base models\n",
        "base_models = [\n",
        "    ('catboost', CatBoostClassifier(random_state=42)),\n",
        "    ('xgboost', XGBClassifier(random_state=42)),\n",
        "    ('lightgbm', LGBMClassifier(random_state=42))\n",
        "]\n",
        "\n",
        "# Meta-model\n",
        "meta_model = CatBoostClassifier(random_state=42)\n",
        "\n",
        "# Initialize predictions DataFrame for train and test\n",
        "train_predictions = pd.DataFrame()\n",
        "test_predictions = pd.DataFrame()\n",
        "\n",
        "# Initialize KFold\n",
        "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
        "\n",
        "# Generate predictions for each base model\n",
        "for name, model in base_models:\n",
        "    print(f\"Training and predicting with {name}...\")\n",
        "    train_preds = []\n",
        "    test_preds = []\n",
        "    for train_index, val_index in kf.split(train_embeddings_df):\n",
        "        X_train_fold, X_val_fold = train_embeddings_df.iloc[train_index], train_embeddings_df.iloc[val_index]\n",
        "        y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
        "\n",
        "        model.fit(X_train_fold, y_train_fold)\n",
        "        train_fold_pred = model.predict(X_val_fold)\n",
        "        train_preds.extend(train_fold_pred)\n",
        "\n",
        "        test_fold_pred = model.predict(test_embeddings_df)\n",
        "        test_preds.append(test_fold_pred)\n",
        "\n",
        "    train_predictions[name] = train_preds\n",
        "    test_predictions[name] = sum(test_preds) / len(test_preds)  # Average predictions across folds\n",
        "\n",
        "# Train meta-model on train predictions\n",
        "meta_model.fit(train_predictions, y_train)\n",
        "\n",
        "# Predict with meta-model on test predictions\n",
        "meta_predictions = meta_model.predict(test_predictions)\n",
        "\n",
        "# Evaluate performance on test set if y_test is available\n",
        "accuracy = accuracy_score(y_test, meta_predictions)\n",
        "print(\"Test Accuracy with blending classifier: \", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNSiSjonBZSz",
        "outputId": "6d040aa4-d28c-44b3-9e3a-dc5314851c4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 3ms/step\n"
          ]
        }
      ],
      "source": [
        "embeddings_test = embedding_model.predict(X_log_transformed_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWTZGSe9Bxxu"
      },
      "outputs": [],
      "source": [
        "df_test=pd.read_csv(\"/content/processed_test_f (2).csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tern67Q2Bdp6"
      },
      "outputs": [],
      "source": [
        "# Predict the winner and winner score using the CatBoost model\n",
        "df_test['pred_winner'] = model.predict(embeddings_test)\n",
        "df_test['pred_winner_score'] = model.predict_proba(embeddings_test)[:, 1]\n",
        "\n",
        "# Determine the predicted winner ID\n",
        "df_test['pred_winner_id'] = df_test.apply(\n",
        "    lambda row: row['team1_id'] if row['pred_winner'] == 1 else row['team2_id'], axis=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgQvr88xCIVI"
      },
      "outputs": [],
      "source": [
        "df_train.to_csv(\"train_embeddings.csv\",index=False)\n",
        "df_test.to_csv(\"test_embeddings.csv\",index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6WfahLfA1ID"
      },
      "outputs": [],
      "source": [
        "# Predict the winner and winner score using the CatBoost model\n",
        "df_train['pred_winner'] = model.predict(X)\n",
        "df_train['pred_winner_score'] = model.predict_proba(X)[:, 1]\n",
        "\n",
        "# Determine the predicted winner ID\n",
        "df_train['pred_winner_id'] = df_train.apply(\n",
        "    lambda row: row['team1_id'] if row['pred_winner'] == 1 else row['team2_id'], axis=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HbuAYQJV9_rD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQPNE_O59wRS",
        "outputId": "92fd180c-6664-4e64-cb19-1768bb2cf56d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0      0.0\n",
              "1      1.0\n",
              "2      1.0\n",
              "3      1.0\n",
              "4      0.0\n",
              "      ... \n",
              "943    1.0\n",
              "944    0.0\n",
              "945    0.0\n",
              "946    0.0\n",
              "947    0.0\n",
              "Name: winner, Length: 948, dtype: float64"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X=embeddings_df\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewgoDOaY43t0",
        "outputId": "12e98702-038d-4d7c-d14e-d0fac749ed76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(948, 200)\n"
          ]
        }
      ],
      "source": [
        "# Standardize the entire dataset\n",
        "X_scaled = scaler.transform(X)\n",
        "\n",
        "# Convert to PyTorch tensor\n",
        "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
        "\n",
        "# Extract embeddings for the entire dataset\n",
        "model.eval()\n",
        "_, embeddings = model(X_tensor)\n",
        "embeddings = embeddings.detach().numpy()\n",
        "\n",
        "# Predict the winner and winner score using the CatBoost model\n",
        "df_train['pred_winner'] = catboost_model.predict(embeddings)\n",
        "df_train['pred_winner_score'] = catboost_model.predict_proba(embeddings)[:, 1]\n",
        "\n",
        "# Determine the predicted winner ID\n",
        "df_train['pred_winner_id'] = df_train.apply(\n",
        "    lambda row: row['team1_id'] if row['pred_winner'] == 1 else row['team2_id'], axis=1\n",
        ")\n",
        "\n",
        "# Print the shape of the dataframe\n",
        "print(df_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AZcIXcC5wDz",
        "outputId": "2368d510-cdc8-4a54-c0ff-2f4665855d42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(271, 199)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "# Load the test data\n",
        "# test_file_path = \"/content/drive/MyDrive/AmEx/processed_test_f.csv\"\n",
        "# test_data = pd.read_csv(test_file_path)\n",
        "\n",
        "# Dropping irrelevant columns\n",
        "irrelevant_columns = [\n",
        "    'match id', 'team1', 'team1_id', 'team1_roster_ids',\n",
        "    'team2', 'team2_id', 'team2_roster_ids', 'venue', 'city',\n",
        "    'match_dt', 'series_name', 'season'\n",
        "]\n",
        "test_data_cleaned = test_data.drop(columns=irrelevant_columns)\n",
        "\n",
        "# Select only numeric columns\n",
        "test_data_numeric = test_data_cleaned.select_dtypes(include=['number'])\n",
        "\n",
        "# Fill missing values with the mean of their respective columns\n",
        "test_data_filled = test_data_numeric.fillna(test_data_numeric.mean())\n",
        "\n",
        "# Standardize the features in the test data\n",
        "scaler = StandardScaler()\n",
        "test_data_scaled = scaler.fit_transform(test_data_filled)\n",
        "\n",
        "# Convert to PyTorch tensor\n",
        "test_data_tensor = torch.tensor(test_data_scaled, dtype=torch.float32)\n",
        "\n",
        "# Extract embeddings for the test dataset\n",
        "model.eval()\n",
        "_, test_data_embeddings = model(test_data_tensor)\n",
        "test_data_embeddings = test_data_embeddings.detach().numpy()\n",
        "\n",
        "# Predict the winner and winner score using the CatBoost model\n",
        "test_data['pred_winner'] = catboost_model.predict(test_data_embeddings)\n",
        "test_data['pred_winner_score'] = catboost_model.predict_proba(test_data_embeddings)[:, 1]\n",
        "\n",
        "# Determine the predicted winner ID\n",
        "test_data['pred_winner_id'] = test_data.apply(\n",
        "    lambda row: row['team1_id'] if row['pred_winner'] == 1 else row['team2_id'], axis=1\n",
        ")\n",
        "\n",
        "# Print the shape of the test dataframe\n",
        "print(test_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7bRHY4lBV8C",
        "outputId": "6c97db6a-c8be-41df-92dc-c4bab1875105"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(948, 200) (271, 199)\n"
          ]
        }
      ],
      "source": [
        "print(df_train.shape, test_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBlSHZQV6NwA"
      },
      "outputs": [],
      "source": [
        "df_train['dataset_type'] = 'train'\n",
        "test_data['dataset_type'] = 'r1'\n",
        "algo_name = 'CatBoost;XGBoost;LightGBM;GBM;CatBoost'\n",
        "is_ensemble = 'yes'\n",
        "n_trees = '131;269;294;223;165'\n",
        "depth = '4;5;3;3;9'\n",
        "lr = '0.026746858922480903;0.1497059900832021;0.15387125194824516;0.013177244157007226;0.21323373869865603'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "it26JQXHxaq2",
        "outputId": "3a8c697a-1e01-4668-e14b-2f1fcb2a4c2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost Accuracy: 0.8245614035087719\n",
            "XGBoost Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.81      0.82      0.82       136\n",
            "         1.0       0.84      0.83      0.83       149\n",
            "\n",
            "    accuracy                           0.82       285\n",
            "   macro avg       0.82      0.82      0.82       285\n",
            "weighted avg       0.82      0.82      0.82       285\n",
            "\n",
            "Cross-Validation Scores - Avg: 0.8035087719298245, Min: 0.7719298245614035, Max: 0.8421052631578947\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Train XGBoost model\n",
        "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "xgb_model.fit(train_embeddings, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_xgb = xgb_model.predict(test_embeddings)\n",
        "\n",
        "# Evaluate the XGBoost model\n",
        "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
        "report_xgb = classification_report(y_test, y_pred_xgb)\n",
        "\n",
        "# Perform cross-validation on the test set\n",
        "cv_scores_xgb = cross_val_score(xgb_model, test_embeddings, y_test, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Print the results\n",
        "print(f\"XGBoost Accuracy: {accuracy_xgb}\")\n",
        "print(f\"XGBoost Classification Report:\\n{report_xgb}\")\n",
        "print(f\"Cross-Validation Scores - Avg: {cv_scores_xgb.mean()}, Min: {cv_scores_xgb.min()}, Max: {cv_scores_xgb.max()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzL-KOQR6b05"
      },
      "outputs": [],
      "source": [
        "df_train.to_csv('sub19 train.csv', index=False)\n",
        "test_data.to_csv('sub19 test.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ROUND 2 SUBMISSION FILES"
      ],
      "metadata": {
        "id": "nJ53WdT4I93e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Load the data\n",
        "data = df_train\n",
        "\n",
        "# Dropping irrelevant columns\n",
        "irrelevant_columns = [\n",
        "    'match id', 'team1', 'team1_id', 'team1_roster_ids',\n",
        "    'team2', 'team2_id', 'team2_roster_ids', 'venue', 'city',\n",
        "    'match_dt', 'series_name', 'season'\n",
        "]\n",
        "data_cleaned = data.drop(columns=irrelevant_columns)\n",
        "\n",
        "# Select only numeric columns\n",
        "data_numeric = data_cleaned.select_dtypes(include=['number'])\n",
        "\n",
        "# Fill missing values with the mean of their respective columns\n",
        "data_filled = data_numeric.fillna(data_numeric.mean())\n",
        "\n",
        "# Split the data into features and target variable\n",
        "X = data_filled.drop(columns=['winner'])\n",
        "y = data_filled['winner']\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y.values, dtype=torch.long)\n",
        "\n",
        "# Define the neural network\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(X.shape[1], 100)\n",
        "        self.fc2 = nn.Linear(100, 35)\n",
        "        self.fc3 = nn.Linear(35, 2)  # Output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        embeddings = x  # Extract embeddings here\n",
        "        x = self.fc3(x)\n",
        "        return x, embeddings\n",
        "\n",
        "model = Net()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs, _ = model(X_tensor)\n",
        "    loss = criterion(outputs, y_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
        "\n",
        "# Extract embeddings from the trained model\n",
        "model.eval()\n",
        "_, embeddings = model(X_tensor)\n",
        "\n",
        "embeddings = embeddings.detach().numpy()\n",
        "\n",
        "print(f\"Shape of embeddings: {embeddings.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "__FQH3WLGoca",
        "outputId": "932ad15b-d76d-49a6-f46a-7c7e097faf3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Loss: 0.7033334970474243\n",
            "Epoch 2/100, Loss: 0.6897017955780029\n",
            "Epoch 3/100, Loss: 0.6779980063438416\n",
            "Epoch 4/100, Loss: 0.6676099300384521\n",
            "Epoch 5/100, Loss: 0.6578643321990967\n",
            "Epoch 6/100, Loss: 0.6484081149101257\n",
            "Epoch 7/100, Loss: 0.6389741897583008\n",
            "Epoch 8/100, Loss: 0.6293782591819763\n",
            "Epoch 9/100, Loss: 0.6195287108421326\n",
            "Epoch 10/100, Loss: 0.609406590461731\n",
            "Epoch 11/100, Loss: 0.5989533066749573\n",
            "Epoch 12/100, Loss: 0.5881728529930115\n",
            "Epoch 13/100, Loss: 0.5770559906959534\n",
            "Epoch 14/100, Loss: 0.5655280351638794\n",
            "Epoch 15/100, Loss: 0.5534976720809937\n",
            "Epoch 16/100, Loss: 0.5410261154174805\n",
            "Epoch 17/100, Loss: 0.5280237197875977\n",
            "Epoch 18/100, Loss: 0.5145041942596436\n",
            "Epoch 19/100, Loss: 0.5004948973655701\n",
            "Epoch 20/100, Loss: 0.4859408140182495\n",
            "Epoch 21/100, Loss: 0.47097092866897583\n",
            "Epoch 22/100, Loss: 0.455764502286911\n",
            "Epoch 23/100, Loss: 0.4403248429298401\n",
            "Epoch 24/100, Loss: 0.424640953540802\n",
            "Epoch 25/100, Loss: 0.40875089168548584\n",
            "Epoch 26/100, Loss: 0.3926490843296051\n",
            "Epoch 27/100, Loss: 0.3764894902706146\n",
            "Epoch 28/100, Loss: 0.36045050621032715\n",
            "Epoch 29/100, Loss: 0.3446243405342102\n",
            "Epoch 30/100, Loss: 0.3291832506656647\n",
            "Epoch 31/100, Loss: 0.31417542695999146\n",
            "Epoch 32/100, Loss: 0.2996079623699188\n",
            "Epoch 33/100, Loss: 0.28557443618774414\n",
            "Epoch 34/100, Loss: 0.2720395624637604\n",
            "Epoch 35/100, Loss: 0.25900977849960327\n",
            "Epoch 36/100, Loss: 0.24649940431118011\n",
            "Epoch 37/100, Loss: 0.23451662063598633\n",
            "Epoch 38/100, Loss: 0.2230253964662552\n",
            "Epoch 39/100, Loss: 0.21205787360668182\n",
            "Epoch 40/100, Loss: 0.20159180462360382\n",
            "Epoch 41/100, Loss: 0.19156594574451447\n",
            "Epoch 42/100, Loss: 0.18197768926620483\n",
            "Epoch 43/100, Loss: 0.17280583083629608\n",
            "Epoch 44/100, Loss: 0.16404174268245697\n",
            "Epoch 45/100, Loss: 0.15563242137432098\n",
            "Epoch 46/100, Loss: 0.14758583903312683\n",
            "Epoch 47/100, Loss: 0.13987591862678528\n",
            "Epoch 48/100, Loss: 0.13245469331741333\n",
            "Epoch 49/100, Loss: 0.125330850481987\n",
            "Epoch 50/100, Loss: 0.11847179383039474\n",
            "Epoch 51/100, Loss: 0.11190232634544373\n",
            "Epoch 52/100, Loss: 0.1055976003408432\n",
            "Epoch 53/100, Loss: 0.09955628961324692\n",
            "Epoch 54/100, Loss: 0.093756765127182\n",
            "Epoch 55/100, Loss: 0.08820311725139618\n",
            "Epoch 56/100, Loss: 0.08289463073015213\n",
            "Epoch 57/100, Loss: 0.07782843708992004\n",
            "Epoch 58/100, Loss: 0.07299309223890305\n",
            "Epoch 59/100, Loss: 0.06840528547763824\n",
            "Epoch 60/100, Loss: 0.06404110044240952\n",
            "Epoch 61/100, Loss: 0.059884220361709595\n",
            "Epoch 62/100, Loss: 0.0559394508600235\n",
            "Epoch 63/100, Loss: 0.05219798535108566\n",
            "Epoch 64/100, Loss: 0.048690322786569595\n",
            "Epoch 65/100, Loss: 0.04538873955607414\n",
            "Epoch 66/100, Loss: 0.042302269488573074\n",
            "Epoch 67/100, Loss: 0.03941375017166138\n",
            "Epoch 68/100, Loss: 0.036741405725479126\n",
            "Epoch 69/100, Loss: 0.03425037860870361\n",
            "Epoch 70/100, Loss: 0.031923603266477585\n",
            "Epoch 71/100, Loss: 0.02975941076874733\n",
            "Epoch 72/100, Loss: 0.027750829234719276\n",
            "Epoch 73/100, Loss: 0.02589324675500393\n",
            "Epoch 74/100, Loss: 0.024167759343981743\n",
            "Epoch 75/100, Loss: 0.02257201075553894\n",
            "Epoch 76/100, Loss: 0.021099094301462173\n",
            "Epoch 77/100, Loss: 0.019739653915166855\n",
            "Epoch 78/100, Loss: 0.01847970485687256\n",
            "Epoch 79/100, Loss: 0.017313921824097633\n",
            "Epoch 80/100, Loss: 0.01624036766588688\n",
            "Epoch 81/100, Loss: 0.015252805314958096\n",
            "Epoch 82/100, Loss: 0.014346604235470295\n",
            "Epoch 83/100, Loss: 0.01351197250187397\n",
            "Epoch 84/100, Loss: 0.01274261623620987\n",
            "Epoch 85/100, Loss: 0.012032769620418549\n",
            "Epoch 86/100, Loss: 0.011379090137779713\n",
            "Epoch 87/100, Loss: 0.010775433853268623\n",
            "Epoch 88/100, Loss: 0.01021879818290472\n",
            "Epoch 89/100, Loss: 0.009704316966235638\n",
            "Epoch 90/100, Loss: 0.009228802286088467\n",
            "Epoch 91/100, Loss: 0.008788207545876503\n",
            "Epoch 92/100, Loss: 0.008379307575523853\n",
            "Epoch 93/100, Loss: 0.007999706082046032\n",
            "Epoch 94/100, Loss: 0.007646310143172741\n",
            "Epoch 95/100, Loss: 0.0073171514086425304\n",
            "Epoch 96/100, Loss: 0.0070105502381920815\n",
            "Epoch 97/100, Loss: 0.006723891943693161\n",
            "Epoch 98/100, Loss: 0.006455690134316683\n",
            "Epoch 99/100, Loss: 0.0062049333937466145\n",
            "Epoch 100/100, Loss: 0.005969595164060593\n",
            "Shape of embeddings: (948, 35)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "V0pBdKJSGzao",
        "outputId": "d607eb5b-4226-410a-a5c8-85b32a8b10ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.5-cp310-cp310-manylinux2014_x86_64.whl (98.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.4.2)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Train CatBoost model on the entire dataset embeddings\n",
        "catboost_model = CatBoostClassifier(verbose=0)\n",
        "catboost_model.fit(embeddings, y)\n",
        "\n",
        "# Predict on the entire dataset\n",
        "y_pred_catboost = catboost_model.predict(embeddings)\n",
        "\n",
        "# Evaluate the CatBoost model\n",
        "accuracy_catboost = accuracy_score(y, y_pred_catboost)\n",
        "report_catboost = classification_report(y, y_pred_catboost)\n",
        "\n",
        "# Perform cross-validation on the entire dataset\n",
        "cv_scores = cross_val_score(catboost_model, embeddings, y, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Print the results\n",
        "print(f\"CatBoost Accuracy: {accuracy_catboost}\")\n",
        "print(f\"CatBoost Classification Report:\\n{report_catboost}\")\n",
        "print(f\"Cross-Validation Scores - Avg: {cv_scores.mean()}, Min: {cv_scores.min()}, Max: {cv_scores.max()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tsApvXirGq31",
        "outputId": "d4ea40d1-3bee-4328-bc1f-143305cf19ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CatBoost Accuracy: 1.0\n",
            "CatBoost Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       477\n",
            "         1.0       1.00      1.00      1.00       471\n",
            "\n",
            "    accuracy                           1.00       948\n",
            "   macro avg       1.00      1.00      1.00       948\n",
            "weighted avg       1.00      1.00      1.00       948\n",
            "\n",
            "Cross-Validation Scores - Avg: 1.0, Min: 1.0, Max: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_r2 = round2_data\n",
        "data_r2 = data_r2.drop(columns = irrelevant_columns)\n",
        "data_r2_nums = data_r2.select_dtypes(include=['number'])\n",
        "data_r2_filled = data_r2_nums.fillna(data_r2_nums.mean())\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_r2_scaled = scaler.fit_transform(data_r2_filled)\n",
        "\n",
        "X_r2_tensor = torch.tensor(X_r2_scaled, dtype=torch.float32)\n",
        "\n",
        "_, embeddings_r2 = model(X_r2_tensor)\n",
        "embeddings_r2 = embeddings_r2.detach().numpy()\n",
        "print(embeddings_r2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DaCcHAkHYJB",
        "outputId": "d34d8263-268e-4204-a415-1491ffccc7bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(207, 35)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "round2_data['pred_winner'] = catboost_model.predict(embeddings_r2)\n",
        "round2_data['pred_winner_score'] = catboost_model.predict_proba(embeddings_r2)[:, 1]\n",
        "round2_data['pred_winner_id'] = round2_data.apply(\n",
        "    lambda row: row['team1_id'] if row['pred_winner'] == 1 else row['team2_id'], axis=1\n",
        ")\n",
        "print(round2_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPujVQBnJI8G",
        "outputId": "b4dfc414-a825-4610-b945-b900c6596c74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(207, 199)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "round2_data.to_csv('r2.csv', index=False)"
      ],
      "metadata": {
        "id": "4W-cNnRYJain"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importances = catboost_model.get_feature_importance()\n",
        "\n",
        "sorted_indices = np.argsort(-feature_importances)\n",
        "sorted_embeddings_r2 = embeddings_r2[:, sorted_indices]\n",
        "sorted_embeddings_r2_df = pd.DataFrame(sorted_embeddings_r2)\n",
        "sorted_embeddings_r2_df.to_csv('sorted_embeddings_r2.csv', index=False)"
      ],
      "metadata": {
        "id": "392_t1mvLW_9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}